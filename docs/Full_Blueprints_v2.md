Domain Index:
Data Domain: L0
Regime Domain: L1, L64
Microstructure Domain: L8, L9, L10, L59, L61, L62, L63
Kinematics Domain: L2, L11–L18, L19–L25, L51–L58, L60
Pattern Domain: L26–L50
Expectancy & Fusion Domain: L3, L7, L66–L68, L70–L73, L75
Risk & Tail Domain: L4, L74, L76–L80, L81, L83, L84, L85–L87, L91–L95
Meta-Learning & Adaptation Domain: L6, L65
Reinforcement Learning Domain: L82
Pine Mirror & Execution Domain: L5, L69, L88–L90, L96–L100
## Data Domain
L0 – Data Ingestion & Market Feed Layer
- Domain: Data
- Primary Role: Serves as the unified market data pipeline for all higher layers, continuously collecting raw feeds (OHLCV, order book, trades, funding rates) from exchanges and normalizing them into synchronized, clean feature sets[1]. L0’s integrity is critical – a fault here can corrupt volatility estimates and patterns, undermining all subsequent analysis[1].
- Key Inputs: Multi-exchange data streams (e.g. Binance REST/WebSocket for price & volume, TradingView for macro proxies), various timeframes (1s to 1d OHLCV), order book snapshots (depth levels), and trade tick data.
- Key Outputs: Time-aligned feature matrix including price/volume bars, microstructure features (ATR%, spread in bps, order book imbalance, wick ratios, volume z-scores, etc.), technical indicators (RSI, Bollinger Width, EMA slopes, volatility estimates) for each timeframe[2][3]. Also produces a daily updated universe of top N assets (e.g. top-50 by volume) for the engine to trade.
- Core Logic/Model: Composed of subcomponents for exchange connectivity and data cleaning – e.g., a Binance data collector (polling + burst refresh logic), a TradingView auxiliary feed merger for cross-asset data, a timeframe resampler building the canonical 1m/5m/15m/1h/4h/1d series, and feature builders for microstructure and indicators[4][5]. Implements error-handling (retry/backoff, failover to cached data) and confidence scoring to flag stale or low-quality data.
- File & Location: core/l0_data_feed.py (data pipeline and feed handlers).
- Config/Wiring: Defined in config/data.yml under L0: settings (exchange API keys, symbols, timeframes, data refresh intervals). Universe selection criteria (e.g. volume thresholds) configurable (writes universe.yaml output consumed by other layers[6]). Integration points: populates global data structures accessed by downstream layers.
- Health & Logging: Continuously logs feed status and any gaps. On critical failures (e.g. data timeout), raises an L0_FEED_DEGRADED alert to Pine and triggers risk-tightening in L4[7]. Metrics like data latency and dropouts are recorded. If L0 fails, the system falls back to reduced functionality mode (using cached or Pine data) to protect trading.
- TCN Impact: Provides the high-integrity data bedrock required for institutional-grade reliability. By ensuring all layers start from consistent, accurate market data, L0 prevents garbage-in that could cascade into erroneous signals. This robust data foundation directly boosts the engine’s Trust-Confidence-Noise (TCN) score via superior data integrity and resiliency.
## Regime Domain
L1 – Regime Classification & Volatility Modelling
- Domain: Regime
- Primary Role: Classifies the market’s volatility regime (e.g. Calm, Trending, Volatile, Explosive) and forecasts near-term volatility using statistical models[8]. L1 essentially labels the market state and supplies volatility context (like forward $\sigma$) to guide risk and model selection in higher layers.
- Key Inputs: Recent return series and volatility measures from L0 (e.g. price changes, realized variance), macro indicators (if any), and prior regime state. Ingests L0 features such as ATR and volume to inform regime probabilities.
- Key Outputs: Discrete regime label (state) with associated probabilities for each regime (e.g. P[Calm], P[Volatile]), the forecasted volatility $\sigma_{t+1}$, downside risk skew (e.g. GARCH asymmetric term), and a volatility confidence level[9]. These outputs feed directly into L2, L3, L4 for risk-adjusted decisions.
- Core Logic/Model: An ensemble of volatility models: EGARCH variants (1,1 and 2,1), a GJR-GARCH for skew, and a Hidden Markov Model (HMM) overlay that treats each volatility model as an expert for a particular regime[10]. The HMM/Mixture-of-Experts fuses their outputs into a consolidated regime posterior and volatility forecast. For example, calm vs explosive regimes are distinguished by model likelihoods, and forward volatility is predicted via a weighted combination of EGARCH forecasts.
- File & Location: core/l1_regime_volatility.py (implements GARCH models and HMM fusion).
- Config/Wiring: Configured in config/regime.yml (parameters for GARCH (α, β, ω, etc.), HMM state definitions, thresholds for regime changes). The layer is wired to periodically update its models (e.g. recalibrate daily) and to broadcast regime shifts.
- Health & Logging: L1 logs regime probabilities and realized vs predicted volatility error each cycle. If model error spikes (indicating model drift), it flags low confidence. Failure of L1 (e.g. no convergence) triggers a default to a conservative regime (e.g. “Volatile”) and notifies L6 (feedback) to adjust model parameters.
- TCN Impact: Enhances the engine’s context-awareness, a key for institutional robustness. By dynamically adjusting strategy according to market regime, L1 helps avoid over-trading in chaotic conditions and leverages opportunities in trending markets, materially increasing the system’s signal-to-noise discrimination and overall stability[11][12].
L64 – Regime Shift Detection Engine
- Domain: Regime
- Primary Role: High-level “macro brain” that monitors multi-domain signals for major regime changes[13][14]. While L1 labels volatility state in real-time, L64 detects broader regime shifts (e.g. transitioning from calm trending to chaotic) using a Hidden Markov Model Mixture-of-Experts (“HMM-MoE Prime”).
- Key Inputs: A wide set of aggregate metrics: volatility regime history (from L1), trend statistics (from L51–L53), microstructure stress signals (from L8/L61), noise levels (L25 output), directional conviction (L24), liquidity and spread trends, and pattern reliability indicators[15]. These provide a holistic view of market behavior.
- Key Outputs: Current macro regime state (categorical, e.g. Trend, Chaotic, Transitional) and regime transition probabilities[13][16]. It also computes a turbulence index (market instability gauge) and flags like metastability_flag when markets are prone to abrupt change[17]. These outputs influence model gating (certain models might be down-weighted in chaotic regimes) and risk management (L4/L85 may cut exposure if regime is hostile).
- Core Logic/Model: An HMM with 3–6 latent states representing macro regimes, using emissions from ensemble models (EGARCH mixtures, Bayesian filters, clustering of patterns)[18]. It continuously updates state probabilities and uses Bayesian regime transition modeling to anticipate regime shifts. Essentially, L64 is a meta-model synthesizing signals across layers to detect when the market’s underlying condition has fundamentally changed.
- File & Location: core/l64_regime_hmm.py.
- Config/Wiring: Settings in config/regime.yml (L64: section) define the possible regimes and sensitivity (e.g. thresholds for turbulence index). L64 subscribes to outputs from many layers (via an internal bus or shared memory) and publishes its regime state globally so that all layers (especially L3 fusion and L4 risk) can adjust decisions per the current regime.
- Health & Logging: L64 logs regime state probabilities and rationale metrics (e.g. volatility shifts, pattern cluster changes). If it detects an abrupt, high-confidence regime flip (e.g. calm→panic), it triggers alerts and potentially invokes L85 (critical failure) logic if extreme. Model confidence is tracked; if HMM confidence is low, the system may default to more conservative settings.
- TCN Impact: Provides institutional-grade oversight by ensuring the engine is never “sleepwalking” in the wrong regime. This meta-layer adds a layer of adaptive intelligence, boosting the TCN score by enabling swift, coordinated response to regime shifts (e.g. scaling down in chaos, ramping up in favorable trends). It closes the loop for full internal consistency across strategies.
## Microstructure Domain
L8 – Microstructure Model (Orderbook, Tick Flow, Impact)
- Domain: Microstructure
- Primary Role: Supplies fine-grained real-time insight into order book dynamics and trading flow[19]. L8 analyzes Level 1–10 order book depth, tick-by-tick trade flow, and liquidity metrics to detect subtle phenomena like order imbalance, spoofing, or hidden liquidity. Its outputs refine entry/exit timing by gauging order book pressure and expected slippage.
- Key Inputs: High-frequency order book snapshots (top 10–20 levels), tick trade data (executions per second), computed metrics like bid/ask spread and volume imbalance from L0.
- Key Outputs: A set of microstructure features and signals: current spread and spread_z-score, order book imbalance (e.g. imbalance curve across depth), liquidity wall and iceberg detection flags, flow toxicity score (a composite of trade speed, one-sided volume, and depth depletion)[20][21], short-term impact forecast (predicted price impact of a market order)[22], and micro bias (short-term directional leaning). These outputs feed L4 (for slippage and risk) and higher layers to confirm trade entries.
- Core Logic/Model: Combines rule-based feature extraction (e.g. calculate imbalance, detect large hidden orders via abnormal depth changes) and simple learning models for short-horizon predictions (like a regression for impact = f(order size, depth, volatility, toxicity)[22]). It often updates multiple times per bar to capture intra-bar microstructure changes.
- File & Location: core/l8_orderbook_engine.py.
- Config/Wiring: Configurable via config/microstructure.yml (depth snapshot frequency, thresholds for imbalance or wall detection). L8 is wired to share its signals with L9 (latency guard), L10 (slippage model), L59 (trend alignment), and risk modules.
- Health & Logging: L8 logs anomalies such as extreme spreads or sudden depth voids. If L8 fails or data is delayed, a fallback triggers Pine to approximate a few metrics (spread, volume spikes)[23]. The system can continue trading with reduced microstructure fidelity, but new entries may be paused if microstructure insight is lost.
- TCN Impact: Elevates the engine’s precision in execution – a hallmark of institutional systems. By understanding order book conditions (e.g. avoiding entries during liquidity vacuum or detecting spoofing), L8 materially reduces slippage and adverse selection, directly raising the TCN score through improved trade efficiency and safety.
L9 – Spread, Latency, Execution Stress Engine
- Domain: Microstructure
- Primary Role: Acts as a real-time gatekeeper that monitors transaction costs and technical conditions (spread width, network latency, execution stress) to protect the system from entering trades under poor conditions[24]. Essentially, L9 will block or restrict trading when spreads blow out or exchange latency spikes to unsafe levels.
- Key Inputs: Current bid/ask spread (absolute and normalized against historical mean), exchange update timestamps (to calculate data latency), volatility and volume conditions from L0/L1 (for context), and microstructure toxicity signals from L8.
- Key Outputs: Spread_Z-score (how many std devs the spread is above normal)[25], latency measure (ms since last exchange update) and derived latency_z, an overall Execution Stress Score combining spread, volatility and latency[26]. Based on these, it issues control flags: e.g. no_entry (if spread or latency beyond threshold), early_exit_ok (if conditions deteriorate), or fallback_mode trigger (if exchange connectivity lags).
- Core Logic/Model: Simple threshold and linear models: if spread_z > 4, it invokes protective actions (halt entries, tighten stops)[25]; if data latency exceeds a config threshold, it assumes exchange issues and halts new trades[27]. The Execution Stress Score is a weighted sum of spread_z, volatility_z, toxicity, and latency_z to quantify total execution risk[26].
- File & Location: core/l9_execution_guard.py.
- Config/Wiring: Defined in config/microstructure.yml under L9: (spread thresholds, max latency in ms, weightings for stress score). L9 continuously listens to L8 and market data; its flags are consumed by L5 (execution bridge) and L7 (scheduler) to delay or cancel trades.
- Health & Logging: L9 logs whenever it triggers a block (with reasons like “Spread 5σ – entry blocked”). If L9 itself fails, Pine fallback rules apply (e.g. Pine will enforce simple spread and volatility rules[28] to maintain safety).
- TCN Impact: Provides industrial-grade risk gating by preventing trades in unstable microstructure conditions. This significantly lowers tail-risk events (like entering during a spread spike or API lag) and thus improves the engine’s reliability and trustworthiness (key factors in TCN scoring).
L10 – Fee, Slippage & Liquidity Regime Engine
- Domain: Microstructure
- Primary Role: Translates theoretical expectancy into realistic expectancy by accounting for transaction costs (exchange fees, slippage) and current liquidity regime[29][30]. L10 adjusts or vetoes trades that would lose edge after fees or in illiquid conditions.
- Key Inputs: Order parameters (size, intended order type from L4), exchange fee schedules (maker/taker fees), current spread and depth (from L8), short-term volatility (from L1/L2), and liquidity regime classification (high/normal/low liquidity environment).
- Key Outputs: Fee cost per trade (entry+exit fee based on maker/taker decision), expected slippage (in % or ticks, computed from spread, volatility, and depth)[31][32], liquidity regime label (HIGH/NORMAL/LOW/EXTREME determined by depth, spread, volatility conditions)[33], and the fee-adjusted expectancy $E_{\text{adj}}$ (post-cost expected value)[34]. If $E_{\text{adj}}$ falls below a threshold, L10 will mark the trade for cancellation[35]. These outputs inform L4 and Pine (Pine will use fallback expectancy if Python goes down[36]).
- Core Logic/Model: Combines deterministic calculations and simple models: it computes fees based on order type (uses maker fee if limit order likely, taker if market) and even inflates the fee for adverse conditions (fee_penalty for volatility or shallow book)[37][38]. Slippage is modeled as sum of components – half-spread, a volatility-proportional term, and impact (which is order size relative to depth)[31]. A rule-based classifier labels liquidity regimes by analyzing depth, book imbalance, spread and volatility z-scores[33]. Finally, $E_{\text{adj}} = E_{\text{raw}} - (\text{fee}\text{cost} + \text{slip}\text{total})$ is computed[34] and checked against a minimum expectancy threshold.
- File & Location: core/l10_friction_model.py.
- Config/Wiring: Configurable in config/microstructure.yml and config/trade.yml (fee rates, slippage model coefficients k_vol, k_imp[39], and min expectancy thresholds). L10 sits in the execution chain: it receives preliminary trade signals from L4 and outputs adjusted expectancy and cost metrics to both L4 and L5.
- Health & Logging: L10 logs all cost calculations and any auto-cancellation decisions (“Trade X canceled: $E_{\text{adj}}$ below 0”). It monitors if slippage forecasts consistently err (via L6 feedback) to recalibrate coefficients. If L10 fails, trades default to worst-case cost assumptions and Pine uses a simpler fee/slip approximation to decide entries.
- TCN Impact: Ensures that strategies remain profitable after real-world frictions – a necessity for institutional viability. By actively filtering out trades where fees/slippage would erode edge, L10 protects the portfolio from execution drag[30] and significantly improves the engine’s realized Sharpe, thereby elevating the TCN score for real-market performance consistency.
L59 – Microstructure-Driven Trend Alignment Engine
- Domain: Microstructure
- Primary Role: Aligns higher-level trend signals with micro-level order flow conditions. L59 evaluates whether the microstructure is supporting the current trend, acting as a quality filter for trend-following entries. For example, a “strong trend” from L51 is downgraded if order book pressure contradicts it.
- Key Inputs: Outputs from L8 (microstructure pressure vectors, imbalance), trend strength score from L51, trend direction confidence from L52, retracement reliability from L55, and recent slippage measurements from L10.
- Key Outputs: A Microstructure Trend Alignment Score (MAS) quantifying how well order book conditions align with the trend direction[40]. Also flags or adjustments like trend_microstructure_quality (e.g. “good” if order flow confirms trend, or “poor” if order flow diverges)[41]. This score feeds back into L51–L52 and informs L60 (trend execution layer) whether to proceed or hold off.
- Core Logic/Model: A weighted formula combining microstructure indicators: e.g. high bid-side pressure and deep liquidity in the trend direction raise MAS, while widening spreads or order book imbalance against the trend lower it[42]. It may use simple linear weights or even a small ML model trained on historical trend-following success.
- File & Location: core/l59_trend_micro_align.py.
- Config/Wiring: Config in config/trend.yml defines weightings (e.g. w1 for order book pressure in trend direction, w2 for depth support, w3 for spread stability, w4–w5 penalties for slippage and adverse selection risk)[42]. L59 subscribes to L8’s real-time feed and L51’s trend updates; its output is consumed by L60 and L4 (for position sizing adjustments).
- Health & Logging: Continuously logs the MAS and triggers a warning if a trend is marked “Strong” by L51 but MAS is very low (potential divergence). In case L59 fails or data is missing, the system assumes worst-case (trend not confirmed by microstructure) to be safe.
- TCN Impact: L59 raises the engine’s intelligence in handling real-market nuances, preventing blind trend-following. By requiring microstructure confirmation for trend trades[43][40], it reduces false signals and slippage, improving win rates – a direct boost to the TCN “Trust” factor for institutional trading.
L61 – Microstructure Anomaly Detection Engine (MAD)
- Domain: Microstructure
- Primary Role: Scans order book and trade flow in real-time to detect abnormal microstructure events that could indicate manipulation or impending drastic moves[44][45]. L61 flags spoofing, layering, sudden liquidity pulls, toxic flow bursts, and other anomalies that deviate from statistically normal microstructure behavior. These early warnings feed into risk and pattern modules to adapt strategy.
- Key Inputs: High-frequency order book delta streams (changes in bids/offers), imbalance and spread trajectory from L8, recent slippage spikes from L10, noise level from L25, short-term kinematic measures from L21, and volume/tick flow histograms over seconds[46].
- Key Outputs: An anomaly_score (continuous value indicating severity of microstructure irregularity)[47], an anomaly_type label (e.g. “spoofing” if large orders appear and cancel, “liquidity vacuum”, “toxic flow spike”, etc.), anomaly_severity level (low/med/high), and anomaly_direction (bullish or bearish bias of the anomaly)[47]. It may also output a microstructure_shock_flag if a very large aberration is detected[47]. These outputs inform L62 (trend risk) and L4/L85 (risk management) to adjust or hold off trades.
- Core Logic/Model: A hybrid of statistical thresholds and unsupervised ML: e.g. compute z-scores of depth changes, imbalance volatility, and detect outliers beyond set sigma[48][49] (spoof/layer events create unusual depth patterns). Also uses anomaly models like Isolation Forest or One-Class SVM on recent order book state vectors to catch subtle anomalies[50]. Clustering algorithms (DBSCAN/HDBSCAN) might identify micro-regime shifts or clustering of unusual events[50].
- File & Location: core/l61_micro_anomaly.py.
- Config/Wiring: Parameters in config/microstructure.yml (L61:) set detection sensitivity (window lengths, z-score thresholds, Isolation Forest contamination rate, etc.). L61 streams its anomaly outputs to L62 (for trend risk scoring) and broadcasts critical anomaly alerts (e.g. to L85 for emergency exits if needed).
- Health & Logging: Logs all detected anomalies with context (e.g. “Spoofing detected: 5 BTC spoof bid at $19k removed”). Over time, L6 monitors false positives/negatives to recalibrate. If L61 goes offline, the engine loses fine anomaly insight; in response, L62 and L4 will assume higher microstructure risk by default (slowing or reducing position sizes).
- TCN Impact: By detecting market manipulation and irregular activities in real-time, L61 adds a protective layer typical of high-end institutional systems[45][51]. This improves the engine’s Trust factor – it’s less likely to get caught in adversarial situations (like chasing a spoof-induced move), thereby enhancing robustness and maintaining performance under varied microstructure conditions.
L62 – Microstructure → Trend/Pattern Risk Engine (MTR)
- Domain: Microstructure
- Primary Role: Serves as a bridge between microstructure anomalies and the higher-level trend/pattern logic, assessing how detected microstructure events impact the validity of trend or pattern signals[52][53]. In essence, L62 evaluates “Is this trend likely to fail due to microstructure?” or “Does this pattern’s edge diminish because of order flow conditions?”.
- Key Inputs: Anomaly vectors from L61 (types and scores of current anomalies), trend strength from L51, pattern ensemble outputs from L41, breakout signals from L30/L56, retracement reliability from L55, and volatility cycle info from L15[54].
- Key Outputs: A Microstructure Trend Risk (MTR) score that quantifies additional risk to trend continuation due to microstructure factors[55]. Also component risk flags like continuation_risk and reversal_risk (e.g. a high continuation_risk means a trend may not continue despite signals)[56], and an invalidation_warning if an anomaly likely invalidates a pattern setup. These outputs adjust L4’s risk surface (e.g. reduce position size or tighten stops when microstructure risk is high) and inform L68/HLDE logic for final decision.
- Core Logic/Model: Computes penalties to trends/patterns based on anomalies: e.g. if L61 flags a bearish spoof while a bullish breakout pattern is forming, L62 will raise reversal_risk. The MTR score might be a weighted sum of factors: anomaly severity (w1), microstructure pressure conflict with trend (w2), spread instability (w3), upcoming volatility shock likelihood (w4) minus mitigating factors like trend stability (w5) or strong continuation signals (w6)[55].
- File & Location: core/l62_micro_trend_risk.py.
- Config/Wiring: Configured in config/microstructure.yml (L62: weights for each risk factor as per above equation). L62 subscribes to L61 anomaly feed and relevant trend/pattern broadcasts. Its risk outputs are fed into L4’s calculations (as additional risk premium) and into L68 (high-level decision engine) to possibly override trade decisions if risk is extreme.
- Health & Logging: L62 logs whenever it downgrades a signal (e.g. “Continuation pattern X risk-up: microstructure anomaly high”). It relies on L61; if anomaly data is missing, L62 assumes worst-case (e.g. raise risk levels moderately to be safe). Failures in L62 cause the engine to treat microstructure risk as unknown, which typically results in more conservative trading (via fail-safe logic in L4).
- TCN Impact: Strengthens the engine’s risk intelligence by marrying low-level market behavior with high-level strategy. This integrated view is crucial for institutional readiness[45][57] – L62 prevents the engine from charging ahead on a trend signal when subtle market undercurrents suggest caution (e.g. likely to “get run over” by a trap[58]). By averting such hidden pitfalls, L62 directly contributes to a higher TCN score in the Noise and Trust dimensions.
L63 – Microstructure → Expectancy Engine (ME-X)
- Domain: Microstructure
- Primary Role: Adjusts the expected value of trades in real-time based on microstructure conditions[59]. While L3 provides a baseline expectancy from model outputs, L63 fine-tunes that expectancy using order flow insights – effectively answering “Given current microstructure, should we be more or less optimistic about this trade’s outcome?”.
- Key Inputs: Baseline expectancy $E_{\text{base}}$ from L3 (ensemble), microstructure vectors from L8 (imbalance, spread changes), the MTR risk from L62, latest slippage/fee data from L10, short-term volatility bursts, etc.[60].
- Key Outputs: An expectancy_micro_adj (adjusted expectancy value)[61][62] which could be higher or lower than $E_{\text{base}}$ depending on order flow (e.g. raised if strong supportive buying detected, or lowered if order book looks adverse). Also outputs a confidence measure for the adjustment and a microstructure_quality_flag (e.g. “good microstructure” or “poor microstructure” for this trade)[62]. L4 uses the adjusted expectancy for position sizing and risk, and L5/Pine may use it to double-check entries.
- Core Logic/Model: Implements an expectancy correction formula: $E_{\text{adj}} = E_{\text{base}} + \text{microstructure_bias} - \text{slippage_penalty} - \text{anomaly_penalty} + \text{imbalance_support} - \text{volatility_shock_penalty}$[61]. These terms are derived from L8/L61 inputs (e.g. if order book imbalance is strongly in favor, add bias; if L61 anomaly is high, subtract penalty; if L10 expects high slippage, subtract penalty). In effect, it linearly (or via a small regression) adjusts expectancy in light of real-time execution factors.
- File & Location: core/l63_expectancy_micro.py.
- Config/Wiring: Config in config/trade.yml sets coefficients for each adjustment term and conditions when micro-adjustment is applied. L63 is wired right before trade execution: it takes L3’s output and produces the final expectancy that L4 and execution logic use.
- Health & Logging: L63 logs each adjustment in detail (“E_base 1.5%, slippage -0.3%, bias +0.2% → E_adj 1.4%”). If L63 fails, the system defaults to using $E_{\text{base}}$ (less accurate, but safe) and flags that microstructure effects are not accounted for.
- TCN Impact: Elevates the realism and adaptability of the engine’s predictions. By continuously incorporating micro-level feedback, L63 helps ensure the engine’s expectancy estimates remain accurate in live market conditions, directly contributing to higher Confidence in TCN terms. This dynamic adaptation is a hallmark of institutional-grade systems that aim to closely track live trading performance.
## Kinematics Domain
L2 – Deep Learning Momentum/Pattern Recognition Layer
- Domain: Kinematics
- Primary Role: Functions as the primary neural backbone of the engine, extracting high-resolution temporal patterns, momentum signals, and market “kinematics” (speed/acceleration/curvature of price moves) from raw features[63][64]. L2’s deep learning model outputs multi-horizon forecasts and rich motion metrics that inform virtually all higher layers (it contributes ~50% of the engine’s predictive power[64]).
- Key Inputs: A large feature tensor from L0 and L1: e.g. normalized price series, microstructure features, volatility regime posteriors from L1, recent momentum indicators, pattern flags from shallow models, volume flow metrics, etc., typically aggregated into a shape [Batch, Time, Features] such as [32, 240, ~80 features][65][66].
- Key Outputs: Quantile forecasts for future returns (q10, q50, q90) giving probabilistic price direction[67], plus an extensive kinematics vector capturing velocity, acceleration, curvature, momentum persistence, trend energy, directional consistency, and probabilities of expansion/compression or reversal events[68][69]. Additionally, L2 emits classification-like signals such as breakout probability, breakdown probability, continuation vs reversal bias, etc. These outputs feed directly into L3 (fusion engine) and L4 (risk) as primary inputs.
- Core Logic/Model: A hybrid deep architecture with three parallel branches[70]: a Temporal Convolutional Network (TCN) for multi-scale pattern detection (long-range convolution learning consolidations→breakouts, etc.[71]), an LSTM for sequence memory (capturing smooth trends and market cycle context[72]), and a Transformer encoder for non-local attention (identifying cross-timeframe interactions and global context like distribution zones or coil patterns[73]). The outputs of these branches are concatenated into a unified representation[74] and passed to output “heads” – one performing quantile regression for future returns[75], and another computing the kinematic metrics[68]. The model is trained offline on historical data and updated periodically (with L6 monitoring performance drift).
- File & Location: core/l2_deep_motion_model.py.
- Config/Wiring: Model architecture and hyperparameters defined in config/model_l2.yml (TCN dilation depths[76], LSTM hidden size, Transformer layers, feature count). L2 runs each minute (or on each new bar) using the latest window of features from L0. Its outputs are written to a shared memory or database that L3 and others read. If Python fails, a Pine mirror approximates some of L2’s logic (using RSI/EMA filters and proxies for breakout/compression probabilities)[77].
- Health & Logging: L2 logs model confidence and attention entropy for each inference (which L3 may use to assess uncertainty[78]). If L2 encounters an error, the system falls back to Pine’s simpler momentum approximation[77] and triggers L6 to possibly retrain or roll back model weights. Training metrics (loss, validation accuracy) are logged during offline updates.
- TCN Impact: As the primary source of intelligent pattern and momentum recognition, L2 hugely boosts the Noise reduction and Confidence aspects of the TCN score. Its sophisticated ensemble of deep networks is designed for stable, leak-free predictions[79][73], giving the engine an edge in anticipating moves while avoiding overfit noise. This deep learning core is a key differentiator for institutional performance.
L11 – Short-Term Momentum Engine (Fast Response)
- Domain: Kinematics
- Primary Role: Generates ultra-fast momentum signals on the sub-minute to few-minute scale to capture immediate price acceleration and breakout-initiation cues[80]. L11 supplements the slower, learned predictions of L2 with reactive technical signals (e.g. surging momentum or intra-bar thrust) useful for fine entry timing and confirmation.
- Key Inputs: High-frequency price data and recent small-TF candles (e.g. 1m, 3m bars), instantaneous indicators like short-term EMA slopes, Rate-of-Change (ROC), volume spikes, and any microstructure thrust metrics (like order book imbalance changes).
- Key Outputs: A set of short-term momentum features such as mom_fast (fast EMA slope or ROC value), mom_strength (an aggregate strength score), acceleration (rate of change of momentum), continuation_bias (likelihood price will continue in current direction), and thrust_score (measuring the force of an ongoing move)[81]. These outputs feed into L2/L3 as additional features and can gate L5’s execution (e.g. require a minimum momentum to trigger an entry).
- Core Logic/Model: Primarily rule-based technical calculations on the 1m timeframe: computes EMA( fast vs medium ) slope, ROC over last N seconds, recent candle body vs wick relationships (e.g. a large bullish 1m candle = high thrust). L11 might also include a small heuristic model that classifies momentum ignition patterns. It is designed for speed and simplicity – essentially a real-time technical oscillator for momentum.
- File & Location: core/l11_mom_fast.py.
- Config/Wiring: Defined in config/momentum.yml (periods for EMA, ROC length, thresholds for what constitutes “strong” momentum or acceleration). L11 runs every bar (or even more frequently on tick data) and shares its signals to L2 (as additional features) and directly to L3 (for redundancy).
- Health & Logging: L11 logs significant events (e.g. “Momentum burst: mom_strength 0.8 at 10:05:30”). It’s straightforward, so failures are rare; if it does fail, the system can manage without it (L2 can approximate these signals). Its metrics are also used by L6 to correlate with trade outcomes (to tune thresholds).
- TCN Impact: Adds reactivity and timeliness, improving the engine’s ability to catch short bursts and confirm breakouts. This lowers the latency of the engine’s responses and contributes to better Confidence in quickly evolving conditions. In TCN terms, L11 helps ensure the engine’s signals are not just accurate, but also timely enough for real trading.
L12 – Mean-Reversion Engine (Local Reversal Logic)
- Domain: Kinematics
- Primary Role: Detects short-term exhaustion and probable local reversals in price, even during larger trends[82]. L12 provides counter-trend awareness by identifying when the market is overextended on a small scale (potentially generating a quick reversion opportunity or at least a warning to not chase momentum blindly).
- Key Inputs: Classic oscillators and pattern signals: RSI divergence, MACD histogram behavior, Stochastic oscillation, Bollinger Band width expansions, candle wick patterns (pin bars indicating exhaustion), and volume climaxes. These are derived from recent price/volume data on multiple small timeframes (e.g. 1m, 5m).
- Key Outputs: reversal_prob (estimated probability of a local top/bottom forming), pivot_strength (a score for how strong a potential turning point is, based on confluence of signals like RSI divergence magnitude, volume spike, etc.), and overextension_flag (true if price appears overextended beyond typical ranges)[83]. L12’s outputs feed into L3 and L24 (directional conviction) to moderate overly aggressive trend-following and into L57 (trend fade engine) for exit logic.
- Core Logic/Model: A combination of indicator thresholds and simple pattern recognition: e.g. flag a likely reversal if RSI divergence is present (price makes a new high but RSI doesn’t), MACD histogram flips from positive to negative, Stochastic is flattening in overbought territory, and an exhaustion candle (long wick) prints on high volume[84]. These conditions are combined (possibly via a weighted sum or decision tree) to yield a reversal probability.
- File & Location: core/l12_mean_reversion.py.
- Config/Wiring: Settings in config/momentum.yml define indicator lookback periods and thresholds (e.g. RSI > 70 and falling, divergence minimum criteria, volume spike percentage). L12 runs each bar and publishes reversal alerts that can cause L4 to tighten stops or L5 to hold entries.
- Health & Logging: L12 logs occurrences of each condition (like “RSI divergence detected at 14:20”). It’s mostly a deterministic engine; if one sub-signal fails (say RSI data missing), it can still function with others. If entirely down, the system loses a layer of safety but higher layers (L2’s learned reversal signals) cover some of that gap.
- TCN Impact: Contributes to Noise filtering and capital preservation – by catching imminent pullbacks, it prevents the engine from buying tops or selling bottoms. This improves the consistency of returns and lowers drawdowns, positively influencing the TCN risk metrics.
L13 – Multi-Timeframe Trend Consensus Engine
- Domain: Kinematics
- Primary Role: Aggregates trend direction signals across multiple timeframes (from 1-minute up to 1-day) to form an overall trend consensus and confidence[85]. L13 ensures the engine is aware of higher timeframe context – for instance, a long signal on 5m has more weight if the 1H and 4H trends agree.
- Key Inputs: Trend indications on various TFs: short-term momentum from L11 on 1m/5m, medium EMA slopes or LSTM outputs on 15m/1H, pattern directions on 4H/1D, etc. It uses outputs from L2 and possibly Pine’s own simpler trend filters on higher TFs.
- Key Outputs: trend_consensus (final direction: bullish, bearish, or neutral), trend_confidence (0–100% measure of agreement among TFs), and a multi-TF alignment score quantifying how many timeframes are aligned[86]. These feed into L24 (directional conviction) and L4 (volatility scaling of positions).
- Core Logic/Model: For each timeframe, determine trend (e.g. via 50/200 MA crossover or L2’s forecast sign). Then weigh each timeframe’s vote (higher TFs might have larger weight). Compute consensus direction by majority or weighted sum. The confidence is higher if more TFs agree and none contradict strongly. For example, if 1m, 5m, 15m are up but 4H is down, consensus might be weak or neutral.
- File & Location: core/l13_trend_multi_tf.py.
- Config/Wiring: Config in config/trend.yml (timeframes considered, weights for each). L13 runs on bar closes of key timeframes or whenever a new higher-TF candle completes. Its consensus is used by L3 to adjust expectancy (regime_weight factor[87]) and by L5 to possibly filter entries (e.g. require alignment if configured).
- Health & Logging: L13 logs current trend on each TF and the resulting consensus. If data for a TF is missing, it reduces confidence proportionally. Not critical for immediate operation; if L13 fails, the engine defaults to using L2’s single-timeframe view and might accept a bit more risk.
- TCN Impact: Provides Contextual Intelligence – aligning trades with higher timeframe trends is a best practice that improves win probability. By incorporating this layer, the engine avoids counter-trend trades that a human analyst would likely avoid, thereby enhancing the Trust factor and reducing whipsaws (Noise) in TCN terms.
L14 – Structural Momentum Engine
- Domain: Kinematics
- Primary Role: Differentiates structural momentum from noise-driven momentum by ensuring that momentum bursts are supported by meaningful market structure[88]. L14 looks for momentum that coincides with volume surges, volatility pattern changes, or known support/resistance breaks – indicating the move is “structural” (likely to persist) rather than a fleeting blip.
- Key Inputs: Signals from L11 (raw momentum), volatility metrics (e.g. volatility contraction/expansion cycles from L15), volume relative to average, detection of proximity to structural demand/supply zones (could be derived from L23’s local geometry or higher TF S/R levels), and kinematic acceleration data from L21.
- Key Outputs: structural_momentum_strength (a score for momentum that is backed by structure and volume) and pattern-supported_momentum (momentum moves that coincide with pattern confirmations)[89]. These outputs can upgrade or downgrade the generic momentum signals in L2/L11 – e.g. L24 directional conviction will weigh momentum higher if it’s structural.
- Core Logic/Model: Cross-checks momentum events with structural criteria: e.g. if price accelerates upward AND volume is well above average AND it occurs right after a volatility squeeze or at a breakout of a consolidation range, then classify that momentum as structural (assign high strength). If momentum happens on low volume or within a choppy range, mark it as noise-based (low strength). A rule-based scoring or simple ML classification could be used.
- File & Location: core/l14_structural_mom.py.
- Config/Wiring: Config in config/momentum.yml sets thresholds (volume multiple, volatility change) for structural criteria. L14 subscribes to momentum events from L11/L2 and relevant context from L15/L23. Its outputs feed into L19 (momentum refinement) and L24 (conviction engine).
- Health & Logging: L14 logs whenever it identifies a momentum instance as structural. If inputs are missing (e.g. volume data outage), it errs on caution (treat momentum as less structural). Not a single point of failure – if down, momentum signals simply go unrefined (slightly higher false positives).
- TCN Impact: Improves Confidence and Noise rejection by ensuring the engine emphasizes only high-quality momentum. This layer mimics an experienced trader’s intuition of “this move has substance behind it.” By doing so, it raises the probability of success for momentum trades, lifting the TCN score through better reliability of momentum signals.
L15 – Volatility Cycle Engine
- Domain: Kinematics
- Primary Role: Analyzes cyclical patterns in volatility – identifying when the market is transitioning from low volatility to high volatility phases (and vice versa)[90]. L15 predicts if a volatility contraction is likely to lead to an expansion (breakout) or if a volatility expansion is nearing exhaustion. This helps time entries and adjust stops dynamically.
- Key Inputs: Rolling volatility measures (ATR%, realized variance) over multiple lookback periods, Bollinger Band width trends, and historical volatility regimes from L1. It also considers volume changes (volume often contracts during volatility squeezes and spikes on expansion).
- Key Outputs: vol_cycle_phase (categorical: e.g. Contracting, Expanding, Peaking, Collapsing), a vol_squeeze_score (how tightly volatility is compressed relative to norm) and volatility_cycle_strength (confidence in the current phase)[91]. For example, a high squeeze score indicates a likely impending expansion (potential breakout). These outputs are used by L16/L17 (breakout/reversal validation) and L4 (to adjust stop distances or risk).
- Core Logic/Model: Detects patterns like “volatility waves” – e.g. uses moving averages of ATR or BBW to identify up-and-down cycles. Could implement a simple state machine: if volatility has been low and flat for X period (squeeze), mark cycle as contraction; once volatility starts rising above threshold, mark expansion. Also monitors meta metrics like volatility-of-volatility (second-order changes).
- File & Location: core/l15_vol_cycle.py.
- Config/Wiring: Configured in config/volatility.yml (squeeze length, expansion threshold, etc.). L15 runs on each new bar of a base timeframe (e.g. 15m or 1h) and broadcasts cycle phase events (like “Entering expansion”). L30 (breakout engine) and L56 (trend breakout engine) listen to whether a squeeze exists prior to breakouts, etc.
- Health & Logging: L15 logs the current cycle phase and any transitions. If volatility data is erratic (maybe due to bad price data), it may misidentify phases, but L3’s Bayesian fusion can down-weight it if inconsistent. Should L15 fail entirely, other layers will rely on direct volatility values from L1 but lose the cycle context (a minor impact on timing).
- TCN Impact: Adds foresight regarding volatility expansions – crucial for Timing and risk management. By anticipating breakouts or calming periods, the engine can allocate risk more efficiently (enter just as volatility expands, or avoid whipsaws during chop). This forward-looking ability enhances the engine’s Noise discipline and Confidence in timing, boosting the TCN score.
L16 – Breakout Confirmation Engine
- Domain: Kinematics
- Primary Role: Validates whether an apparent breakout is genuine or a likely fake-out[92]. L16 waits for price to clear a key level and then checks for confirming evidence: volume surge, price closing beyond the level, lack of immediate rejection, etc. This protects against false breakouts.
- Key Inputs: Price behavior around breakout levels (from L23’s support/resistance identification or L30’s range breakout signals), volume change (relative to prior bars), retest patterns (does price retest the broken level and hold), wick behavior (long wicks against the breakout direction indicate rejection), multi-timeframe alignment (L13 outputs), and any L15 volatility expansion signal.
- Key Outputs: breakout_valid (bool or probability if the breakout is deemed confirmed), breakout_strength (score reflecting how convincingly price broke and held above the level), and retest_holding (flag if a retest of the level was successful)[93]. These outputs are used by L3 and L24 to increase confidence in continuation trades, and by L50 (execution bridge) to decide if a breakout trade should be executed or skipped.
- Core Logic/Model: Implements a short-term checklist after a breakout level is crossed: price must close beyond the level (not just spike), volume on the breakout bar must be above average, any retest within a few bars should not fall back below the level significantly, and no large opposite wicks should appear[94]. If all conditions pass, mark breakout_valid = true. Possibly uses a score weighting these factors.
- File & Location: core/l16_breakout_confirm.py.
- Config/Wiring: Config in config/pattern.yml (minimum volume surge %, allowable wick size, retest duration, etc.). L16 is event-driven by candidate breakouts (e.g. triggered by L30’s detection of a breakout pattern), then monitors the next few bars. Its confirmation output is fed to L56 (trend breakout engine) and L3 to favor confirmed breakouts in expectancy.
- Health & Logging: L16 logs each breakout attempt and whether it was confirmed or failed (useful for L6 to adjust thresholds). If L16 doesn’t run, the system might take some false breakouts; however L3’s ensemble and L61’s anomaly detection might catch many fakes anyway.
- TCN Impact: Filtering out head-fakes and only acting on real breakouts improves the engine’s hit rate and reduces drawdowns. This directly influences the Trust metric of TCN, as the system avoids unproductive trades common in lesser systems. L16’s confirmation logic is a key contributor to the engine’s professional-grade discipline.
L17 – Reversal Confirmation Engine
- Domain: Kinematics
- Primary Role: Confirms whether a detected reversal setup is truly indicating a trend change or just noise[95]. When patterns or indicators suggest a potential reversal (e.g. bullish morning star or a high L12 reversal_prob), L17 examines follow-through to validate the reversal. This prevents premature counter-trend entries on flimsy signals.
- Key Inputs: Reversal pattern triggers (from L27 Engulfing, L29 Morning Star, etc.), L2’s internal reversal probability, sentiment extremes (if any), L10 liquidity shifts (a sudden widening of spreads or order book flip can precede a real reversal)[96], and possibly external confirmation like a sentiment engine (if integrated).
- Key Outputs: reversal_valid (bool/probability indicating the reversal pattern has confirmed with price follow-through), and reversal_strength (a confidence score of the reversal’s potency)[97]. Provided to L24 (reducing directional conviction in the original trend) and L57 (trend fade logic) to trigger exits or counter-trend trades if strong.
- Core Logic/Model: Similar to breakout confirm but for reversals: e.g. if a bullish reversal pattern (like a morning star) is identified, L17 checks that subsequent price action indeed turns up (price exceeds pattern high), volume supports it, and context (were there prior oversold conditions?) is right[98]. If multiple reversal signs align and price starts a new uptrend on multiple bars, flag reversal_valid. Otherwise, consider it a false signal.
- File & Location: core/l17_reversal_confirm.py.
- Config/Wiring: Settings in config/pattern.yml (criteria for confirming pattern-based reversals: e.g. require a close beyond the pattern’s range, minimum volume). L17 triggers on alerts from pattern engines (L27–L29) and outputs confirmation to risk and fusion layers.
- Health & Logging: Logs each major reversal pattern and outcome (success or failure). If L17 is inactive, the engine might act on unconfirmed reversal signals, potentially increasing whipsaws (which L6 would detect and prompt fixes for).
- TCN Impact: Strengthens the engine’s contrarian moves by ensuring they are taken only when truly justified. This selectivity enhances performance consistency (fewer failed counter-trend trades), thus boosting Confidence and Noise discipline metrics in the TCN evaluation.
L18 – Continuation Model (Impulse → Pullback → Impulse)
- Domain: Kinematics
- Primary Role: Identifies “healthy pullbacks” within trends – the classic impulse-pullback-impulse pattern that signals trend continuation rather than full reversal[99]. L18 flags when a trending move is merely taking a breather (a shallow correction) and is likely to continue, which is an ideal entry opportunity.
- Key Inputs: Price pattern features such as “rising three” or “falling three” candle formations, bull/bear flag recognition from L31, trend context from L13/L51 (to confirm a larger trend is in place), volume behavior (decreasing volume during the pullback is a good sign), and any microstructure support (like L54’s pullback quality).
- Key Outputs: continuation_valid (true if the pullback appears valid for continuation), continuation_prob (likelihood that the next impulse will resume the trend), and continuation_strength (confidence score)[100]. These outputs feed L24 and L55 (reliability of retracement) and ultimately help L5/Pine decide to add to a position or open a new one on the resumption of trend.
- Core Logic/Model: Recognizes specific continuation pattern structures: e.g. the “rising three methods” – after an up impulse, 3 small down candles that stay within the impulse range indicate a continuation[101]. Also uses L31’s outputs (flags, triangles) to generalize. It likely employs a ruleset: small pullback range relative to impulse, low volatility during pullback, no violation of trend support, followed by a strong candle in direction of trend. If criteria met, continuation_valid = true.
- File & Location: core/l18_trend_continuation.py.
- Config/Wiring: Config in config/pattern.yml (max pullback depth %, min impulse strength, etc.). L18 monitors active trends (when L51 trend_strength is high) for qualifying pullbacks. Its signals update L55 (retrace probability) and L56 (breakout engine uses them too).
- Health & Logging: Logs when a continuation pattern is recognized and its outcome (did price indeed continue). If missed, L54’s pullback engine and L31 patterns still contribute similar info, so redundancy exists. Failures here might slightly reduce optimal re-entry points but not critical.
- TCN Impact: Helps maximize profits within trends by confidently stepping back in after minor corrections. This improves the engine’s Return component without adding much risk – a sophisticated behavior that enhances the TCN score by demonstrating the engine’s ability to dynamically scale into trends like a human pro would, thereby increasing the overall expectancy.
L19 – Momentum Refinement Engine
- Domain: Kinematics
- Primary Role: Refines raw momentum signals from earlier layers (like L11 and L14) to produce a more reliable momentum indicator, filtering out noise and false momentum caused by temporary spikes or wicks[102][103]. Essentially L19 turns “noisy” momentum into “momentum with conviction”[104] by smoothing and validating it with volume and structural context.
- Key Inputs: Fast momentum signals from L11 (mom_fast, etc.), structural momentum strength from L14, Bollinger Band width or compression signals (to know if momentum is emerging from consolidation), volume Z-score (is momentum accompanied by high volume), wick ratio (to penalize momentum that’s wick-driven), trend consensus from L13, and regime type from L1 (some regimes naturally produce head-fakes).
- Key Outputs: momentum_refined (a cleaner momentum value/score), momentum_conviction (momentum strength adjusted for volume and quality), false_momentum_flag (true if the raw momentum was likely a head-fake), and momentum_confidence[105]. These refined signals feed L24 (directional conviction) and L51 (trend strength calculation) for more accurate trend assessments.
- Core Logic/Model: Calculates factors like a Conviction Factor (CF) = raw momentum_strength * volume_z * (1 - wick_penalty) to boost momentum that has volume confirmation and low wickiness[106]. Also computes Structural Momentum Boost = structural_momentum_strength * trend_alignment to further elevate momentum that aligns with broader trend[107]. If wick_ratio is high (indicating possibly fake move), it flags false_mom and reduces the momentum score by e.g. 50–80%[108]. L19 likely uses a linear combination or rule-based adjustments as described to output the refined momentum[106][108].
- File & Location: core/l19_momentum_refine.py.
- Config/Wiring: Config in config/momentum.yml (weights w1–w3 for CF, boost, filters, and threshold for what’s considered “false momentum” by wick_ratio)[107]. L19 ingests signals from L11, L14, etc., each tick or bar, and updates global momentum state that L2/L3 can use.
- Health & Logging: Logs whenever it filters out momentum (e.g. “Momentum spike at 12:31 filtered 60% due to long upper wick and low volume”). If L19 fails, raw momentum is still available but less trustworthy; likely the ensemble in L3 will down-weight momentum in that case.
- TCN Impact: By increasing precision of momentum signals (only acting when momentum is “real”), L19 improves trade timing and reduces false starts. This enhances Confidence in short-term trend signals and reduces losing trades caused by noise, thereby positively impacting the TCN score’s reliability component.
L20 – Reversal Refinement Engine
- Domain: Kinematics
- Primary Role: Sharpens the detection of potential reversals, building on the coarse signals from L12 (mean reversion) and pattern engines (like L17 reversal patterns). L20 ensures that reversal trades are taken only when multiple factors align (early, accurate, volume-supported)[109], preventing premature counter-trend positions.
- Key Inputs: A combination of reversal cues: L12’s pivot_strength, L17’s reversal_strength confirmation, classic divergence signals (RSI/MACD divergence values), an exhaustion wick indicator (from L28, e.g. presence of a large pin bar), and volatility cycle context (from L15 – a volatility contraction after expansion can precede a reversal)[110]. Also uses trend consensus from L13 to penalize reversal attempts against very strong trends.
- Key Outputs: reversal_refined (a refined probability or score of an actual reversal happening), reversal_confidence (the system’s confidence in this reversal signal), and countertrend_allowed_flag (which, if true, indicates conditions are met to consider a countertrend trade)[111]. These refine inputs to L24 and risk modules to decide if a reversal entry is justified.
- Core Logic/Model: Computes a Reversal Validity Score (RVS) as a weighted sum of factors such as pivot_strength (L12) and pattern reversal strength (L17) – which add to the score – plus exhaustion signals (like an exhaustion wick) and a volatility regime term for contraction→expansion patterns, while subtracting points if the higher timeframe trend is strongly against the reversal[112][113]. For example: RVS = w1pivot + w2pattern_rev + w3exhaustion_wick + w4volatility_turn - w5trend_consensus_penalty[112]. If RVS exceeds a threshold, mark reversal_refined high and allow the countertrend.
- File & Location: core/l20_reversal_refine.py.
- Config/Wiring: Defined in config/reversal.yml (weights w1–w5 as above, threshold for countertrend). L20 listens to raw reversal alerts and continuously updates the refined score until either a trade is taken or the signal passes. It outputs to L24 (which might reduce directional conviction of the current trend) and to L57 (trend fade engine) to signal likely trend termination.
- Health & Logging: Logs when a reversal signal is upgraded (e.g. “Reversal at 09:45 refined score 0.8 – confidence high”) or dismissed. If down, the engine might take more dubious reversal trades; however L3’s Bayesian models might naturally assign them low confidence. L6 would catch sustained underperformance and flag retraining or parameter tweaks.
- TCN Impact: Improves the Trust* in reversal signals – a notoriously tricky aspect. By filtering to only the most credible reversals, L20 reduces whipsaw trades and complements trend-following parts of the system. This balance and increased hit-rate on countertrend plays contribute to a more stable equity curve, hence a higher TCN score.
L21 – Acceleration Engine (Kinematic Level 2)
- Domain: Kinematics
- Primary Role: Provides a deeper quantitative analysis of price acceleration and higher-order momentum (“jerk”, convexity of motion) beyond the basic first-derivative captured in momentum indicators[114][115]. L21 measures how the acceleration of price is changing, which is vital for anticipating surges or collapses in trend speed. It flags when acceleration sharply increases (breakout impulse) or when it decays (trend losing momentum).
- Key Inputs: Price series (recent bar closes) from L0 to compute derivatives, possibly the output of L2’s internal kinematics for cross-check, and any time-normalized values (to ensure consistent scaling across timeframes).
- Key Outputs: accel_strength (magnitude of acceleration), accel_sign (direction of acceleration, e.g. accelerating upward or downward), accel_confidence (reliability of the reading), jerk_flag (true if third derivative “jerk” spikes, often a strong reversal or breakout sign), and convexity_mode (whether price curvature is convex or concave, indicating accelerating or decelerating trend)[116]. These metrics feed into L24 (conviction) and L55 (retracement analysis) as well as pattern engines that look for acceleration flips.
- Core Logic/Model: Uses finite difference calculations: velocity v = price[t] - price[t-1], acceleration a = v[t] - v[t-1][117], jerk j = a[t] - a[t-1][118]. Also possibly fits a quadratic curve to recent prices to gauge convexity (second derivative sign). It detects events: acceleration_burst (if accel jumps beyond threshold), acceleration_collapse (accel falls rapidly), jerk_spike (if the rate of change of acceleration is extreme, often signaling a very strong impending reversal)[119], velocity_flattening, and convexity_flip (when curvature changes sign)[120]. All mathematical but implemented efficiently.
- File & Location: core/l21_acceleration.py.
- Config/Wiring: Settings in config/kinematics.yml (window lengths for derivative calc, thresholds for what constitutes a “spike” or “burst”). L21 runs every bar and updates global state that pattern engines (like L27 or L34) monitor (e.g. L27 uses jerk in engulfing strength[121], L34 uses acceleration collapse for trap detection[122]).
- Health & Logging: Logs notable events (“Jerk spike detected, potential sharp reversal at 11:20”). This layer is straightforward mathematically; if an error occurs it’s likely data-related (e.g. missing price), in which case it can skip a cycle. Other layers can survive without it short-term, but it’s important for subtle pattern triggers, so L6 would highlight if missed often.
- TCN Impact: Enhances the engine’s Responsiveness – by capturing acceleration and jerk, the engine can react to changes in trend dynamics faster than traditional momentum alone. This extra foresight (especially jerk spikes forewarning reversals) improves the TCN Confidence in timing exits and entries, adding to institutional-grade agility.
L22 – Curvature Engine (Geometric Layer)
- Domain: Kinematics
- Primary Role: Models the geometric curvature of price trajectories to detect rounding of trends or parabolic moves that often precede reversals[123]. Curvature indicates whether a trend is linear or bending – e.g. a trend flattening out (curving downward) can signal a fade, while an upward curvature can indicate a parabolic rally. L22 quantifies this to feed pattern recognition and risk control.
- Key Inputs: Recent price velocities and accelerations (from L21), or directly uses price series to compute curvature formula. Could also incorporate a moving average curve shape.
- Key Outputs: curvature (κ) – a numeric measure of the price path’s curvature[124], curvature_state – a qualitative state like flat, curved upward, curved downward, parabolic expansion or collapse[125], and curvature_confidence (if data fits the curvature model well)[126]. These outputs are used by L55 (retrace probability uses curvature state[127]), L57 (trend fade engine uses curvature flattening in its score[128]), and L27/L28 (pattern detectors use curvature flips in their calculations[129]).
- Core Logic/Model: Calculates curvature as $\kappa = \frac{|a[t]|}{1 + v[t]^2}$ (which for price series means how much acceleration there is relative to speed)[124]. Alternatively, fits an arc to the last N points and measures how curved it is. It then classifies the pattern: “flat” if κ ~ 0, “curved upward” if price acceleration is positive (trend gaining steepness), “curved downward” if acceleration is negative (trend losing steepness), “parabolic expansion” if curvature is high and increasing, etc.[125].
- File & Location: core/l22_curvature.py.
- Config/Wiring: Config in config/kinematics.yml (N for curvature calc, thresholds for categorizing states). L22 runs on each bar using L21’s v and a or directly price differences. It shares curvature metrics to pattern and trend engines that subscribe.
- Health & Logging: Logs curvature value and state transitions (e.g. “Trend curvature flipped downward at 16:00”). If fails, its consumers (L55, L57, etc.) may be slightly less sensitive to trend shape changes. L6 monitors if, say, many trades fail when curvature was signaling something (to possibly adjust usage of κ).
- TCN Impact: Adds a nuanced understanding of trend geometry that static indicators miss. For institutional use, this helps in tightening stops as trends flatten (reducing risk) or holding winners as trends go parabolic (maximizing returns). That dynamic management improves Trust (drawdown control) and Return in the TCN score by smartly reacting to the “curve” of trends.
L23 – Local Geometry Engine
- Domain: Kinematics
- Primary Role: Extracts micro-level geometric patterns from recent price action (candle shapes, swing highs/lows, mini support/resistance levels) as a preprocessing for formal pattern detectors[130]. It effectively summarizes the last few bars’ geometry – e.g. identifies inside/outside bars, pivot points, or minor channel formation – which helps pattern engines and L7’s trade logic.
- Key Inputs: Recent sequence of candles (1m or 5m bars perhaps) with open/high/low/close and volume.
- Key Outputs: A geometry_vector encoding features like body size ratio, body position (top/middle/bottom of range), candle type signature (doji-like, hammer-like, etc.)[131], upper/lower wick strength, presence of inside or outside bars, small range compressions, basic swing highs/lows (higher-high, lower-low etc.)[132]. Also outputs micro_SR_levels (detected short-term support/resistance from recent swings), and local probabilities like breakout_prob_local and reversal_prob_local based purely on the immediate pattern structure[133]. These feed into L30 (breakout engine), L31 (continuation patterns), and give quick pattern context to L3 fusion.
- Core Logic/Model: Rule-based pattern feature extraction: for each of last ~3–5 candles, classify its shape (using body vs wick metrics)[134], find sequences (like three inside bars, or an engulfing shape, etc.), measure swing relationships (higher highs/lows). It likely outputs a fixed-length vector of 20–40 features summarizing this local structure[135]. Some simple logic flags patterns: e.g. an outside bar after a series of lower highs could be start of reversal (raises local reversal_prob).
- File & Location: core/l23_local_geometry.py.
- Config/Wiring: Parameters in config/pattern.yml (e.g. what defines “long wick”, thresholds for body sizes relative to ATR, etc.). L23 runs every bar on the smallest trading timeframe and writes geometry features into a shared structure that pattern engines (L26–L32) consume to identify bigger patterns.
- Health & Logging: Logs notable geometric observations (“Inside bar detected”, “Long lower wick on high volume -> potential absorption”). If L23 fails, pattern detection layers lose some inputs but many have internal logic too; redundancy in patterns ensures graceful degradation (just slightly less precision).
- TCN Impact: Improves the engine’s ability to perceive subtle clues in price action that quants often overlook but discretionary traders use. By quantifying candlestick geometry and micro support/resistance, the engine can catch early pattern formation and fine-tune entries/exits, boosting Signal Quality (reducing noise) and thus enhancing the TCN score.
L24 – Directional Conviction Engine
- Domain: Kinematics
- Primary Role: Fuses signals from multiple momentum and reversal analyses (L19–L23, etc.) into a single directional conviction score representing the engine’s final bias (strong long, weak long, neutral, etc.) before higher-level fusion[136][137]. It is essentially the distilled “opinion” of the technical momentum system about market direction.
- Key Inputs: Refined momentum (L19’s momentum_conviction), refined reversal (L20’s reversal_confidence), acceleration and jerk signals (L21), curvature state (L22), local geometry breakouts/reversals (L23’s breakout_prob_local, reversal_prob_local), trend consensus from L13, and regime from L1 (to possibly temper the conviction in certain regimes)[138].
- Key Outputs: directional_conviction (a continuous score between -1 and +1 indicating bearish to bullish conviction)[139], directional_confidence (magnitude or reliability of that conviction), and explicit bias flags like bias_long or bias_short if conviction passes a threshold[140]. These outputs are fed into L3 fusion (influencing model gating and expectancy adjustment) and into L68 (high-level decision) to guide trade bias.
- Core Logic/Model: A weighted linear combination of inputs: e.g. conviction = w1 * momentum_conviction + w2 * trend_consensus - w3 * reversal_confidence + w4 * accel_strength + w5 * curvature_sign + w6 * local_breakout_prob - w7 * local_reversal_prob[141]. In practice, if momentum is strong and no credible reversal signals, conviction will be strongly in that direction. Conversely, if reversal signals are high, it will pull conviction toward neutral or opposite. L24 essentially balances pro-trend and anti-trend inputs to decide net bias.
- File & Location: core/l24_directional_conviction.py.
- Config/Wiring: The weights (w1–w7 etc.) and scaling factors are set in config/conviction.yml[141]. L24 runs every bar after its input layers update. It publishes the conviction to the global state for use by L3 and decision layers.
- Health & Logging: L24 logs its component inputs and the resulting conviction each cycle (“Conviction +0.7 (bullish): +0.5 mom +0.3 trend -0.1 reversal, etc.”). If it fails, higher layers lose a unified bias input but still have the raw pieces; L3’s ensemble can compensate by reading those individually (with possibly less efficiency).
- TCN Impact: By consolidating numerous technical inputs into one coherent signal, L24 reduces internal disagreement and ensures the engine’s actions have a clear rationale. This improves the system’s Consistency and Transparency (important for institutional trust). A strong, well-founded conviction score helps avoid indecision and whipsaw, thereby positively influencing the TCN metrics for stable decision-making.
L25 – Noise Classification Engine
- Domain: Kinematics
- Primary Role: Classifies the current market condition in terms of “tradability” vs noise, effectively telling the engine when not to trade. L25 evaluates volume, volatility, and microstructure to determine if the market is too choppy/unpredictable (untradable noise) or reasonably clean for signals to work[142][143]. It can block or reduce confidence in signals during highly noisy periods.
- Key Inputs: Low-level metrics that indicate noise: low volume (volume_z from L0), high wick ratio (from L23 or simply candle wicks relative to bodies), Bollinger Band width (narrow BB implies potential randomness if volume low), volatility compression without direction, L21 jerk flags (erratic reversals), L8’s depth (if order book is thin or erratic). Spread_z from L9 and slippage model output from L10 also help gauge execution noise.
- Key Outputs: noise_score (a composite score of market noise level)[144], trade_block_flag (true if noise_score exceeds a threshold meaning conditions are too random to trust signals)[145], and noise_confidence (confidence in this noise assessment). If trade_block_flag=true, L5 or L7 will suspend new entries. The noise score also feeds into L3 to scale down expectancy in noisy regimes and L36 (pattern validity) which penalizes patterns in noisy contexts.
- Core Logic/Model: Calculates noise_score via a weighted sum: e.g. noise_score = w1wick_ratio + w2(1 - volume_z) + w3spread_z + w4jerk_flag + w5(1 - trend_consensus)[144]. This formula captures that noise is high if wicks are large, volume is low, spreads are wide, sudden jerks occur, and no clear trend consensus exists. If noise_score > threshold, mark trade_block_flag true[145].
- File & Location: core/l25_noise_filter.py.
- Config/Wiring: Config in config/trade.yml under NoiseFilter (threshold for blocking, weightings for each component of noise). L25 runs each minute and broadcasts its noise state. L7 (scheduler) and L68 (decision engine) subscribe to possibly halt or skip signals if noise is extreme.
- Health & Logging: Logs noise_score and whether trading is allowed. For instance, “Noise score 0.85 – above 0.8, blocking entries.” If L25 fails, the system defaults to assuming normal conditions (which could be dangerous in true noise). As a safety net, L9’s rules (spread, etc.) and the Regime classification might partially compensate by identifying chaotic regimes.
- TCN Impact: By explicitly avoiding trading in highly noisy, untradable conditions, L25 significantly improves the engine’s risk-adjusted returns (fewer false signals and whipsaws). This elevates the Noise handling* aspect of the TCN rating and shows institutional discipline in not forcing trades during bad conditions – a hallmark of a high TCN score.
L51 – Trend Strength Engine (Multi-Dimensional)
- Domain: Kinematics
- Primary Role: Quantifies the strength of an ongoing trend by synthesizing structural, statistical, and microstructural factors[146][147]. L51 aims to answer “How real and robust is this trend?” Strong trends justify larger positions and looser stops; weak or fake trends warn of caution.
- Key Inputs: Trend line slope or moving average angle (from L12 or direct), classification from L13 (Trending vs ranging), volatility regime from L1 (trends in calm regimes may be smoother than in volatile regimes), multi-TF pattern alignment from L35 (higher timeframe trend support), momentum refined from L19, directional conviction from L24, curvature support from L22 (is trend sustaining curvature), microstructure imbalance from L8 (is order flow supporting the trend), spread/slippage penalty from L10, and noise level from L25[148][149].
- Key Outputs: trend_strength_score (0.0 to 1.0 scale measuring overall trend strength)[150], trend_strength_bucket (categorical: e.g. Weak/Fake, Moderate, Strong, Power Trend)[151], trend_reliability (an estimate of how reliable following this trend has been historically, which might overlap with L53 but on short-term basis), and trend_microstructure_alignment (echo of L59’s info, indicating if microstructure confirms the trend)[152]. These outputs directly affect risk scaling in L4 (e.g. strong trend → allow higher RR or position size) and feed L55 and L56 for continuation or breakout logic.
- Core Logic/Model: Implements a weighted formula for Trend Strength Score (TSS) combining multiple dimensions: trend slope normalized by volatility, momentum/acceleration (kinematic component)[147], curvature support (is acceleration mostly positive), higher timeframe alignment, volume confirmation, minus penalties for noise and slippage[147]. For example: TSS = w1trend_slope_norm + w2kinematic_accel + w3curvature_support + w4HTF_alignment + w5continuation_score - w6noise_penalty - w7slippage_penalty + w8volume_confirmation[147]. Based on TSS, categorize strength into buckets (e.g. >0.85 = “Power Trend”) with intuitive labels[151].
- File & Location: core/l51_trend_strength.py.
- Config/Wiring: Config in config/trend.yml (weights w1–w8, threshold values for buckets[151]). L51 updates each bar on a mid-level timeframe (perhaps 15m or 1h) and writes trend_strength to global state. L4 reads this for dynamic risk (e.g. if strong trend, maybe allow higher take-profit distance)[153]. Also shared with L57 (trend fade engine) to know baseline strength.
- Health & Logging: Logs all components and final TSS for transparency. If any input missing, it still computes with available ones (robust via normalization). If L51 is down, the engine loses a quantitative grasp of trend quality – risk module will then rely on cruder measures (like fixed ATR thresholds). L6 monitors the correlation of TSS with outcomes to refine weighting over time.
- TCN Impact: By rigorously evaluating trend quality, L51 ensures the engine capitalizes on true trends (boosting returns) and steps back during weak trends (avoiding losses), thereby improving both Return and Trust metrics of TCN. It mathematically encodes what human traders call a “strong trend day” versus “chop,” lending the system a crucial adaptive edge.
L52 – Trend Direction Confidence Engine
- Domain: Kinematics
- Primary Role: Measures certainty about the direction of the prevailing trend, separate from its strength[154]. A trend might be strong in magnitude but ambiguous in direction (for example, volatile oscillation). L52 outputs how confident the engine is that the trend is definitively up or down, helping to avoid indecision or quickly flip if needed.
- Key Inputs: Slope stability of trend indicators (e.g. consistency of moving average direction), EMA “cloud” angle and separation (if fast and slow MAs both aligned = high confidence), multi-timeframe direction consensus from L13, momentum bias from L19/L24, reversal probabilities from L20 (which if high, reduce confidence in current direction), volatility expansion (if expanding volatility with no directional resolution, confidence is low), and microstructure conflict signals from L8 (e.g. order flow opposing price trend lowers confidence)[155][156].
- Key Outputs: trend_direction_confidence (scale 0–1 or % indicating confidence in current trend direction)[157][158], trend_direction_stability (a metric possibly capturing how steady the direction has been over recent bars), and trend_direction_drift (if any drift or rotation in direction is observed, e.g. trend turning from up to sideways)[158]. These influence position-holding logic: e.g. L57 (trend fade) and L68 (HL decision) might decide to exit or reduce if direction confidence drops.
- Core Logic/Model: Computes a Trend Direction Confidence Score (TDCS) by weighing factors: e.g. positive contributions from slope_stability (how steadily price has risen or fallen), higher timeframe agreement, inverse of reversal probability (if reversal_prob is high, subtract from confidence), strong momentum direction (adds confidence), pattern alignment direction, and subtracting noise or microstructure conflict[159]. For instance: TDCS = w1slope_stability + w2HTF_direction_consensus + w3(1 - reversal_prob) + w4momentum_direction_strength + w5pattern_alignment_direction - w6noise - w7microstructure_conflict[159]. The result is a numeric confidence.
- File & Location: core/l52_direction_confidence.py.
- Config/Wiring: Parameters in config/trend.yml (weights w1–w7, thresholds for maybe categorizing high vs low confidence). L52 runs alongside L51 and feeds its confidence to L57 (used in trend fade score[160]) and to L68 to decide whether to trust signals or wait.
- Health & Logging: Logs contributors to confidence. If failed, the system might either assume moderate confidence by default or rely on L51 strength solely (which could cause staying in trades too long in ambiguous trends). Over time, L6 ensures L52 correlates well with actual trade success (tuning if needed).
- TCN Impact: Enhances the system’s Consistency* by preventing overcommitment to trends that are uncertain. This metric, essentially a guardrail, ensures the engine doesn’t flip-flop or get whipsawed by unclear trends, thereby maintaining higher average performance (contributing to TCN’s trust/stability evaluation).
L53 – Trend Reliability Engine (Long-Term)
- Domain: Kinematics
- Primary Role: Evaluates the historical reliability of trend-following signals for the current market regime and asset, effectively telling how trustworthy trend signals have been over time[161][162]. It’s analogous to L44 (pattern reliability) but for momentum/trend strategies – used to modulate how much weight to give trend signals in current decisions.
- Key Inputs: Performance logs from L6 capturing outcomes of past trend-following trades (win/loss, expectancy), the time series of trend_strength from L51 and actual returns, volatility regime mapping from L1 (maybe trend works differently in calm vs volatile markets), noise levels over time, and slippage-adjusted returns of trend trades (to see if slippage often eats trend profits).
- Key Outputs: trend_reliability_score (a normalized score of trend model performance, e.g. 0 to 1 where 1 means historically trend signals very profitable)[163][164], trend_reliability_drift (if reliability is improving or decaying recently), and volatility_conditioned_reliability (perhaps separate reliability under different vol regimes). L53’s score feeds into L55 (retrace engine uses it[165]) and L45 meta-controller to potentially suppress trend signals if reliability is low.
- Core Logic/Model: Computes statistics like win rate and average payoff of trend-following trades over a rolling window. Possibly calculates an EWMA of (wins - losses) as in a performance index[166], weighted by conditions (maybe down-weight trades during extreme volatility or noise to get a clearer picture). Might also track the trend strategy’s failure-rate trend (are false signals increasing or decreasing?). Combines these into a reliability metric updated gradually (RRF – recursive reliability factor)[167][168].
- File & Location: core/l53_trend_reliability.py.
- Config/Wiring: Config in config/reliability.yml (window length for performance stats, smoothing factor α for RRF updates[168]). L53 is updated by L6 offline or in near-real-time, and its output is referenced by L4 (for fractional Kelly adjustments perhaps) and L45 (pattern meta-controller) to decide weighting between pattern vs trend signals.
- Health & Logging: L53 logs the reliability score periodically. It relies on correct feedback data from L6; if that pipeline breaks, L53 may output stale info. In worst case, L53 not functioning means trend signals will not be adjusted for long-term efficacy – the engine still works but without this adaptive bias (performance might degrade slowly until fixed).
- TCN Impact: Introduces a meta-learning aspect into trend following – the engine learns and adapts based on its own trend trading success. This self-correcting ability is key for institutional strategies to remain effective over years. It bolsters the TCN Trust metric by demonstrating the engine can detect when its trend model is faltering (and scale it down) or when it’s robust (scale up), ensuring more consistent long-term performance.
L54 – Smart Pullback Engine
- Domain: Kinematics
- Primary Role: Distinguishes “good” pullbacks (brief, controlled corrections in a trend that present entry opportunities) from “bad” pullbacks (deeper corrections that may signal trend failure)[169][170]. L54 provides a quality score for a pullback, used to decide if adding or initiating a position on the pullback is prudent.
- Key Inputs: Kinematic data from L21/L22 (depth and rate of the pullback – shallow vs steep), microstructure info from L8 (does liquidity remain or dry up during the pullback?), volatility state from L1 (high volatility pullbacks are more dangerous), L51 trend strength (a strong trend can tolerate deeper pullback), L25 noise level, and L10’s slippage expectation (a chaotic pullback often has widening spreads).
- Key Outputs: good_pullback_prob (probability that this pullback is merely a trend pause and will resume)[171], pullback_quality (a score 0–1 indicating how textbook-ideal the pullback is)[171], and pullback_reentry_zone (price zone suggestion for re-entry, if computed). These outputs feed L55 (retracement engine uses pullback_quality[172]) and L56 (trend breakout engine looks at smart pullback signals[173]). They also could directly cue L7 scheduler to schedule add-on trades.
- Core Logic/Model: Uses criteria such as: shallow retracement percentage (e.g. less than 38% Fibonacci of impulse), declining volume during pullback[170], low noise (no erratic spikes), maintained market structure (pullback stays above a key moving average or support). Calculates a Good Pullback Score (GPS) combining depth_quality, volume_decay, curvature_resilience (trend curvature didn’t flip), microstructure_support (order book still showing interest) minus penalties for acceleration_conflict (price sharply reversing) and volatility_penalty (if volatility spiked during pullback)[163]. A high GPS yields high good_pullback_prob[163].
- File & Location: core/l54_smart_pullback.py.
- Config/Wiring: Config in config/trend.yml (thresholds for “shallow” depth, volume drop required, etc.). L54 triggers when a pullback is in progress (like when L19 momentum drops while L51 still indicates uptrend). It outputs continuously updated quality until the pullback either turns into a continuation or breaks down.
- Health & Logging: Logs whenever it labels a pullback good or bad (“Pullback quality 0.8 – likely continuation”). If down, L55 still can estimate continuation via pattern logic, but this refined view is lost, possibly resulting in less optimal add-on entries.
- TCN Impact: Allows the engine to intelligently add to winning positions or enter trends at better prices, without blindly buying every dip. By discerning pullback quality, L54 contributes to higher Return (capturing more of trend moves) and better Trust (fewer buys in failing trends), thereby bolstering the TCN score through smarter trade management.
L55 – Retracement Reliability Engine
- Domain: Kinematics
- Primary Role: Determines whether a trend retracement (pullback) is likely to continue the trend or break it. L55 essentially quantifies if the current pullback is just a retracement (trend will resume) or a trend failure in progress. This guides whether to hold through the pullback or exit/hedge early.
- Key Inputs: L54’s smart pullback metrics (pullback_quality), L53 trend_reliability (if trend strategy is historically reliable, trust retracements more)[165], pattern continuation probabilities from L31 (flags/triangles indicating continuation), multi-TF pattern stacking signals from L35 (higher timeframe alignment through the pullback), curvature state from L22 (is trend curvature still supportive), analysis of wick signals from L28 (wick reversal pressure).
- Key Outputs: retracement_continuation_prob (RCP) – probability that this retracement will end and trend will continue[174], retracement_failure_prob (chance the retracement turns into full reversal)[175], and retracement_validation_flag (if true, indicates sufficient evidence that this retracement is a normal one)[176]. These outputs feed directly into L56 (trend breakout engine considers retracement reliability[173]) and L57 (trend fade engine uses them to decide if trend is fading or not). L4 risk might also adjust stop-loss strategy based on RCP.
- Core Logic/Model: Calculates RCP with a weighted linear formula: e.g. RCP = w1pullback_quality + w2trend_reliability + w3kinematic_support + w4volume_behavior + w5multiTF_support - w6wick_reversal_pressure[177]. Essentially, high pullback quality (shallow, low noise) plus strong trend reliability and multi-TF backing minus any strong wick reversal signs yields a high continuation probability[177]. Also sets failure_prob = 1 - RCP or a variant adjusting for neutrality.
- File & Location: core/l55_retracement_reliability.py.
- Config/Wiring: Config in config/trend.yml for weights w1–w6 and threshold for validation_flag. L55 runs during a pullback phase, updating probabilities continuously. Its output is read by L56 and L57 each bar.
- Health & Logging: L55 logs RCP values especially when crossing 50% (e.g. “Retracement likely to hold: RCP 75%”). If a factor input like multiTF_support (from L35) is missing, it can still compute with others. Should L55 fail, trend engines lack an aggregated retracement view – they might then rely solely on pattern signals (a degradation in coordination).
- TCN Impact: Greatly improves how the engine manages open trend trades. By quantitatively assessing retracements, it allows the engine to ride winners longer and cut losers sooner, directly impacting Return (bigger trend wins) and Trust (avoid giving back profit on trend reversals). This adaptive hold/exit behavior is key to institutional-grade trade management and thus a strong positive on the TCN risk-adjusted performance scores.
L56 – Trend Breakout Engine
- Domain: Kinematics
- Primary Role: Detects and confirms continuation breakouts during trends – e.g. breakouts from bull flags, channels, or HTF structure breaks in the direction of the prevailing trend[178]. L56 identifies when a trending market is accelerating into its next leg up or down, integrating pattern and microstructure cues to confirm the breakout’s validity.
- Key Inputs: Trend structure context (from L12/L13 – prior pivot highs/lows and consensus), continuation pattern signals from L31 (flags/triangles indicating a setup), multi-TF stacking info from L35 (alignment of pattern across TFs), L54 smart pullback signals (to know a base was good), L55 retracement reliability (to ensure trend likely to continue)[173], volatility expansion indication from L15 (vol starting to expand as breakout triggers), and microstructure imbalance from L8 (order book pressure in breakout direction)[179].
- Key Outputs: breakout_confirmation_prob (probability the trend breakout is genuine), breakout_strength_score (strength of this breakout move) and breakout_failure_risk (risk of this breakout failing/trapping)[180]. These outputs are fed to L3 and L24 for biasing expectancy upward when positive, and to L60 (trend execution) to decide to enter or add on breakout.
- Core Logic/Model: Computes a Breakout Confirmation Score (BCS) by combining microstructural and volatility signals with pattern confirmations: BCS = w1microstructural_pressure + w2volatility_expansion + w3pattern_confirmation + w4pullback_quality + w5trend_strength - w6slippage - w7noise[181]. A high BCS means: order book pressure supports the breakout, volatility is expanding as expected, patterns confirm (e.g. flag resolved), recent pullback was high quality, in a strong trend, and with low friction from slippage/noise[181]. BCS then maps to breakout_confirmation_prob. Breakout_failure_risk is high if these conditions are not met or contradictory signals exist.
- File & Location: core/l56_trend_breakout.py.
- Config/Wiring: Settings in config/trend.yml for weights and thresholds in BCS. L56 triggers when price approaches a key structural level (e.g. flag upper trendline) and monitors through the breakout event. It sends confirmed breakout signals to L5 (to execute entry).
- Health & Logging: Logs whenever it identifies a breakout (“Flag breakout confirmed, strength 0.9”). If down, trend continuation trades rely on more basic triggers (L30 or manual Pine logic), possibly reducing profitability. However, L3 would still incorporate some momentum thrust from L2.
- TCN Impact: L56 elevates the engine’s ability to compound profits in trending markets by catching continuation breakouts. This increases the Return side of performance. Additionally, by requiring confirmation (and quantifying risk of failure), it avoids chasing every apparent break – preserving capital (boosting Trust*). Together, that improves the TCN score, reflecting an engine that maximizes trend opportunities like a pro trader.
L57 – Trend Fade Engine (Mean Reversion)
- Domain: Kinematics
- Primary Role: Detects when a strong trend is losing momentum or likely to reverse (trend “fading”)[182]. Unlike pattern-based reversal detection, L57 focuses on a gradual erosion of trend strength – e.g. bullish trend that starts to stall out with slowing slope, volume drop, etc. It provides early exit warnings for trend-following trades and potential countertrend entry signals.
- Key Inputs: Trend strength from L51 (to see it peaking then declining), direction confidence from L52 (if confidence starts dropping)[183], L55 retracement reliability (if repeated pullbacks get riskier), microstructure deterioration signs (L8/L59 – order book support vanishing), volume collapse relative to earlier in trend, volatility compression after a long expansion, and presence of exhaustion patterns (like multiple dojis or L12 signals of overextension).
- Key Outputs: trend_fade_prob (probability the current trend is in a topping/weakening phase)[184], trend_exhaustion_flag (true if strong evidence trend is out of steam), and exit_warning_signal (advisory to start taking profit or tightening stops)[184]. These outputs directly inform L68/HLDE to consider an exit or reduction, and L4 to perhaps cut position size. Pine might display an “exit early” alert when exit_warning_signal is true.
- Core Logic/Model: Computes a Trend Fade Score (TFS) by combining factors that indicate decay: slope_decay (trend slope flattening)[185], volume_collapse (significant drop in volume fueling trend)[185], curvature_flatten (L22 shows curvature turning zero or negative)[128], microstructure_conflict (order flow starts opposing trend)[186], volatility_contraction (ATR or BB width shrinking after trend)[186], minus any continuation patterns or acceleration support still present (if continuation signals exist, subtract from fade). TFS = w1slope_decay + w2volume_collapse + w3curvature_flatten + w4microstructure_conflict + w5volatility_contraction - w6continuation_pattern_support - w7acceleration_support[187]. A high TFS yields a high trend_fade_prob.
- File & Location: core/l57_trend_fade.py.
- Config/Wiring: Config in config/trend.yml (weights in TFS formula, threshold for raising an exit_warning). L57 runs continuously during a trend, especially once L51 was high and now starts dropping. It outputs to L68 and L5 (could trigger Pine to allow earlier exit than stop).
- Health & Logging: Logs fade signals (“Trend fade detected: volume down 50%, slope flattening”). If not operational, the engine might ride trends slightly too long until an actual reversal signal hits, possibly giving back more profit. L6 would note if many trades lost profit after a clear fade and prompt adjustments.
- TCN Impact: Enables the engine to gracefully step off a trend near its end, rather than only reacting after a reversal is obvious. This preserves gains and avoids unnecessary drawdown, improving the Trust and Noise* metrics (fewer whipsaw exits) in TCN. Essentially, L57’s early warning contributes to smoother equity curves – an institutional must-have.
L58 – Trend Timing Engine
- Domain: Kinematics
- Primary Role: Predicts when key trend events are likely to occur: continuation, break, acceleration, fade, or reversal[188]. L58 provides time-to-event estimates, effectively adding a temporal dimension to signals (e.g. expecting a breakout in the next 3 bars, or a reversal likely within 10 minutes). This helps L7 (scheduler) and Pine to time entry alerts more precisely.
- Key Inputs: Outputs from various timing-relevant models: pattern timing from L31/L49 (e.g. three-bar continuation patterns give a clue on timing), volatility cycle stage from L15 (how long contraction has lasted), current trend length vs historical average, any cyclical timing indicators (Fourier or seasonality analysis), and possibly statistical time-to-hit data from L83 (expected time to TP/SL).
- Key Outputs: ttf_trend_acceleration (time-to-further acceleration in current trend), ttf_trend_break (estimated time until trend might break), ttf_trend_recovery (if in pullback, time until trend likely resumes), and an overall trend_timing_confidence[189]. These outputs are primarily consumed by L7 (Daily Scheduler) to schedule entries and Pine to issue pre-entry alerts a few bars ahead of expected moves, especially on 5m/15m charts[190].
- Core Logic/Model: Likely uses regression or Gaussian Process models on historical trends to predict durations. For instance, given the volatility regime and current trend strength, how much longer do similar trends usually last? Could also incorporate an EWMA on trend’s slope or momentum peaks to guess when momentum will wane. L58 might also incorporate a local TCN or LSTM that takes recent trend metrics and outputs a probability distribution over time-to-event.
- File & Location: core/l58_trend_timing.py.
- Config/Wiring: Config in config/timing.yml (GP regression parameters, historical window length for learning timing). L58 is updated each bar with revised estimates. L7 queries L58’s output when prioritizing trades (e.g. if a breakout is expected within 10 minutes on BTC, schedule that earlier). Pine’s alert script uses these to post “likely breakout in next 3 bars” messages.
- Health & Logging: Logs predicted times and actual outcomes (to improve model via L6 feedback). If L58 is unreliable or off, the effect is mainly suboptimal scheduling – trades might still happen but not ideally timed. The system can function without it, just possibly with more delay.
- TCN Impact: Adds proactive timing to the engine’s capabilities. Getting timing right is often what separates good from great performance. By anticipating when a trend will accelerate or die out, the engine demonstrates a refined level of control that improves its Noise/Return profile (less time in market = less noise exposure, more catching of moves = higher return). This sophistication boosts the TCN evaluation especially under the “noise-adjusted returns” criteria.
L60 – Trend Execution Bridge (to L5)
- Domain: Kinematics
- Primary Role: Serves as the final processing stage for trend-related signals before handing off to the execution layer (L5). L60 takes all the trend analysis (strength, direction, continuation signals) and decides if a trend-following trade should be executed, modified, or suppressed at the last moment[191][192]. Essentially, it’s a trend-specific gatekeeper to execution, similar to how L50 is for pattern signals.
- Key Inputs: The full trend “complex” outputs from L51–L59 (strength, confidence, reliability, alignment, breakout confirmations, fade warnings, etc.)[193], the current volatility state and any changes from L1/L15, expectancy info from L3 (to see if trend signals are aligning with overall expectancy), risk outputs from L4 (to ensure not violating risk limits), pattern execution signals from L50 (to coordinate if pattern and trend signals conflict), and slippage cost context from L10 (if microstructure is not favorable, perhaps skip marginal trend trades).
- Key Outputs: trend_execution_flag (true if conditions are met to execute a trend-continuation entry)[194], trend_trade_direction (long/short based on conviction), trend_SL_modifier and trend_TP_modifier (any adjustments to default stop-loss/take-profit distances due to trend considerations, e.g. extend TP in strong trend)[194], and a Pine trend bundle (a compact set of ~64 or fewer fields summarizing the trend trade info to Pine)[194]. These outputs go straight into L5 (execution bridge) for enacting trades and to Pine as part of alerts.
- Core Logic/Model: Implements a decision tree or rule checklist[195]: If trend_strength is high AND direction_confidence is high AND microstructure aligned (via L59) AND retracement reliability is good (L55) AND a breakout is confirmed (L56) → allow trend continuation entry (trend_execution_flag = true)[196]. Else, if any are unsatisfactory (e.g. trend fading or micro conflict), it may suppress the trade or even signal to consider the opposite (if fade is strong, might effectively hand off a reversal bias to HLDE). Also ensures trade doesn’t violate risk (if risk says no new trades, it won’t signal).
- File & Location: core/l60_trend_exec_bridge.py.
- Config/Wiring: Configured in config/execution.yml (criteria for allowing trend trades, e.g. all components must be above certain thresholds). L60 is the last stop for trend signals; it sends an “entry package” to L5 containing direction and adjusted SL/TP guidelines.
- Health & Logging: L60 logs the decision logic outcome (“Trend trade allowed” or “Suppressed: micro misaligned”). A failure of L60 could result in trend signals going unfiltered to L5 – L5 would then rely on global signals, which might cause entries that L60 would normally filter out. That could hurt performance, so redundancy is minimal here; prompt fix would be needed.
- TCN Impact: Adds an extra layer of Institutional control by ensuring trend trades are only executed when multiple conditions concur, effectively reducing false starts and aligning entries with ideal conditions[197][198]. This improves both the Trust (due to consistent logic being applied) and the Noise management (fewer bad trades) in the system’s performance, thus enhancing its TCN profile for real-world deployment.
## Pattern Domain
L26 – Candle Classifier Engine (Primary Pattern Layer)
- Domain: Pattern
- Primary Role: Acts as the foundational layer for pattern recognition by classifying individual candlesticks into a feature vector that captures their essential characteristics[199]. L26 itself doesn’t identify complex patterns; it encodes each candle’s attributes (size, wick structure, shape type) and produces “pattern seeds” that higher-level pattern layers (L27–L50) will assemble into full patterns[200]. This provides a standardized input for the pattern detection stack.
- Key Inputs: Raw OHLC data for the latest candle on relevant timeframes (especially the base trading timeframe, e.g. 5m or 15m), ATR or volatility-normalized price range (to classify candle size), wick lengths, volume of that candle, and context like current volatility regime (for normalization).
- Key Outputs: candle_signature_vector – a numeric vector describing the candle (20–40 features) including body size category (micro/small/medium/large/expansion)[201], wick signature (long upper/lower, both, or none)[202], and basic candle type probabilities (hammer-like, doji, thrust bar, etc.)[134]. Also outputs a candle_energy_score (price movement * volume) and pattern_seed_vector – a concise encoding that will be passed to pattern layers as the building block for multi-candle patterns[135].
- Core Logic/Model: Rule-based classification: calculates candle metrics (body_pct, wick_ratio, volatility-adjusted range) and assigns categories: e.g. body classified by ATR multiples[201], wick signature determined by relative wick vs body lengths[202]. Recognizes preliminary shapes (hammer-like if small body with large lower wick, etc.) and encodes those as probabilities instead of binary labels[134] to feed into pattern detection. Essentially, L26 is a feature engineering step turning raw price action into machine-readable signals for patterns.
- File & Location: core/l26_candle_classifier.py.
- Config/Wiring: Config in config/patterns.yml sets thresholds for body sizes (ATR fractions), wick length definitions, etc. L26 processes each new candle close across required TFs and writes its signature to a pattern recognition buffer. Layers L27–L32 consume these candle signatures sequentially to detect multi-candle formations.
- Health & Logging: Logs classification results for each candle (e.g. “Candle 10:15 – medium bull body, long lower wick (hammer-like: 0.8 prob)”). If L26 fails, pattern layers lose their structured input (they might fall back to Pine’s simpler pattern logic, but complex patterns likely won’t trigger). Quick detection and fix would be needed as pattern detection is heavily dependent on L26.
- TCN Impact: Provides the granular inputs that enable high-fidelity pattern recognition. This layer enhances the engine’s Noise filtering by quantifying candle significance; only with these features can the system discern real patterns from random fluctuations. Thus, L26 underpins the Pattern Intelligence domain, directly supporting a higher Pattern skill score in the TCN evaluation.
L27 – Engulfing Family Detection (Reversal Engine 1)
- Domain: Pattern
- Primary Role: Identifies bullish and bearish engulfing patterns and their variants, which are strong 2-candle reversal signals, while filtering out look-alikes that lack proper context[203][204]. L27 classifies not just textbook engulfing (second candle’s body fully engulfs the first’s) but also flags micro-engulfings or likely fake engulfings based on volume and kinematics, giving a nuanced view of this pattern family.
- Key Inputs: Sequence of candle_signature_vectors from L26 for the last 2–3 candles, including body size, relative positions. Volume Z-score for those candles (a true engulfing ideally has higher volume on the engulfing candle), acceleration and jerk info from L21 (to identify a sharp momentum reversal that supports an engulfing), curvature from L22, trend consensus from L13 (engulfings mean more as reversals if trend was established), and noise score from L25 (to discount engulfings in very noisy conditions)[205].
- Key Outputs: engulfing_bull_strength and engulfing_bear_strength (scaled 0–1 indicating how strong a bullish or bearish engulfing pattern is in the current context), engulfing_confidence (overall confidence in the detection), and engulfing_valid_flag (true if a valid engulfing is present and not overridden by noise or context)[206]. These feed into L20 (reversal refinement uses engulfing strength[207]), L3 (as part of pattern engine flags to fusion), and L45 meta-controller (to possibly assert a reversal family dominance).
- Core Logic/Model: Evaluates Engulfing Strength Score (ESS): combines body overlap (did second candle’s body envelop first’s – main criterion), volume confirmation (volume_z positive adds weight), jerk_reversal from L21 (a strong jerk adds weight)[129], curvature_flip from L22 (trend curvature changing sign adds weight)[208], penalizes if pattern is counter to a very strong trend (trend_conflict_penalty)[209], and subtracts noise_penalty for choppy contexts[209]. Applies additional context rules: e.g. bullish engulfing in a prior downtrend = strongly valid; engulfing inside a low-volatility chop = not valid[210]. If ESS exceeds a threshold and context rules pass, sets engulfing_valid_flag true with associated strength[211].
- File & Location: core/l27_engulfing_detector.py.
- Config/Wiring: Config in config/patterns.yml (min body size for engulfing, required volume ratio, etc., plus weights for ESS components). L27 triggers on every new candle close (or when two-candle pattern completes) by reading the last two entries in the pattern buffer from L26. It publishes pattern strength to a pattern-state vector (L32 consolidates these).
- Health & Logging: Logs detection (“Bullish Engulfing at 14:35, strength 0.9, valid”). If misclassifications occur frequently, L6 might adjust thresholds. In case of failure, engulfing patterns won’t be explicitly signaled – other reversal logic (L12/L20) might catch some, but the loss of this explicit pattern reduces reversal detection robustness.
- TCN Impact: Engulfing patterns are high-value signals often used by discretionary traders. Automating their detection with nuance (volume, context) improves the engine’s Pattern Intelligence and reversal timing (Trust and Return). Correctly leveraging engulfings can raise the win rate of countertrend trades, thus positively affecting TCN’s performance and risk metrics.
L28 – Pin Bar / Wick Reversal Detection (Reversal Engine 2)
- Domain: Pattern
- Primary Role: Identifies single-candle wick reversal signals such as pin bars (long wick, small body) which indicate rejection of a price level (e.g. hammer, shooting star), along with related phenomena like exhaustion wicks, stop-hunt liquidity sweeps, etc.[212][213]. L28 focuses on when wicks signal impending reversal due to aggressive rejection.
- Key Inputs: Candle geometry from L26 (especially wick_asymmetry, upperWick vs lowerWick length, body_position)[213], volatility regime from L1 (wick signals differ in high vol vs low vol), liquidity imbalance from L8 (a large wick often corresponds with liquidity being absorbed), slippage model from L10 (extreme wick likely spiked slippage), acceleration collapse from L21 (quick slowdown often with a long wick)[214], and pivot zone proximity (if wick occurs at a known support/resistance from L23, it’s more meaningful)[215].
- Key Outputs: wick_reversal_strength (score of how strong the wick reversal signal is), wick_reversal_confidence, exhaustion_flag (true if the wick likely indicates capitulation/exhaustion of trend)[216], liquidity_sweep_flag (true if pattern looks like a stop-hunt/liquidity grab), and possibly a trapped_traders_signal (if the wick likely trapped breakout traders)[217]. These outputs feed L20 (reversal refinement uses exhaustion_flag etc.), L62 (trap detection uses these flags), and L3/Pine for alerting.
- Core Logic/Model: Recognizes a PinBarScore: uses wick_length_relative_to_ATR (longer wick proportion = higher score), body_position (a pin bar has body at one end of range)[218], volume_confirmation (did volume spike, indicating capitulation)[219], pivot_zone proximity (if wick touches a known S/R, add weight)[219], rejection_velocity (how fast price moved off the low/high, could infer from subsequent candle or intra-bar data), minus noise_penalty if context is choppy[220]. Special states: sets exhaustion_wick_detected if a very large wick after a prolonged move[221]; sets liquidity_sweep_flag if wick likely triggered stops (e.g. quick dip beyond last low then reversal)[221]. Outputs flags and strength accordingly.
- File & Location: core/l28_pinbar_detector.py.
- Config/Wiring: Config in config/patterns.yml (min wick-to-body ratio for pin bar, volume spike threshold, etc.). L28 evaluates each candle close via L26 data. It posts identified wick patterns with strength to the pattern state (for L32 fusion) and directly to anomaly/trap detectors (L34) which use the flags.
- Health & Logging: Logs detection (“Bearish Pin Bar at 10:00, exhaustion_flag true”). If L28 misses signals, the system might not reduce risk on exhaustion as effectively (though L12 might still catch oversold conditions). Overall pattern redundancy exists, but losing L28 would diminish fine-grained reversal capture.
- TCN Impact: Pin bars and wick rejections are classic reversal signs – incorporating them enhances the Pattern Intelligence and agility of the engine. By flagging exhaustion or stop-hunts, L28 helps avoid late entries and encourages timely exits, thereby improving the Noise discipline and drawdown control (Trust) metrics of the system’s TCN profile.
L29 – Morning Star / Evening Star Detection (Reversal Engine 3)
- Domain: Pattern
- Primary Role: Detects 3-candle reversal structures like Morning Star (bullish) and Evening Star (bearish), which signify major sentiment shifts over a short series of bars[222][223]. These patterns involve a three-step sequence (strong trend candle, indecision/doji, strong opposite candle) and are among the most reliable candlestick reversals. L29 accounts for volatility and volume to validate these patterns.
- Key Inputs: Candle signatures from L26 for the last 3 bars, including their relative sizes and positions. Momentum info from L19 (was trend momentum high then collapsed during pattern?), volume on each candle (especially spike on third candle), curvature from L22 (should see convexity flip), micro S/R from L23 (did pattern form at a local support/resistance?), and context from L8 (no heavy opposite flow until the star completes ideally).
- Key Outputs: morning_star_strength and evening_star_strength (scores 0–1 indicating pattern strength)[224], star_reversal_prob (probability this star pattern marks a true reversal)[225], and star_valid_flag (true if pattern meets all criteria for validity)[225]. Provided to L20 and L3 similarly to other reversal patterns.
- Core Logic/Model: Implements pattern-specific logic: For a Morning Star – requires 1st candle a long bearish candle, 2nd candle a small body (often gap down in stocks, here maybe just small range) ideally on low volume, 3rd candle a strong bullish candle closing well into the 1st candle’s body on high volume[226][227]. It likely normalizes for crypto’s continuous nature (no gaps, so uses large second candle wicks or small range as indecision). It scores pattern strength by body size ratios (3rd vs 1st), volume increase on 3rd, volatility drop then re-expansion, and pattern must occur after a downtrend. Similar logic for Evening Star inverted. These criteria combined yield a strength/confidence.
- File & Location: core/l29_star_detector.py.
- Config/Wiring: Config in config/patterns.yml (min size difference, volume change required, permissible wick lengths). L29 monitors sequences of 3 candle signatures via a sliding window. When it spots the pattern, it outputs to pattern state and reversal engines.
- Health & Logging: Logs detection (“Morning Star identified 08:00–08:15, strength 0.85”). If L29 misfires or is down, morning/evening stars might be partially caught by L12 or L27 but with less precision. Given stars often precede big moves, missing them can impact performance – L6 would likely notice pattern misses in logs and prompt re-calibration.
- TCN Impact: Capturing multi-bar reversal patterns like stars further enriches the Pattern Intelligence of the engine. These patterns often mark significant pivot points, so detecting them improves entry/exit timing drastically – adding to the Return (catching new trends early) and Trust (reliability of exits) in the TCN scoring. It shows the engine’s capability to interpret complex price action like a seasoned trader.
L30 – Breakout + Retest Engine (Continuation Engine 1)
- Domain: Pattern
- Primary Role: Identifies range breakouts and subsequent retests – the classic breakout→retest scenario which provides high-probability continuation entries[228][229]. L30 spots when price breaks out of a consolidation or channel and then successfully retests the broken level, indicating a likely continuation of the move.
- Key Inputs: Local support/resistance levels from L23 (recent swing high/low or range boundaries), Bollinger Band or consolidation metrics from L15 (prior squeeze), volume patterns (surge on breakout, moderate on retest), L21 acceleration (did we get an acceleration burst on breakout?), curvature from L22 (should flip upward after breakout), and volatility state from L1 (ensuring breakout is meaningful relative to volatility).
- Key Outputs: breakout_strength (score of how forceful the breakout move was)[230], retest_strength (score of how well the retest held – e.g. shallow dip with low volume = strong retest)[230], continuation_prob (probability of continuation after retest)[231], and continuation_valid_flag (true if conditions for a valid breakout + retest pattern are met)[231]. These outputs feed L56 (trend breakout confirms use them) and L3 for expectancy adjustments upward when a breakout pattern is confirmed.
- Core Logic/Model: Detects breakout by price closing outside a defined range with conditions: prior to breakout, a contraction or range (maybe identified by L31 flags or BB width low)[228]; breakout bar has above-normal range and volume; then monitors retest rules[232]: price should pull back to near the broken level, hold above it (for a bullish breakout) with only shallow penetration, accompanied by lower volume than the breakout (no heavy selling). If retest is successful (maybe multiple criteria: low wick penetration, decent subsequent bounce), mark continuation_valid_flag true. The breakout_strength could be computed from BBW contraction, volume on break, and acceleration[232], and retest_strength from metrics like minimal drawdown on retest, etc.
- File & Location: core/l30_breakout_retest.py.
- Config/Wiring: Config in config/patterns.yml (definition of range – e.g. last N bars within X%; breakout threshold – e.g. close beyond by Y%; allowed retest depth). L30 triggers when a breakout condition is seen, then keeps track of price action for a retest window (maybe next few bars). It then emits pattern confirmation if retest passes.
- Health & Logging: Logs each breakout and whether retest confirmed (“Breakout of $20k confirmed on retest, continuation_prob 80%”). If it fails, the engine might rely on trend engines and momentum to catch moves but could miss the structured entry on retest (meaning slightly worse entry timing or missing second-chance entries).
- TCN Impact: Implements a favorite tactic of savvy traders – waiting for the retest after a breakout. By doing so, the engine dramatically improves its win-rate on breakout trades (since confirmed breakouts with retest have better odds) and avoids many fakeouts. This enhanced selectivity and timing boosts the TCN’s Trust and Noise avoidance metrics, reflecting a more sophisticated and institution-friendly trading style.
L31 – Continuation Patterns Engine (Flags, Triangles, Three-Bar Continuation)
- Domain: Pattern
- Primary Role: Detects classical continuation chart patterns that signal a trend is pausing only to continue: bull/bear flags, pennants/triangles, and multi-bar continuation formations like “Rising Three Methods”[233][234]. L31 provides early confirmation that a consolidation is a continuation pattern rather than a reversal.
- Key Inputs: Geometry from L23 (to identify small range “flag” candles vs prior impulse), outputs of L15 (volatility contraction within pattern), trend consensus from L13 and momentum from L19 (to ensure prior impulse was strong), acceleration/velocity from L21 (impulse vs pullback speed), curvature from L22 (trend curvature aligning), volume pattern (decreasing during the flag).
- Key Outputs: continuation_pattern_strength (score of how robust the continuation pattern is)[235], continuation_confidence (confidence in pattern recognition), and continuation_valid_flag (true if a valid continuation pattern like a bull flag or triangle is present)[235]. These outputs feed into L55 (retrace reliability uses them[236]) and L56 (trend breakout engine uses pattern_confirmation part of BCS), as well as L24 directional conviction (a continuation flag raises conviction in trend direction).
- Core Logic/Model: Recognizes a flag when: after a strong impulse move, price forms a shallow, downward-sloping channel of a few bars with decreasing volatility and volume[237]. Recognizes a Rising/Falling Three by the sequence: big impulse candle, a few small opposite candles, then another impulse candle[238]. Also identifies triangles/pennants by converging highs/lows and contracting range. It computes a Continuation Score (CS) with factors: impulse_strength (prior move size)[239], pullback_shallowness (flag depth small)[239], volatility_contraction (yes/no)[240], volume_pattern (declining volume during consolidation)[240], curvature_alignment (trend curvature not broken)[240], minus any reversal_pressure from L20 signals in the consolidation[241]. If CS is high and pattern visually fits, set valid_flag and strength accordingly[239].
- File & Location: core/l31_continuation_patterns.py.
- Config/Wiring: Config in config/patterns.yml (definitions for flag vs pennant vs triangle, min impulse size, max flag retracement %, etc.). L31 monitors sequences of bars after a momentum burst from L19. It posts pattern detections to a pattern state vector consumed by L32 and others.
- Health & Logging: Logs identified patterns (“Bull flag forming, strength 0.7”). If L31 misidentifies, the engine might confuse a potential reversal as continuation or vice versa; however, backup from L12 and L27–L29 help mitigate. Still, proper function of L31 improves trade confidence significantly.
- TCN Impact: Enables the engine to exploit compound trend moves effectively – catching the second leg of a move is a big profit driver. By systematically finding these continuation patterns, L31 increases trade frequency in favorable conditions (boosting Return) without adding much risk (since these patterns are generally high-probability). This skill elevates the engine’s pattern exploitation ability, contributing positively to the TCN score’s performance component.
L32 – Pattern Fusion (Early Layer Fusion before L50)
- Domain: Pattern
- Primary Role: Aggregates all detected pattern signals from L27–L31 (and others up to L50) into a single pattern-state vector that summarizes the current pattern-based view of the market[242][243]. L32 essentially performs an internal ensemble of pattern indicators, creating a holistic pattern probability distribution that higher layers and models can easily consume.
- Key Inputs: Outputs from all pattern detection engines in the L26–L50 range: engulfing strengths (L27), wick reversal flags (L28), star pattern probabilities (L29), breakout/retest results (L30), continuation pattern strengths (L31), noise classification from L25 (to weigh patterns less in noisy conditions), microstructure risk from L62 (to penalize patterns likely to fail due to anomalies).
- Key Outputs: pattern_state_vector – a vector of probabilities for various pattern outcomes or states (e.g. probability of reversal pattern active, continuation pattern active, compression pattern, exhaustion pattern, breakout pattern, trap pattern, etc.)[243]. It may also provide pattern_directional_bias (whether patterns collectively favor long or short) and an overall pattern_confidence level[243]. Additionally, a Pattern Consolidated Score (PCS) summarizing the net effect of all pattern signals is computed[244]. This fused pattern info is a key input to L3 (fusion engine) and L45 (pattern meta-controller) for final decision weighting.
- Core Logic/Model: L32 forms a vector of length ~15–25 where each element corresponds to a pattern category or outcome (reversal, continuation, breakout, compression, exhaustion, trap, etc.)[243]. It then populates this by combining model outputs: e.g. reversal_prob from patterns = maybe average or max of engulfing, star, wick signals for reversal; continuation_prob from L30/L31 outputs; breakout_prob from L30; trap_prob from L34 (later layer). It also normalizes them into a distribution or keeps them separate but correlated. Then it computes a Pattern Consolidated Score (PCS) as a weighted combination: e.g. PCS = w1reversal_prob + w2continuation_prob + w3breakout_prob + w4retest_prob - w5noise_penalty - w6microstructure_penalty + w7volume_support_factor[245], to have an overall single metric if needed.
- File & Location: core/l32_pattern_fusion.py.
- Config/Wiring: Config in config/patterns.yml defines how pattern outputs map into categories and weights for consolidation (w1–w7 for PCS formula as given)[245]. L32 runs each bar after individual pattern engines have updated. It stores the pattern_state_vector in a global structure accessible by L3 (fusion) and any layer that needs a quick holistic pattern view.
- Health & Logging: L32 logs the pattern probabilities it computes (e.g. “Continuation 70%, Reversal 10%, Exhaustion 5%, …”). If any pattern engine is down, those probabilities go to zero or are estimated as uncertain, which L32 can incorporate by increasing uncertainty. A failure in L32 itself means L3 loses structured pattern info – fallback would be L3 individually polling pattern layers it’s aware of, but integration would suffer.
- TCN Impact: Pattern Fusion provides a unified pattern intelligence input to the decision-making process, akin to how L3 fuses model outputs. This prevents any single pattern signal from being overlooked and allows the engine to account for pattern confluences. For TCN, this improves the Confidence and Noise management* since decisions are based on a broad consensus of pattern information rather than isolated signals. It demonstrates a high level of internal consistency and integration, boosting the engine’s institutional credibility.
L33 – Failed Pattern Detection Engine (Reverse Confirmation Layer)
- Domain: Pattern
- Primary Role: Identifies failed patterns, i.e. instances where a classic pattern setup triggers but then fails to follow through, often leading to an aggressive move in the opposite direction[246][247]. L33 treats pattern failures as potent signals in themselves (e.g. a failed breakout can cause a sharp reversal rally). This layer essentially prepares the engine to flip bias when a well-known pattern fails.
- Key Inputs: The consolidated pattern_state_vector from L32 (to know which pattern was expected), pattern_confidence from L32, breakout/retest status from L30, continuation structure status from L31 (were we expecting continuation?), microstructure signals from L8 (did order flow contradict the pattern?), noise level from L25, momentum from L19 (maybe momentum went opposite to pattern expectation), and refined reversal/momentum signals from L20 and L19 (if pattern fails, often reversal signals spike).
- Key Outputs: failed_pattern_prob (probability that a recently identified pattern has failed)[248], failed_pattern_confidence (confidence in that failure assessment), failed_pattern_direction (the opposite direction likely to materialize post-failure)[248], and failed_pattern_flag (a boolean flag for downstream layers)[248]. These outputs feed L3 (which can swing expectancy if a high-confidence failure is detected) and L34 (trap detection engine, since failed patterns often coincide with traps) and directly to HLDE (L68) which might trigger an opposite trade or tighten stop if pattern failure is flagged.
- Core Logic/Model: Defines failure conditions: e.g. a breakout pattern is considered failed if price met structural conditions for breakout but quickly reversed back into range, or a reversal pattern failed if price continued in the original trend[247][249]. L33 increases failure probability if post-pattern conditions occur: volume collapse after supposed breakout, microstructure thinning on supposed trend continuation, sudden liquidity appearing on opposite side, acceleration flip opposite to pattern direction, or if L24’s directional conviction contradicts the pattern[250]. It computes a Failed Pattern Score (FPS) such as: FPS = w1pattern_confidence (original pattern’s confidence) - w2follow_through_strength + w3opposite_acceleration + w4opposite_volume_pressure + w5slippage_spike_penalty + w6curvature_flip + w7microstructure_reversal - w8initial_breakout_strength[251]. A high FPS means the pattern likely failed and an opposite move is in play.
- File & Location: core/l33_failed_pattern.py.
- Config/Wiring: Config in config/patterns.yml (defining pattern failure criteria and weights as per FPS formula)[251]. L33 watches active pattern signals and monitors actual price reaction over subsequent bars. If criteria met, it outputs failure signals promptly.
- Health & Logging: Logs pattern failures with context (“Failed bull flag → sharp reversal likely”). If L33 is down, the engine might treat failed patterns as normal ones until other signals catch up (a delay in reacting to the failure). That could mean missed opportunities or small losses that could have been wins by flipping. L6 would highlight repeated pattern misfires and push to fix L33.
- TCN Impact: Being able to detect and exploit failed patterns is a mark of advanced strategy (turning losers into winners). L33 improves Noise adaptation and Return by not only avoiding false signals but profiting from them. This contrarian capability significantly boosts the TCN score – it shows the engine can handle adversarial scenarios (like traps) and still thrive, a necessity for high institutional TCN ratings.
L34 – Trap Detection Engine (Stop Hunts + Liquidity Sweeps)
- Domain: Pattern
- Primary Role: Identifies market traps – situations engineered to lure traders the wrong way (stop hunts, false breakouts with liquidity sweeps)[252][253]. L34 finds when large players might be hunting liquidity (e.g. spiking price to trigger stops, then reversing), which are prime opportunities for the engine to take the opposite side or at least avoid the trap.
- Key Inputs: Wick reversal flags from L28 (long wicks often indicate stop hunts)[253], microstructure imbalance flips from L8 (rapid switch from heavy selling to buying or vice versa after a stop run), anomalies from L61 (spoofing or sudden liquidity withdrawal could precede a trap)[254], slippage anomalies from L10 (unusual slippage spike can mean a stop flood), acceleration collapse from L21 (price spiked then halted), curvature flips from L22 (indicative of V-shape moves), volume patterns (volume spike at wick extremes), plus breakout strength from L30 (a trap often has initial breakout that fails).
- Key Outputs: trap_prob (probability a long/short trap just occurred or is occurring)[255], trap_type (long trap = stop hunt down then reverse up, short trap = stop hunt up then reverse down)[256], trap_confidence, and trap_flag (boolean trigger)[256]. These outputs feed L62 (microstructure risk – trap detection raises risk), L3 (maybe reducing expectancy momentarily if a trap detected against position), and HLDE to possibly avoid new entries right after a suspected trap.
- Core Logic/Model: Recognizes two archetypes: Long Trap (Stop Hunt Down) – a strong downward wick followed by immediate recovery, volume spike at bottom, microstructure flips bullish, acceleration rises on recovery, slippage ironically decreases after the wick (less liquidity impact as big player got filled)[257]. Short Trap (Stop Hunt Up) – mirror conditions upward[258]. Computes a Trap Score (TS): w1wick_extreme_ratio + w2recovery_acceleration + w3volume_spike_relative + w4microstructure_flip + w5slippage_reduction - w6trend_conflict_penalty - w7noise_penalty[259]. High TS yields trap_prob high. Essentially, a trap is flagged if an extreme wick occurs with quick reversal and supportive order flow shift[260].
- File & Location: core/l34_trap_detector.py.
- Config/Wiring: Config in config/patterns.yml (wick length threshold as multiple of ATR, min volume spike multiple, etc., plus weights for TS formula). L34 triggers on large wick events (from L28) and evaluates the subsequent bar or two for recovery and flow shift. It then emits a trap signal if pattern fits.
- Health & Logging: Logs trap events (“Long trap detected: stop hunt down at 09:42, trap_flag true”). If not functioning, the engine may fall for traps (taking breakouts that fail) more often, hurting performance. However, L33 and L28 provide partial coverage; L34 is specialized to proactively catch it.
- TCN Impact: Trap detection is a highly valued capability as it demonstrates advanced Risk Intelligence. By sidestepping or inversely trading traps, the engine significantly reduces its losing trades and can capture sharp reversal profits, improving both Return and Trust*. This layer showcases sophistication expected in institutional systems and thus elevates the TCN score with regard to handling complex market microstructure ploys.
L35 – Multi-Timeframe Pattern Stacking Engine
- Domain: Pattern
- Primary Role: Aggregates pattern signals across multiple timeframes to form a hierarchical view of patterns[261][262]. A pattern seen on multiple timeframes (e.g. a bull flag on both 15m and 1H) is far stronger than on one alone. L35 computes combined pattern vectors to quantify such alignment and thus significantly boosts confidence when patterns “stack up” across scales.
- Key Inputs: Pattern_state_vectors or key pattern probabilities from various timeframes. For instance, pattern outputs from a 5m chart and a 1H chart (L32 outputs on each TF) – perhaps scaled or weighted by timeframe importance. It also considers trend consensus (L13) to ensure stacking is meaningful (patterns aligned with trend are weighted more), volatility regime from L1 (to adjust weighting, as high vol might make lower-TF patterns less reliable), and noise per TF (to down-weight signals from noisier small TFs).
- Key Outputs: stacked_pattern_vector – a combined vector representing pattern probabilities after multi-TF integration[263], a pattern_alignment_score (numeric measure of how well higher and lower TF patterns align)[264], and flags like HTF_reversal_flag or HTF_continuation_flag if a strong pattern family is confirmed on high timeframe that should dominate trading bias[265]. These outputs feed L55 (e.g. multiTF_support factor in retracement probability[266]) and L45 (meta-controller uses HTF flags to override lower TF noise).
- Core Logic/Model: Assigns weights to each timeframe’s pattern signals (higher TF = higher weight)[267]. Then computes a weighted sum or average for each pattern probability across TFs to form a stacked vector[263]. Key logic: if a reversal pattern appears on daily and 4h and 1h, and a continuation only on 5m, the stacked output will heavily favor reversal. Recognizes special cases: Multi-TF engulfing alignment (strong reversal)[268], multi-TF flags alignment (very strong continuation)[269], weekly+daily align = “ultra-high conviction”[268]. Likely highlights these via flags or significantly boosting alignment_score.
- File & Location: core/l35_pattern_stack.py.
- Config/Wiring: Config in config/patterns.yml (list of considered TFs, weights, cluster criteria for alignment). L35 receives pattern outputs from all configured TFs (could be through separate instances of pattern detection on each TF or input from Pine/TV for higher TF patterns). It computes outputs every time a high-TF candle closes or on significant events (like daily close). The stacked outputs are used by subsequent layers continuously.
- Health & Logging: L35 logs cases of alignment (“Multi-TF pattern alignment: Daily & 4H bullish flag in sync”). If high-TF data is missing or it fails, the engine loses some conviction cues but can still operate on single-TF signals. However, losing alignment detection may reduce trade quality (no extra confidence on big setups).
- TCN Impact: Multi-TF alignment is a cornerstone of how human experts trade (e.g. aligning daily and hourly signals). Encoding this gives the engine an institutional edge, improving Confidence (trades taken when multiple TFs agree are more likely to succeed) and Return (capturing larger multi-TF moves). This inter-timeframe coherence elevates the engine’s strategy robustness in TCN evaluations.
L36 – Pattern Validity Engine (Context-Aware Validation)
- Domain: Pattern
- Primary Role: Evaluates whether a detected pattern is valid given the current market context, filtering out patterns that might be technically present but unreliable due to external factors (e.g. volatility too high, wrong regime)[270][271]. L36 ensures the engine doesn’t act on every pattern blindly – only those sensible under prevailing conditions.
- Key Inputs: All pattern scores from L27–L35 (reversal, continuation, etc.), L24 directional conviction (to see if pattern aligns or conflicts), L19 momentum_refined (patterns in strong momentum may fail), L21/L22 geometry (acceleration/curvature – if pattern is fighting these, be wary), L10 slippage/spread context (patterns during huge spread spikes are less valid), L8 microstructure signals (spoofing or heavy order flow against the pattern can invalidate it), L25 noise level (patterns in high noise likely false)[272][273].
- Key Outputs: pattern_validity_flag (overall boolean – are pattern signals currently trustworthy or should they be ignored?), pattern_validity_score (a score 0–1 reflecting degree of validity)[274], and adjusted_pattern_state_vector (possibly a version of the pattern vector after down-weighting or nullifying invalid patterns)[275]. These outputs guide L45 meta-controller (suppresses patterns if flag is false) and L3 (could reduce expectancy if patterns are flagged invalid in current context).
- Core Logic/Model: Computes a Validity Score (VS) factoring in context alignment: VS = w1pattern_confidence + w2directional_alignment + w3volume_support - w4noise_level - w5slippage_penalty - w6microstructure_penalty + w7volatility_compatibility[276]. It essentially asks: Are pattern signals coming from a context of supportive volume and trend alignment? And subtracts if noise high, slippage environment bad, microstructure anomalies present[277]. If VS falls below a threshold, pattern_validity_flag = false (meaning ignore pattern-based trades now)[278]. For example, even a good head-and-shoulders pattern might be invalid if volatility is extreme and unpredictable or if regime is chaotic.
- File & Location: core/l36_pattern_validity.py.
- Config/Wiring: Config in config/patterns.yml for weights and the threshold for flagging invalid patterns[276]. L36 runs each decision cycle after patterns are detected, outputting a binary go/no-go for pattern-based logic. Downstream, L45 and HLDE heed this: if invalid, pattern signals might be ignored or heavily down-weighted in decisions.
- Health & Logging: Logs when it invalidates patterns (“Pattern signals suppressed due to extreme volatility (VS=0.2)”). If L36 is inactive, the engine might chase patterns in bad contexts, likely increasing false positives (which L6 would catch as a decline in pattern strategy performance and push adjustments).
- TCN Impact: By incorporating situational awareness, L36 prevents the engine from making naïve pattern trades when context suggests they won’t work – a nuance that improves Noise filtering and Trust*. This context-filtering raises the engine’s quality bar to institutional level (no overfitting to patterns irrespective of conditions), thereby positively reflecting in TCN’s evaluation of strategy discipline and adaptability.
L37 – Pattern Structure Predictor Engine
- Domain: Pattern
- Primary Role: Forecasts the next likely pattern that might form by analyzing current partial formations and market trajectory[279][280]. L37 is proactive – instead of just identifying completed patterns, it predicts if, for example, a flag is likely to form, or a head-and-shoulders is in development. This helps higher layers anticipate and position for patterns before they fully emerge.
- Key Inputs: Current state of partial patterns: e.g. L31’s identification that two flag poles are in place but flag not completed, L23 geometry (are we seeing the first two candles of a morning star?), volatility compression clues (L15 says contraction starting could precede triangle), microstructure ebb/flow changes (L61 signals irregular behavior that precedes patterns), L24 directional conviction trends (if conviction is dropping, maybe a reversal pattern upcoming), etc.[281].
- Key Outputs: pattern_forecast_vector – a probability distribution over pattern types that are likely to form next (breakout, retest, reversal, flag, triangle, exhaustion)[282], pattern_shift_prob (probability that the market is about to shift pattern regime, e.g. from trending to ranging), and early_warning_flags (like “upcoming_breakout_prob”, “upcoming_reversal_prob” etc. from L37’s distribution)[282]. These outputs feed L38 (failure anticipation) and L50 (execution bridge might prepare for potential entries), and L7 scheduler can hold off or expedite trades if a pattern is forecasted (like wait for a predicted breakout rather than entering right before it).
- Core Logic/Model: Likely a lightweight sequence model (small LSTM or TCN) as indicated[280] that takes as input recent pattern indicators (from L26–L36, L61, etc.) and outputs probabilities for upcoming pattern types. It might also incorporate a simple rule: e.g. after a long trend run with high L57 fade signals, forecast a reversal pattern forming (morning star or H&S). If microstructure anomalies increase, forecast trap pattern. The model outputs a distribution: e.g. 60% chance of breakout pattern soon, 20% chance of reversal, etc.[282].
- File & Location: core/l37_pattern_predictor.py.
- Config/Wiring: Config in config/patterns.yml for any threshold to raise early warnings (e.g. only alert if a pattern prob > 0.7) and choice of model (LSTM parameters if used). L37 likely updates continuously and posts forecasts to a short-term forecast bus. L38 uses these forecasts as an input to predict pattern failure ahead of time. L50 might use an upcoming_breakout_flag to prepare Pine signals.
- Health & Logging: Logs predictions (“Pattern forecast: 50% triangle, 30% flag in next ~5 bars”). As a predictive layer, errors here are expected occasionally; it’s supplementary. If down, the system loses some foresight but core detection still covers eventual patterns – less proactive but still functional.
- TCN Impact: This is a cutting-edge feature that anticipates market structure – a big plus for Timing and Noise avoidance. By readying the system for likely scenarios, L37 helps avoid being reactive-only. This forward-looking intelligence, even if not perfect, is indicative of an advanced system and can improve performance modestly but consistently. In TCN scoring, it reflects in improved Confidence (the system often “expects” what happens, reducing surprises) and contributes to shorter reaction times, which is valued.
L38 – Pattern Failure Anticipation Engine
- Domain: Pattern
- Primary Role: Proactively predicts the failure of a pattern before it completes, complementing L33 (which detects failure after it happens)[283][284]. L38 processes early warning signs that a currently forming pattern (or one that just triggered) will likely fail, allowing the engine to avoid entering or to prepare to reverse. This provides a defensive edge by catching failures earlier.
- Key Inputs: Pattern forecast from L37 (if L37 foresees a pattern but environment is shifting, that pattern might fail), outputs from L30/L31 (if a breakout started but L38 sees issues), L20 reversal signals creeping in (e.g. as a continuation pattern forms, reversal indicators appear – bad sign), L24 conviction conflict (if pattern suggests long but conviction dropping), L10 slippage risk (rising slippage suggests instability), microstructure mismatch from L62 (microstructure not supporting pattern), and volatility signals from L15 (sudden expansion against expectation).
- Key Outputs: pattern_failure_forecast (probability that the currently developing pattern will fail)[285], pattern_failure_confidence (confidence in that forecast), and failure_early_warning_flag (urgent signal if probability is very high)[285]. These outputs are used by L50 (execution bridge can decide not to execute a pattern trade even if L50 gets a signal, due to early failure warning) and by HLDE to lean opposite if strong.
- Core Logic/Model: Similar to L33’s logic but in predictive mode: calculates a Failure Prediction Score (FPS2) using factors available before failure fully materializes[286]: microstructure_mismatch (L61 anomalies that often presage failure)[287], volume_collapse (pattern forming but volume drying up unexpectedly)[287], slippage_risk (L10 shows rising friction, pattern likely shaky)[288], directional_conflict (L24’s bias opposes pattern’s implication)[288], acceleration_collapse (momentum waning when it shouldn’t)[289], curvature_flattening (trend losing shape during supposed continuation)[289], wick_pressure_against_pattern (L28 shows wicks counter to pattern direction)[289], minus structural_momentum (if momentum still strong in pattern’s favor, subtract). Weighted sum of these yields a forecast; if high, raise failure warning.
- File & Location: core/l38_failure_predictor.py.
- Config/Wiring: Config in config/patterns.yml for weights in FPS2 formula[287] and thresholds for issuing warnings (maybe only if probability > 80%). L38 actively listens to pattern formation processes (like during a breakout or flag formation) and outputs warnings in real-time. L50 checks this before executing any pattern-based entry.
- Health & Logging: Logs whenever it issues a warning (“Early Warning: Ongoing triangle likely to fail, prob 85%”). If L38 is off, the engine relies on L33 after-the-fact detection, which is still effective but a bit late. Early avoidance is always better.
- TCN Impact: This engine is about preventing losses before they happen – a huge plus for institutional performance. By reducing false starts even further, L38 enhances the Noise resilience and Trust in the engine (fewer whipsaw trades). It showcases the engine’s ability to dynamically adapt intra-pattern, a sophistication that would reflect in a higher TCN score through improved Sharpe and lower max drawdown.
L39 – Pattern Volatility Overlay Engine
- Domain: Pattern
- Primary Role: Adjusts pattern interpretations based on the volatility regime to avoid misreading patterns that behave differently in different volatility contexts[290][291]. For example, some continuation patterns are unreliable in low-volatility grinding markets, or reversal patterns might need extra confirmation in high-volatility spikes. L39 essentially weights or tweaks pattern signals using volatility context.
- Key Inputs: Current volatility regime from L1 (Calm/Trend vs Volatile/Panic), volatility cycle phase from L15 (expansion or contraction currently)[292][293], pattern_state_vector from L32, and pattern forecast from L37.
- Key Outputs: volatility_adjusted_pattern_state_vector – the pattern probabilities after applying volatility-based multipliers[294], and volatility_pattern_multipliers (the set of multipliers used for each pattern type in the current vol regime)[294]. Essentially, it provides a “corrected” set of pattern signals that L3 and others then use.
- Core Logic/Model: Implements rules like: If Low Volatility: boost reversal pattern significance (because big reversal patterns in quiet markets are rare but meaningful), weaken continuation patterns (trends in low vol might not follow through strongly)[295]. If High Volatility: boost continuation patterns (since breakouts in high vol often run far) and penalize small reversal patterns (as they may be noise in high vol)[296]. If Vol Expansion: boost breakout patterns (market breaking out of a squeeze = strong)[297]. If Vol Collapse: boost flag/triangle continuation patterns (coils in collapsing vol often precede resolution)[293]. The engine likely has a matrix of pattern type vs volatility regime adjustments which it applies to pattern probabilities.
- File & Location: core/l39_pattern_vol_overlay.py.
- Config/Wiring: Config in config/patterns.yml (the exact multipliers for each pattern type under each regime). L39 runs post-pattern-detection and multiplies the probabilities or scores accordingly, then updates the pattern state (or passes to L32/L45).
- Health & Logging: Logs adjustments (“Low vol regime: continuation patterns downweighted 30%”). If not working, patterns are treated uniformly regardless of vol, which might reduce accuracy in extreme regimes. This is a refinement layer, so its absence would be subtle but present in performance.
- TCN Impact: Tailoring pattern strategy to volatility regime prevents systematic bias (e.g. not over-trading patterns in wrong environments). This adaptiveness increases the Confidence and Noise control of the engine. It basically ensures pattern efficacy stays high across regimes, supporting a better TCN profile (especially under volatile conditions where lesser systems falter).
L40 – Pattern Kinematic Alignment Engine
- Domain: Pattern
- Primary Role: Verifies that detected chart patterns are backed by corresponding kinematic signals (momentum/acceleration alignment)[298][299]. A pattern “matters” more if the underlying price motion supports it. For example, a bull flag is truly significant if momentum was strong into it and remains supportive. L40 gives a final stamp of approval by checking price motion consistency with pattern structure.
- Key Inputs: The collective pattern vectors from L32–L39 and their pattern vectors, plus velocity/acceleration/jerk metrics from L21, curvature state from L22, local geometry from L23, and directional conviction from L24. Essentially, it looks at whether momentum and geometric movement agree with the implications of the pattern.
- Key Outputs: pattern_kinematic_alignment (score indicating how well patterns and motion align), and kinematic_approved_pattern_vector (perhaps a filtered pattern vector where only patterns with good kinematic support are emphasized)[300][301]. These outputs inform L3 and L45 – e.g. if a pattern lacks kinematic alignment, the meta-controller might suppress acting on it.
- Core Logic/Model: Computes a Kinematic Compatibility Score (KCS): for each major pattern signal, check directional_alignment with L24 (pattern is bullish and conviction is bullish? add weight)[302]; accel_support (if continuation pattern, is acceleration rising? if reversal pattern, was there a jerk spike? etc.)[303]; jerk_confirmation (e.g. a sharp jerk could confirm a V-reversal pattern)[303]; curvature_consistency (does price curvature shape match the pattern’s expectation – e.g. rounding top pattern should have convex curvature)[304]; geometric_support (did local swing points from L23 confirm pattern’s shape)[304]; subtract pattern_conflict if any pattern contradicts motion. If KCS is high, pattern_kinematic_alignment is strong. L40 may then output an adjusted pattern set focusing on those patterns.
- File & Location: core/l40_pattern_motion_align.py.
- Config/Wiring: Config in config/patterns.yml (weights for KCS factors). L40 runs after patterns are detected, as a final filter. It issues alignment scores that L45 uses to potentially reject patterns with poor alignment (pattern_conflict flag in KCS equation)[305].
- Health & Logging: Logs alignment decisions (“Head-and-Shoulders detected but momentum rising – not aligned, KCS low”). If L40 fails, the system might act on some patterns that are just optical illusions without momentum, possibly lowering success rate. Over time L6 might catch that and call for improvements.
- TCN Impact: By ensuring that patterns are not just visually present but actionable (confirmed by the underlying momentum), L40 filters out low-quality signals, thereby improving the engine’s Signal-to-Noise ratio. This directly enhances performance stability (Trust) and lowers false signals (Noise), both crucial for a high TCN score. It reflects an institutional-grade nuance: merging price action with quantitative motion analysis for decisions.
## Expectancy & Fusion Domain
L3 – Fusion Engine (Ensemble, Bayesian, XGB, MoE)
- Domain: Expectancy & Fusion
- Primary Role: Serves as the decision-making “senate” of the engine, fusing all predictive model outputs into a unified trade signal: expected value (expectancy) of a trade, with associated confidence and uncertainty[306][307]. L3 weighs inputs from deep models (L2), pattern engines (L26–L50), sentiment or other externals (if any), and forms a single coherent view (E, probability of success, etc.) that drives whether to go long, short, or stay out.
- Key Inputs: Predictions from L2 (quantile forecasts, breakout/continuation probabilities, kinematics)[308], regime info from L1 (regime posterior, forward vol)[309], microstructure signals (L8–L10 outputs like liq_regime, slip_total)[310], pattern ensemble flags (L32 outputs)[310], sentiment or alternative data signals (if present, e.g. from L74–L80 domain), and any other model outputs available. Essentially, all layers up to L50 funnel key outputs here.
- Key Outputs: expectancy (E) – the base expected value per trade (e.g. in % of capital)[311], adjusted expectancy (E_adj) – expectancy adjusted for confidence and regime (as final signal strength)[87], confidence – the overall confidence level in the signal[312], uncertainty – the modeled uncertainty (variance) in predictions[313], directional bias (long or short bias with some strength), volatility-adjusted expectancy (if separate), and perhaps error condition flags if models disagree strongly[314]. These feed directly into L4 (risk engine) for position sizing and into L5 for execution (via JSON to Pine)[315].
- Core Logic/Model: A multi-model ensemble approach: (1) An XGBoost regressor that takes quantile spreads, kinematic features, vol regime, etc., to predict expectancy and probability of trade success[316]. (2) A Bayesian ensemble that treats outputs of various sub-models as observations to compute a posterior distribution for expectancy (giving mean μ and variance σ²)[317][318]. (3) An HMM-based Mixture-of-Experts gating that chooses which model’s signals to emphasize based on regime (e.g. in calm markets, simpler models; in trending, momentum models; in volatile, maybe pattern models)[319]. L3 combines these: The XGB provides a point estimate, Bayesian ensemble provides uncertainty and adjusts for model disagreement, and MoE ensures the right experts are weighted given current regime[319]. Additionally, L3 computes expectancy per trade via standard formula E = P(win)AvgWin - P(loss)AvgLoss (P(win) from models, avg win/loss from L2 quantiles)[311]. It also cross-checks model outputs correlation to avoid redundant signals dominating[320]. The final adjusted expectancy E_adj = E * C * regime_weight (scaling by confidence and perhaps regime risk appetite)[87].
- File & Location: core/l3_fusion_engine.py.
- Config/Wiring: Configuration is complex: config/fusion.yml might contain XGB model parameters (trees, features), Bayesian prior settings, mapping of regimes to expert weights, etc. L3 runs each decision cycle (e.g. every minute) after updating inputs, and publishes its outputs to a central decision object that L4 and L5 read. It also likely references a global config for risk/regime weighting (e.g. risk-off regimes reduce E_adj via regime_weight).
- Health & Logging: L3 logs the components of its decision (each model’s output and weight, combined expectancy, uncertainty)[321][322]. If one sub-model fails (e.g. XGB output NaN), L3 can fall back on Bayesian combination of remaining, albeit with higher uncertainty flagged. If L3 fails entirely, the engine loses its brain – Pine fallback logic (simplified expectancy from tech indicators[323]) would take over, but performance would degrade significantly. As such, multiple safeguards (like MoE gating out a bad model or defaulting to Pine majority vote) exist to handle partial issues. L6 monitors L3’s output vs realized outcomes to continuously refine calibration.
- TCN Impact: L3 is a major contributor to Confidence and Noise reduction. By fusing diverse predictors and quantifying uncertainty[324][325], it produces more stable and reliable signals than any single model could – a key reason the engine targets institutional-grade reliability. L3’s ensemble approach also exemplifies Transparency (via correlation matrix and feature importance logged[326][327]) which is valuable for institutional trust. Altogether, L3 significantly boosts the engine’s overall TCN score by maximizing predictive accuracy and gracefully managing uncertainty.
L7 – Daily Scheduler / Trade Optimization Layer
- Domain: Expectancy & Fusion
- Primary Role: The portfolio-level planner that decides which trades to take and when across a universe of assets each day[328][329]. L7 ranks trade opportunities, schedules entries to respect capital and concurrency limits, and optimizes timing for maximum daily expectancy. It ensures the engine behaves like a portfolio manager rather than just a signal generator.
- Key Inputs: Expected trade signals for each asset from L3 (expectancy E, confidence, direction) for the current cycle, risk metrics from L4 (position sizes, volatility regimes), L6 feedback on model quality (if certain models are flagged as drifting, maybe skip some trades), correlation and diversification data from L72 (which assets are highly correlated) to avoid over-concentration, the current universe list from L0 (which assets are in play), and any external constraints (max concurrent trades, sector exposure, etc.).
- Key Outputs: A schedule of trades for the day (or upcoming session): essentially a prioritized list of trade candidates with timing. Specifically: ranked trade candidates with scores[330], planned entry times/windows (maybe if an opportunity should wait for a certain time or condition), and tasks such as risk adjustments (if risk budget nearly used, slow new trades). Also may output a “next best trade timing” advisory to Pine (like suggesting an optimal bar to execute a batch of entries)[331]. L7’s decisions manifest as orchestrated entries (sent to L5 for execution) and possibly an internal log of scheduled vs unscheduled trades.
- Core Logic/Model: Gathers all assets’ signals and filters by thresholds (must meet expectancy and confidence cutoffs)[332]. Computes a candidate Score for each: for instance, Score = E_adj * f_position * trend_energy * regime_validity (as given in docs)[333]. Then sorts by score. It will only consider a trade if E_adj > threshold, confidence > min, uncertainty < max, and volatility not extreme for that asset[334]. Next, it applies portfolio constraints: e.g. do not take 5 trades if all are highly correlated (L72 data helps limit to best among correlated groups). Uses Monte Carlo or greedy algorithms to maximize total daily expectancy under constraints (like a knapSack problem: maximize sum of chosen trades’ expectancy)[335]. It may simulate thousands of combinations (Monte Carlo paths) to choose the set that gives best risk-adjusted portfolio expectancy[335]. Also, it staggers timing: might schedule highest ranked immediately, others spaced to avoid execution overlap or during predicted optimal windows (using L58 outputs for volatility windows perhaps).
- File & Location: core/l7_scheduler.py.
- Config/Wiring: Config in config/portfolio.yml (max concurrent trades, sector limits, risk budget per day, scheduling rules). L7 runs perhaps once per day or continuously updates as new signals come (depending on style). It intimately interacts with L5: it sends signals to execute at certain times and monitors their completion. It also feeds back into L6 (reporting if scheduled trades deviated from plan or if daily targets hit).
- Health & Logging: L7 logs chosen trades and rationales (“Selected BTC long at 13:00, Score 2.5, expected value X; Skipped ETH long – correlation high with BTC”). If L7 fails, the engine would revert to taking every qualifying trade signal, which may lead to overtrading or too many correlated positions – not catastrophic immediately but suboptimal and potentially risky. Thus, robust operation of L7 is crucial for capital efficiency and risk control; its failure would degrade performance and raise risk.
- TCN Impact: This layer turns a collection of good signals into a coherent portfolio strategy, which is essential for institutional adoption. By optimizing trade selection and timing, L7 dramatically improves Return (by focusing on best opportunities) and Trust (by controlling risk and avoiding redundant exposure). In the TCN framework, L7’s contribution is reflected in improved overall profit factor and risk-adjusted metrics, pushing the engine closer to the TCN-10000 institutional benchmark through intelligent resource allocation.
L66 – Expert Fusion Engine (Multi-Domain Fusion)
- Domain: Expectancy & Fusion
- Primary Role: Integrates the high-level outputs from various domains (Trend, Pattern, Microstructure, Volatility, Regime, Risk, RL hints) into a consolidated Master Action Vector (MAV) that represents the final recommended action (e.g. go long, short, flat) and its strength[336][337]. L66 is like a second-stage fusion that sits above L3, ensuring that specialized domain “experts” (trend complex, pattern complex, etc.) are all considered in the ultimate decision.
- Key Inputs: Summarized signals from major domain clusters: trend complex output (like L60’s trend_execution_flag or trend bias), pattern complex output (L50 or L32), microstructure complex signals (L61–L63 composite), regime info (L64’s state), risk posture (L4’s current risk allowances), and maybe RL cues (L82’s bias suggestions). Essentially an array of inputs like [trend_strength, pattern_bias, micro_risk_flag, vol_regime, expectancy (L3), risk tolerance, etc.].
- Key Outputs: master_action_vector – a vector whose components could be e.g. [P(Long), P(Short), P(No-Trade)] or a continuous scale representing the preference to go long vs short[338]; master_confidence in that action; long/short strength measures (like how strongly long or short)[338]; neutrality probability (chance that no action is best)[339]; action_entropy (level of internal disagreement)[339]. MAV is consumed by L67 (consistency check) and L68 (HL decision engine) as the primary input.
- Core Logic/Model: Uses an ensemble-of-ensemble approach: possibly an XGBoost, Gaussian Process, or neural Mixture-of-Experts (hence “Expert Fusion”)[340]. Each domain’s output can be considered an expert’s recommendation. L66 likely uses a small ensemble or gating network to weight these recommendations appropriately. For example, if patterns and trend both say long strongly, MAV will be heavily long. If they conflict (one long, one short), MAV might be neutral with high entropy (i.e. no clear action)[341]. It might incorporate regime-conditioned weighting (in trending regime, trust trend expert more; in volatile regime, trust pattern/reversal expert more, etc.). The outcome is essentially similar to L3’s output but at an even higher abstraction level, balancing entire subsystems.
- File & Location: core/l66_master_fusion.py.
- Config/Wiring: Config in config/fusion.yml or config/decision.yml defines how to map domain signals to an action. Possibly a mapping of regimes to weight vectors for each domain, and parameters for GP or MoE gating network. L66 runs every decision tick after gathering all domain summaries. Its MAV is passed to consistency engine L67.
- Health & Logging: Logs composition of MAV (“MAV: [Long 0.7, Short 0.1, Neutral 0.2], from Trend=+0.9, Pattern=-0.4, Micro OK, Regime supportive, Risk OK”). If L66 fails, L68 might revert to relying directly on L3 and L24 signals – possible but lacking the final polish of cross-domain integration. The engine might then occasionally have internal disagreements (e.g. pattern vs trend conflict unresolved) – L67 would catch conflict ratio high. In a fail scenario, HLDE would likely be more conservative or rely on pre-set hierarchies.
- TCN Impact: L66 is critical for full internal consistency – a key part of reaching TCN-10000[342][343]. By fusing all domains, it ensures the engine’s final actions consider all angles, reducing contradictory moves and improving reliability. This elevates the Trust and Noise discipline metrics (since conflicting signals are resolved into a clear action or abstention), showcasing institutional-grade cohesion in the decision process.
L67 – Action Consistency Engine
- Domain: Expectancy & Fusion
- Primary Role: Verifies that all layers’ outputs are coherent with each other and flags or suppresses trades when signals conflict[344][345]. Essentially, L67 measures the degree of agreement among the various components (trend, pattern, micro, regime, risk) and ensures the final decision (from MAV) isn’t proceeding on a divided vote. If a conflict is high, it may recommend no trade or a reduced position.
- Key Inputs: The master action vector from L66 (which includes an implied direction and perhaps probabilities), detailed inputs from trend complex (L51–L60), pattern complex (L30–L39), microstructure (L61–L63), regime state (L64), and risk model (L4) – specifically looking at directional recommendations or warnings from each.
- Key Outputs: action_consistency_score (ACS) – a score between 0 and 1 indicating the fraction of signals in agreement (1 means all signals align, 0 means complete disagreement)[346], suppression_flag – true if ACS is below a threshold and thus the trade should be suppressed (no entry)[347], alignment_flag – true if ACS is very high indicating strong unanimous support for the action (could be used to scale up confidence or size)[347]. These outputs go to L68 (HL decision) and L5/Pine (so that Pine might hold fire on an alert if suppression_flag is true).
- Core Logic/Model: Calculates a conflict_ratio as weighted sum of disagreements[348]. For example, if of 5 domain signals, 3 favor long, 1 favors short, 1 neutral, conflict_ratio might be something like (signals disagreeing / total). ACS = 1 - conflict_ratio[349]. Weighted: maybe trend and pattern signals have more weight than micro risk flags, etc. If conflict_ratio above threshold, suppression_flag = true (the example said if conflict signals sum to a certain level, ACS low)[350]. L67 might implement these thresholds from config (like require at least 60% weighted agreement to proceed). It effectively enforces a consensus rule.
- File & Location: core/l67_consistency_check.py.
- Config/Wiring: Config in config/decision.yml (weights for each domain’s vote, threshold for suppression vs proceed). Runs every decision cycle after L66. It doesn’t change the recommended action direction, but can veto it (suppression) or mark it strong (alignment_flag). L68 reads these flags to finalize decision.
- Health & Logging: Logs conflict metrics (“Conflict ratio 0.4 – moderate disagreement, ACS 0.6”). If L67 fails, HLDE might act on some contentious signals that normally would be filtered, possibly resulting in more whipsaws or inconsistent performance. It’s a safeguard; without it the engine might sometimes trade when internal consensus wasn’t there (increasing risk).
- TCN Impact: L67 ensures the engine trades only when the majority of evidence supports it, a crucial factor for reliability. This reduces whipsaw trades born of one-off false signals, thus improving Noise filtering and drawdown control (Trust). In TCN terms, it contributes to a higher win percentage and consistency by avoiding low-consensus trades – exactly the kind of internal risk management expected in institutional systems.
L68 – High-Level Decision Engine (HLDE)
- Domain: Expectancy & Fusion
- Primary Role: Makes the final trade/no-trade call and high-level action decisions such as Go Long, Go Short, Stay Out, Enter Later, Exit Early, Adjust Size based on inputs from all prior logic[351][352]. L68 is effectively the ultimate policy layer that issues directives like open a position, hold, or close, given the fused signals and consistency checks.
- Key Inputs: Action_consistency_score and flags from L67, master_action_vector from L66 (which implies a bias and strength), expectancy and confidence from L3, risk output from L4 (current positions, acceptable risk for new trade), microstructure risk from L62 (likely influencing conditions to avoid entry), pattern execution signals from L50 (if any pending pattern triggers), trend execution from L60 (if a trend entry was suggested), and overall regime condition from L64 (e.g. if regime is chaotic, HLDE might impose a “stay out” regardless of signals).
- Key Outputs: high_level_action – discrete decision like “LONG”, “SHORT”, “EXIT”, “HOLD/NO TRADE”[353], an action_strength (how strong this directive is, possibly mapping to confidence or how big position to take if multiple allowed)[353], and action_confidence (ensuring HLDE also outputs a confidence in its decision)[353]. These outputs are sent to L69 (meta-execution bundler) and L5 (execution interface) to be translated into actual orders/alerts.
- Core Logic/Model: Implements a decision tree using conditions aggregated from all layers[354][355]: For Long decision: require MAV.long > threshold, expectancy positive, risk acceptable, supportive regime, micro aligned[355]. For Short: similar mirror conditions. For Exit: if trend fade OR reversal flagged OR volatility spike OR microstructure inversion OR expectancy collapses mid-trade[356]. For Avoid: if regime chaotic OR noise extreme OR slippage extreme OR overall confidence low[357]. These conditions (given in pseudocode in the spec[355][358]) are implemented with specific numeric thresholds from config. HLDE basically says: “All systems go” for an entry, or “Don’t trade” if any major block conditions triggered. It also might issue “Enter Later” if signals are good but perhaps waiting for specific timing (maybe uses L58 output to delay a bit), though that might be more L7’s job. It definitely decides on Exit Early signals for existing positions, e.g. combining L57 fade, L20 reversal, L85 critical failure to decide an exit is prudent even before SL/TP. It also can signal Reduce Size or Expand Size, though that nuance might be handled by L4’s sizing and position scaling engines (HLDE might just effectively allow adds if confidence rises or call L4 to reduce if risk events hit).
- File & Location: core/l68_high_level_decision.py.
- Config/Wiring: Config in config/decision.yml holds thresholds for all conditions (like MAV threshold to enter, min confidence, what constitutes volatility “spike”, etc. as enumerated in conditions[355][358]). HLDE runs at every decision point and outputs a final decision datagram to be executed. It also references current position state (perhaps via L4’s context) to decide on exits vs entries.
- Health & Logging: HLDE logs its decision and which conditions were met (“Decision: STAY OUT – chaotic regime & conflict high” or “Decision: GO LONG – all clear”). If HLDE fails, the engine effectively has no final arbiter – which likely means either no trades or uncontrolled trades. To fail safely, it might default to not trading (which preserves capital but misses opportunities). This is such a critical layer that a fail-stop is probably in place (if HLDE logic fails, do not trade until fixed).
- TCN Impact: HLDE encapsulates the engine’s discipline and prudence. By explicitly enumerating conditions for action, it ensures the engine behaves rationally, akin to an experienced human trader’s checklist, which hugely contributes to Trust and Risk management in TCN. It stops the engine from forcing trades in suboptimal conditions and coordinates exits – directly enhancing risk-adjusted performance (Sharpe, drawdowns). Essentially, HLDE is the final guardian of institutional-grade behavior, its presence and quality significantly reflecting in a high TCN score.
L69 – Meta-Execution Engine (Python → Pine Bridge)
- Domain: Pine Mirror & Execution
- Primary Role: Packages the high-level decision from Python (L68 output) into a Pine-compatible execution bundle and augments it with additional context (entry quality, risk metadata) to send to the Pine script for actual order execution on the exchange[344][359]. L69 translates internal signals into the standardized format for the Pine execution layer (limited to ~64 fields due to Pine constraints).
- Key Inputs: HLDE’s decision (action, strength, confidence) from L68, the master action vector and consistency score (maybe to include in bundle), position sizing info from L4 (f_position, target size), TP/SL multipliers from L50/L60 (if any adjustments), microstructure risk from L62 (to include caution flags), regime stamp from L64, summaries of trend and pattern states for logging. Basically, everything Pine or a human overseer might need to understand and act on the trade signal.
- Key Outputs: pine_execution_bundle – a JSON or dict with <=64 fields containing the action and all relevant data (direction, entry price or trigger, SL, TP, position size fraction, confidence, any override flags like “reduced risk” or “manual confirmation needed”)[360]. Also outputs an execution_quality_score (how ideal conditions are right now for execution, e.g. low spread, etc.)[360] and sets any override_flags or caution_flags (like if it’s an override from a previous plan or if manual confirmation is suggested)[361].
- Core Logic/Model: Essentially a formatting and augmenting layer. It collects inputs: direction = high_level_action, sets entry parameters: If LONG, perhaps it uses the latest price as entry (or a limit if needed), attaches SL and TP distances from L4 outputs (like sl_distance, tp_distance from L4 outputs[362] possibly modified by L50/L60). Includes micro_risk = microstructure_risk_level from L62, regime_state from L64, pattern_summary from L46 (which compressed pattern signals to <=64 fields)[363], trend_summary (like trend_strength, etc.). All these are put into a structured message. The challenge is compressing to Pine’s variable count limit – thus likely summarizing each domain to a few fields. Possibly uses indices or codes instead of verbose keys. Execution_quality_score might be derived from L9 stress or L59 alignment. Override flags might be set if HLDE’s decision was borderline (like conflict high but still decided long – caution flag). This engine ensures Pine gets a self-contained “order packet”.
- File & Location: core/l69_meta_execution.py.
- Config/Wiring: The content of the bundle is defined in config/execution_format.yml, which maps internal fields to Pine fields. L69 runs at the moment of decision/entry and anytime an update is needed (like to adjust stop or exit). It communicates with Pine via a shared JSON file or websocket.
- Health & Logging: Logs the bundle content and if any fields were truncated or omitted due to limits. If L69 fails to format properly, Pine might receive incomplete data and not execute, or mis-execute. This is critical for real trading – to fail safe, Pine might have defaults (like if data missing, do nothing). Robust testing ensures bundle fits size limits; any error here could halt trading (which is safer than mis-trading).
- TCN Impact: L69 does not directly influence trading logic quality, but ensures Integrity and Communication between Python and Pine (and any human interface). In TCN terms, this affects Governance/Transparency – an institutional engine must clearly communicate signals (for oversight and latency reasons). L69’s structured output gives the system the ability to be monitored and controlled, contributing to the Integrity Sentinel aspect (ref. L98–L100). It indirectly affects TCN score by ensuring execution is correct and audit-friendly, preventing technical mishaps from reducing performance.
L70 – Scheduler Interface Engine (L7 Link)
- Domain: Pine Mirror & Execution
- Primary Role: Acts as the liaison between the Python scheduler (L7) and the Pine execution layer, passing timing and prioritization information to Pine and ensuring trades are executed at the optimal times and under concurrency constraints[364][365]. Essentially, L70 communicates L7’s planned schedule to the Pine script, which can then stagger alerts/entries accordingly.
- Key Inputs: Data from L7 such as expected optimal entry time windows, trade priority ranks, concurrency limits (like how many trades to allow simultaneously), risk windows (times of day to avoid if L7 chooses), and any “hold until” or “delay” instructions (e.g. if L7 says not to enter until volatility window opens in 10 minutes). Also uses output from L69 (the raw execution bundle) so it can embed scheduling info into it.
- Key Outputs: scheduler_task_package – an addition to the execution bundle or a separate message that Pine reads, which includes fields like trade_priority_rank, recommended_entry_time or time-window, whether to queue this trade or execute immediately, etc. Also outputs expected_trade_value (maybe the expected value of the trade L7 computed, for logging), opportunity_window (time or condition when trade should ideally trigger), and trade_priority_rank (the rank among the day’s trades)[366]. Essentially, this instructs Pine how to sequence the trade relative to others.
- Core Logic/Model: Fairly straightforward: it appends or merges L7’s instructions into the final Pine payload. For instance, if this trade is ranked #1 and can be executed now, mark it immediate. If it’s rank #3 and currently two trades are active (max concurrency = 2), mark it as queued until one trade closes. If L7 found an “opportunity window” (like most momentum expected around 14:30, from L58), it will include that as not before 14:30. If L7 identified an “avoid time” (maybe around major news event), it might instruct Pine to skip or delay new entries until after.
- File & Location: core/l70_scheduler_link.py.
- Config/Wiring: Defined in config/scheduler.yml (fields to communicate, handling of queue). Pine must be coded to obey these fields (like not fire an alert if queue flag is set). L70 runs with L69 at decision points to ensure each execution bundle includes scheduling meta-data.
- Health & Logging: Logs scheduling instructions (“Trade queued, priority 3, will trigger after 15:00 or on slot availability”). If L70 fails to attach schedule info, Pine will execute trades as they come without global optimization – which could mean slight performance loss (like taking a lower-ranked trade concurrently with a top-ranked one). However, core trading still happens, just less optimized.
- TCN Impact: This interface ensures that the sophisticated portfolio scheduling by L7 is actually enforced in execution. It contributes to maintaining Return while controlling risk by not overcrowding trades. Its presence means the system truly operates as intended by L7, which directly affects TCN performance metrics like total return and drawdown (lack of scheduling could lead to overallocation and higher drawdown). Furthermore, it aligns with Institutional governance that trading follows a planned schedule rather than ad-hoc bursts. While L70 is more technical, the effective outcome is better risk-adjusted returns, hence an improved TCN evaluation.
## Risk & Tail Domain
L4 – Risk Engine (Risk Surface, TP/SL, Position Sizing)
- Domain: Risk & Tail
- Primary Role: Transforms the fused expectancy and volatility inputs into a concrete trade risk plan: dynamic stop-loss and take-profit levels, optimal position size, reward-to-risk ratio, and other execution penalties[367][368]. L4 ensures each trade is structured with proper risk management – where to exit if wrong, where to take profit if right, and how much capital to allocate. It is where “arbitrary predictions become an executable strategy”[369].
- Key Inputs: Expectancy (E) and confidence from L3, forward volatility σ_fwd from L1, kinematic measures from L2 (speed, acceleration, curvature – used to size stops), breakout/reversal probabilities from L2 (to gauge asymmetry), volume trend and liquidity regime from L10 (slippage expectation), microstructure factors from L8 (spread, etc. for penalty), uncertainty from L3. Optionally, sentiment or OI signals from L74 (if included) as extra context.
- Key Outputs: Key risk parameters for each trade: SL_distance (stop-loss distance in % or ATR multiples) and TP_distance (take-profit distance)[370][362], RR (reward-to-risk ratio) for the trade (optimized)[371], f_position (fraction of capital to allocate, essentially position size)[372][373], slippage_expected (expected slippage per L10, for logging or further penalty)[374][375], volatility_mode (just passes through vol regime perhaps), uncertainty_flag (if uncertainty high and special adjustments made)[376], trade_direction reaffirmed (long/short), and confidence (passed through). These outputs go to L5 (so Pine knows where to put SL/TP and how much to trade) and to L6 (for logging actual vs expected outcomes).
- Core Logic/Model: Multi-step risk calculation: - Volatility Model: Combines ATR and L1’s σ_fwd to estimate appropriate volatility measure for sizing stops[377][378]. It penalizes if microstructure spread is wide (spread_penalty from L8)[379]. - Stop/TP Engine: Uses quantile regression maps (trained offline) to derive SL and TP distances given current signals[380][370]. For instance, baseline SL = ATR_scaled * α_SL, TP = ATR_scaled * α_TP, where α are predicted by models (Quantile Regression Forest, Gaussian Process, with XGB fallback) using inputs like expectancy, volatility, momentum, trend energy, uncertainty[370][381]. Example dynamic shaping: if breakout_prob is high, set wider TP and tighter SL (to exploit upside but cut quick if fails)[382]. If reversal_prob high, opposite adjustments. - Reward/Risk Optimization: Calculate raw RR = TP_distance / SL_distance[383]. Then adjust with a function f(E, volatility, uncertainty) to get optimized RR_opt[383]. For example: if expectancy is high and volatility low, target a high RR (let profits run), if expectancy low or uncertainty high, accept a modest RR (like 1.2–2)[384]. - Position Sizing: Three stages[385][386]: 1. Fractional Kelly: f_kelly = (expectancy / variance) * 0.25 (quarter Kelly to temper aggression)[387]. 2. CVaR Constraint: compute Expected Shortfall from distribution of returns, then f_ES = min(f_kelly, risk_budget/ES) to ensure worst-case within budget[388]. 3. Microstructure Scaling: penalize size based on spread, slippage expectation, liquidity regime, volatility (like f_micro = 1 - penalty_microstructure, clamped between 0.1 and 1.0)[389]. Final position fraction f_position = f_ES * f_micro[390] (ensuring size is reduced in poor micro conditions). - Slippage & Impact Model: Quick calc: slip = spread/2 + impact_coeff * order_size[374]. Impact coeff learned from historical execution data and depth. L4 logs this slippage_expected and includes a slippage penalty in expectancy if needed. - Uncertainty Penalty: If L3’s uncertainty is high, reduce expectancy and position size. Specifically, uncertainty_penalty = (uncertainty / max_uncertainty)[391], then E_adj = E * (1 - uncertainty_penalty) and f_final = max(f_position * (1 - uncertainty_penalty), f_min)[392]. This ensures not over-sizing when confidence is low. - Outputs & Failure Modes: If any condition indicates extreme risk (excessive vol, high uncertainty, liquidity collapse, etc.), L4 can override to extremely low risk or freeze entries (risk = reduced 90%, allow only exits)[393]. It also sets a fail-safe: if risk calc fails, Pine fallback SL/TP kicks in (like fixed ATR multiple from Pine side) and new entries freeze[394].
- File & Location: core/l4_risk_manager.py.
- Config/Wiring: Many config files: config/risk.yml for Kelly fraction factor, min f position, risk budget etc., config/stop_loss.yml for quantile model parameters, config/take_profit.yml similarly, config/slippage.yml for impact coeff etc. Wires to L5 by outputting stop & target levels (likely in ticks or % to Pine), position size (in fraction of capital or contracts), and any risk-off flags. Also wired to L6 to log realized vs predicted metrics (E_pred vs E_real for feedback).
- Health & Logging: Extensively logs trade parameters: recommended SL, TP, RR, f_position, and any adjustments (like “Uncertainty high, size reduced to X”). If L4 detects anomalies or fails to compute (maybe missing vol input), it triggers fallback: it might provide default wide stops and minimal position (ensuring safety) and sets an uncertainty_flag so Pine knows to be cautious (or to not trade at all if critical). Pine also has embedded fallback risk rules if Python offline. L4 is critical but the system has backup: Pine mirror can apply a basic stop (like 3×ATR, fraction of capital fixed) if L4 output is absent.
- TCN Impact: L4 is pivotal for the Tail-risk and Risk management aspect of the system[395][396]. By dynamically sizing positions and stops, it strives for consistent risk per trade and target expectancy ~1-2% as per design[397]. This directly affects drawdowns and volatility of returns (Trust) and ensures profitable signals translate to real profits (Return). A sophisticated L4 that tailors each trade’s risk and sizing to conditions is a hallmark of institutional-grade engines, heavily influencing the TCN score’s risk-adjusted performance metrics. Essentially, L4 is why the engine can pursue high expectancy trades while respecting capital preservation – a key contributor to reaching TCN-10000 level.
L74 – Monte Carlo Risk Simulation Engine (MCR)
- Domain: Risk & Tail
- Primary Role: Simulates the portfolio’s performance under thousands of random scenarios to estimate the distribution of returns, drawdowns, and tail risks[398][399]. L74 provides a forward-looking risk assessment (value-at-risk, expected drawdown, ruin probabilities) by Monte Carlo, incorporating slippage, volatility shocks, and correlation stress. This helps L4/L7 calibrate risk and helps overall governance to ensure risk limits (like max drawdown) aren’t breached.
- Key Inputs: Pattern expectancy distribution from L43 (distribution of trade outcomes)[400], trend expectancy similarly, microstructure risk from L62 (which can amplify downside in simulations), correlation matrix from L72 (to simulate multi-asset combined outcomes), slippage model from L10 (to embed realistic execution costs), and regime transitions from L64 (to incorporate the chance of regime changes mid-simulation). Also uses current portfolio composition from L4/L7 (positions or planned trades) as a starting point for simulation.
- Key Outputs: mc_E (Monte Carlo expected return over a period or per trade, possibly verifying L3’s expectancy with simulation)[401], mc_drawdown (distribution or a specific percentile max drawdown estimate)[401], mc_volatility (simulated portfolio volatility), mc_ruin_prob (probability of hitting a ruin level or very large drawdown)[401], and mc_scenario_stress_metrics (maybe worst-case scenario details or tail event stats). These outputs feed L86 (portfolio risk engine) and L45 (maybe to adjust reliability if MC shows pattern strat not working in some scenarios). Also used by humans/governance to ensure risk is on target.
- Core Logic/Model: Runs 10,000+ simulated paths for the portfolio/trades using random draws for returns and volatility changes. It likely uses a bootstrap or stochastic model for trade outcomes: e.g., for each trade it can sample a return from the distribution given by pattern and trend expectancy (maybe a mixture distribution or custom from L43 and L3 outputs). It sequences trades along a time axis with possible overlapping positions (which is where correlation matrix informs joint outcomes). It also randomly introduces extreme events (volatility shock events correlating assets). Simulating at portfolio level may involve approximating strategy as trades with certain win/lose distribution and correlation. Possibly GPU-accelerated as spec suggests heavy simulation[398]. The result is a distribution of equity curves or outcomes from which it extracts metrics like median return, 95% worst drawdown, etc.
- File & Location: core/l74_monte_carlo_risk.py.
- Config/Wiring: Config in config/montecarlo.yml (number of paths, horizon length, ruin threshold, etc.). L74 likely runs once per day or per major plan update (not every minute, as it’s heavy). It outputs to logs and to risk controllers (L85 might use ruin_prob to trigger failsafe if too high). It could also inform L7 to possibly scale down new trades if simulation indicates high risk.
- Health & Logging: Logs summary of simulation (“MC: ExpReturn ~ 2%, 95% drawdown = 8%, ruin_prob ~0.5%”). If L74 fails (maybe due to heavy computation or missing distribution inputs), the engine can still function with static risk metrics, but missing it means less foresight of tail risk. In such case, fallback approach (like using L86’s simpler risk calc or conservative assumptions) would apply.
- TCN Impact: Monte Carlo simulation demonstrates an institutional approach to risk management – quantifying tail risks and worst-case scenarios. While it doesn’t directly alter trading, it strongly informs how risk limits are set (affecting L4 sizing, L7 concurrency). If simulation shows high tail risk, system can adjust to avoid it. This leads to improved Tail Risk Management (the “Tail” in Risk & Tail domain), boosting TCN’s view of risk intelligence. It ensures the engine’s aggressiveness is kept in check by rigorous scenario analysis, which is key for scoring high on risk management facets in TCN-10000.
L76 – Fee Impact Model (FIM)
- Domain: Risk & Tail
- Primary Role: Provides a precise calculation of transaction fee costs and rebates for each trade and incorporates hidden fee impacts (like volume-tier adjustments, maker rebates) into expectancy adjustments[402][403]. L76 ensures that the engine’s performance projections account for exchange fees and thus protects against strategies that only look good ignoring fees.
- Key Inputs: Order type (market vs limit) from L5, expected execution price and size from L4, the exchange’s fee schedule (e.g. Binance’s maker/taker rates, any rebates or tier adjustments, maybe changes if large volume), and asset-specific fee tier (some assets or high-volume accounts have different rates). Possibly any “hidden” fees like withdrawal or funding if relevant (but likely focusing on trading fees).
- Key Outputs: expected_fee_cost (in % or absolute, the cost that will be paid in fees for entry+exit of this position)[403], and fee_adjusted_expectancy (L3’s expectancy minus this fee cost) – although L10 already includes fee in expectancy for decision-making, L76 might confirm or refine it with precise values. The outputs feed back to L3 or L10 to ensure expectancy is net of fees, and to any performance logging.
- Core Logic/Model: Straight calculation: If taker order, cost = size * fee_rate_taker; if maker, cost = size * fee_rate_maker (could be negative if rebate?). It might also consider that if price moves to certain levels, order could flip from maker to taker or partial fills, but likely not too granular. Hidden aspects: if trading at very high volume, maybe engine expects moving to a better fee tier – L76 can simulate the tier for cumulative volume. It then outputs expected_fee_cost (for e.g. 0.04% taker each side = ~0.08% round-trip). It then subtracts that from expectancy E to give fee_adjusted_expectancy (if not already done by L10). L76’s value is mostly in accurate accounting and possibly scenario planning (like if a strategy does a lot of market orders, the cumulative fee impact is higher than with maker orders – L76 helps quantify that and could influence L7’s trade selection if one trade requires a taker and another can be maker).
- File & Location: core/l76_fee_model.py.
- Config/Wiring: Config in config/fees.yml (maker/taker rates, volume tiers, etc.). Runs per trade and passes results to risk calculators (L4 logs it, L3 uses it if necessary for expectancy). Could also update an internal cumulative fee counter.
- Health & Logging: Logs every trade’s fee estimation (“Fee cost = 0.05%, E_adj_fee = 1.50%”). It's a simple computation – unlikely to fail except misconfiguration. Without it, fees are still roughly handled by L10’s dynamic inclusion, but L76 offers exactness. If absent, the risk is minimal (slightly inaccurate expectancy calculations).
- TCN Impact: Small but important for Data Integrity in performance – ensures no hidden drag is ignored. It slightly improves Return realism (so no overestimation), and it's part of institutional thoroughness. By quantifying even minor costs, the engine meets high standards of performance accounting (which TCN scoring would implicitly expect in a top-tier system). It’s less about boosting score and more about preventing unexpected performance gaps due to fees.
L77 – Slippage Impact Model (SIM)
- Domain: Risk & Tail
- Primary Role: Enhances L10’s slippage model by considering higher-level context (pattern, volatility regime, microstructure state) to compute a more dynamic slippage forecast and worst-case slippage scenario. L77 updates expected slippage as conditions evolve and gives additional caution signals if potential slippage is high.
- Key Inputs: Baseline slippage from L10 (spread/2 + impact term), pattern-based volatility changes (e.g. if a big pattern triggers, short-term volatility might spike beyond normal), L15 volatility cycle (if expansion phase, slippage could increase), L8 microstructure features (like depth might drop if breakout triggers lots of orders), as well as volume relative to depth of book (from L8). Possibly RL output or external events (if any known news event incoming, slippage potential rises).
- Key Outputs: dynamic_slippage_forecast (updated expected slippage % considering current context), worst_case_slippage (maybe a 95th percentile slippage if a large adverse event hits), and execution_slippage_penalty (a recommended further penalty in expectancy or sizing because of slippage risk). These outputs refine L4’s calculations or cause L9/L62 to trigger protective measures if too high.
- Core Logic/Model: Observes that certain patterns or conditions amplify slippage beyond normal linear models. For instance, a breakout pattern might empty the order book on one side – slippage would be higher than a calm trade. L77 might incorporate pattern and regime multipliers to L10’s output: e.g. if bull flag breakout in low-liquidity asset, multiply base slippage by 2. If regime is calm and microstructure stable, maybe slippage is lower than base. It also likely keeps track of actual slippage from recent trades (via feedback) to adjust forecasts. The worst_case_slippage might be base slip + k * volatility * (some factor) – giving e.g. what happens if price gaps on entry.
- File & Location: core/l77_slippage_model.py.
- Config/Wiring: Config in config/slippage.yml (pattern multipliers, volatility-phase adjustments). L77 updates whenever a trade is about to execute or when conditions shift drastically mid-trade (maybe for trailing stop adjustments). It feeds L4 (to re-calc positions if needed) and L9 (if slippage forecast too high, L9 might block entry).
- Health & Logging: Logs “Dynamic slippage now X% (base Y%, increased due to [reason])”. If fails, L10’s simpler model still stands, so risk is moderate (just less refined).
- TCN Impact: Directly addresses Execution Efficiency: by anticipating extra slippage in tough conditions, the engine either avoids those trades or sizes them appropriately, preserving performance. That improves Return vs Noise – fewer trades lost to execution friction. It's another institutional hallmark, beneficial for TCN scoring under real-world performance conditions.
L78 – TP/SL Optimization Engine (Advanced)
- Domain: Risk & Tail
- Primary Role: Fine-tunes the stop-loss (SL) and take-profit (TP) distances using advanced techniques, beyond L4’s base model, to reflect current distribution of returns and risk appetite. L78 uses dynamic market factors (volatility changes, expectancy distribution shape, momentum) to adjust SL/TP for optimal performance (e.g. widen TP in trending conditions, tighten SL in choppy conditions).
- Key Inputs: Dynamic volatility from L15 (if volatility rising, maybe widen SL to avoid noise stop), current expectancy distribution from L43 (e.g. if distribution is skewed positive, lean on larger TP), momentum from L2 (strong momentum = push TP further), pattern risk from L32 (if pattern risk high maybe tighten stops), microstructure risk from L62 (if micro risk high, maybe tighter stop to exit quickly), and risk threshold from L4 (like an overall risk budget – if near limits, might tighten stops).
- Key Outputs: optimized_TP and optimized_SL distances (possibly expressed as multipliers to baseline or absolute values), and TP_SL_confidence (how confident it is that these are better than baseline). These feed back into L4’s outputs (basically replacing or adjusting the initial SL_distance and TP_distance) just before being sent to execution.
- Core Logic/Model: Possibly employs an iterative or ML approach: e.g., L78 might simulate slight variations of SL/TP around the baseline (using historical data or scenario analysis) to maximize some utility (like expected value of trade or Sharpe of outcome). It could also be rule-based: If realized volatility is exceeding forecast by X%, then increase SL by Y% (to avoid getting hit prematurely). Or, if momentum continuing strongly and trade in profit, it might recommend extending TP further (which can be signaled by trailing stops adjustments). It might incorporate multi-objective optimization: minimize risk of hitting SL while maximizing gain probability. Could be using gradient-free optimizers or a pre-trained model linking current context to ideal RR adjustments.
- File & Location: core/l78_tp_sl_optimizer.py.
- Config/Wiring: Config in config/risk_opt.yml (parameters for adjustments). L78 likely runs at trade initialization to set initial SL/TP and perhaps periodically for trailing adjustments (if the strategy does trailing stops or dynamic TPs). It directly modifies values in the risk plan that L4 outputs (so L4 might call L78 after its initial calc).
- Health & Logging: Logs changes (“Optimized TP to 2.5×ATR (base 2×ATR) due to strong momentum, conf 80%”). If L78 fails, the engine uses the original L4 outputs – which are already robust. So risk is low: L78 provides marginal gains in optimizing profit capture and loss avoidance.
- TCN Impact: Potentially improves Return by squeezing more profit from winners and cutting losers appropriately. It refines performance by maybe a few percentage points, which matters at the elite level. For TCN, it shows the engine leaves less on the table and has sophisticated risk-reward fine-tuning, supporting the Return and Trust aspects (fewer unnecessarily tight stops = trust, and bigger winners = return).
L79 – Position Sizing Engine (Advanced)
- Domain: Risk & Tail
- Primary Role: Further refines position size beyond L4’s base fraction by considering more factors like Monte Carlo variance, microstructure risk (again), and the aggregate portfolio context, to compute optimal trade size at a more granular level[404][405]. L79 ensures capital allocation per trade is fine-tuned using advanced risk metrics (CVaR, etc.) so each trade’s contribution to portfolio risk is appropriate.
- Key Inputs: Fee-adjusted expectancy from L76 (to ensure sizing aware of net edge), Monte Carlo variance from L74 (to gauge distribution of returns for strategy, thereby calibrate Kelly fraction more accurately), microstructure risk from L62 (again, heavy micro risk might reduce size), any outstanding correlation exposures (if similar trade already open, reduce new size), and volatility targeting info (if portfolio volatility too high, reduce new positions).
- Key Outputs: position_size (final size as fraction of equity or number of contracts)[406], size_confidence (confidence in this sizing), and size_safety_margin (perhaps how much buffer was left from maximum allowed, indicating conservativeness)[406]. This essentially replaces or adjusts f_position from L4.
- Core Logic/Model: Possibly re-calculates Kelly using updated variance from MC (L74): f_kelly_new = (E_net / variance_MC) * some fraction (like 0.2 instead of 0.25 if more conservative). It might incorporate conditional value-at-risk (CVaR): e.g., ensure that even in worst-case 5% scenario, loss doesn’t exceed a certain fraction of capital, then solve for size that meets that constraint. It likely also monitors account leverage usage and might cap size to not exceed account-level limits. Liquidity constraints might also come here (if order size would be significant relative to daily volume, cut it). The output is a final size that might often be lower than L4’s initial suggestion if advanced factors indicate higher risk.
- File & Location: core/l79_adv_position_sizing.py.
- Config/Wiring: Config in config/risk_adv.yml (CVaR percentile, maximum per trade risk allowed, etc.). L79 receives initial f_position from L4 and then applies adjustments. It outputs final position_size to L4 or directly to execution output overriding previous.
- Health & Logging: Logs final size and rationale (“Final position size 1.5% of equity (base 2% reduced due to high variance)”). If L79 fails, L4’s sizing (which already considered many factors) is used – safe enough.
- TCN Impact: Further reduces risk of ruin and volatility of returns by smart sizing. This directly improves the Tail Risk aspect, guarding against outlier events. It helps keep drawdowns smaller, thereby boosting risk-adjusted performance metrics (Sortino, etc.) that TCN likely values. It’s an extra layer of risk optimization, contributing to the engine’s ability to handle larger capital (since position sizing is very refined, it can push limits more safely).
L80 – Multi-Asset Position Allocation Engine
- Domain: Risk & Tail
- Primary Role: Allocates capital across multiple simultaneous positions/trades ensuring the sum of exposures remains within limits and is optimally distributed. If multiple trades are active, L80 balances capital among them based on their risk/return profiles, correlation, and real-time performance. Essentially, it ensures the portfolio is not over-leveraged or overly concentrated.
- Key Inputs: Current capital allocation vector (how much is currently in each open trade), trade priority and expected value from L7 (for new candidates), correlation matrix from L72 (to avoid doubling down on correlated assets), liquidity and volatility of each asset (some assets may warrant smaller allocations due to higher volatility or lower liquidity), and the risk outputs from L86 (total portfolio risk metrics).
- Key Outputs: capital_allocation_vector (the recommended fraction of capital in each open position or planned position)[407], allocation_risk (an index measuring how risky the current allocation is), and allocation_efficiency (perhaps an output measuring how optimal the allocation is in terms of risk-reward)[408]. These outputs could directly adjust orders (if needed, e.g. instruct to scale down certain position if new one added) or simply inform L7 to not take a trade if allocation full.
- Core Logic/Model: If total allowed exposure is X%, and trade opportunities exceed that, L80 distributes X% among them in proportion to some metric (like each trade’s expected Sharpe or E/vol). It might solve a small optimization problem: maximize sum of expected returns of allocations minus penalty for risk (Markowitz style or submodular selection problem). If one asset is highly correlated with another already in portfolio, L80 will allocate less to it. If one trade’s risk (volsize) is dominating, it might trim that position to free risk budget for others. Possibly uses a quadratic programming or linear programming approach to satisfy constraints (like sum allocation <= X, each >=0, etc.) while maximizing a utility (combining expectancy and variance via modern portfolio theory).
- File & Location: core/l80_allocation_engine.py.
- Config/Wiring: Config in config/portfolio.yml likely covers these high-level constraints (max total exposure, correlation threshold, etc.). L80 runs whenever a new trade wants to enter or periodically to rebalance if some trades moved significantly (less likely in intraday though). It issues instructions possibly to L5 to scale positions (if one is too large relative to new info).
- Health & Logging: Logs current allocation vs ideal (“Allocations: BTC 50%, ETH 30%, cash 20%; correlation-adapted”). If down, L7’s schedule and L4’s sizing still enforce some discipline, but might not be as optimal multi-asset wise. Could result in slight overexposure to one sector etc. If severe, L86 would catch increased portfolio risk and could trigger risk-off actions, albeit after the fact.
- TCN Impact: L80 elevates the engine from single-trade optimality to portfolio optimality, which is crucial at institutional scale. It improves Return by better diversification and Trust* by controlling overall risk usage. A well-allocated portfolio yields smoother equity curves (lower drawdowns, better Sharpe), directly influencing TCN scoring. Essentially, L80 helps ensure the engine’s performance doesn’t degrade when scaling to multiple concurrent positions – a necessary trait for high TCN scores at institutional complexity.
L81 – Early Exit AI Engine
- Domain: Risk & Tail
- Primary Role: Monitors open trades and predicts in real-time if a currently profitable trade is likely to turn into a loser, recommending an early exit before the stop is hit[409][410]. L81 acts as a protective mechanism to lock in gains or cut risk when conditions change adversely, but SL hasn’t been reached yet.
- Key Inputs: Active trade data (entry price, current P&L, SL and TP levels) from L5/L4, reversal signals from L20/L57 (if trend is fading or reversal probability jumps), microstructure inversion detection (order book changes from L8 indicating incoming pressure opposite to trade), anomaly spikes from L61 (if something unusual arises that could reverse the trade), volatility shocks from L15 (sudden spike might reverse direction), and time in trade (if trade is lingering too long without hitting TP, maybe losing momentum).
- Key Outputs: early_exit_flag (true if it’s advisable to exit the trade immediately to preserve profit or mitigate loss)[411], early_exit_confidence (level of certainty in this call), and protective_exit_price (the suggested price to exit, possibly current market price or a limit slightly better if expecting slip)[411]. These outputs are consumed by L5 which will execute an early exit (market close or adjust order). It might also inform L6 to log that it was an AI-driven early exit (to analyze outcome).
- Core Logic/Model: Likely a classification model or rule that triggers if conditions match known reversal patterns while trade is still open. E.g. if trend_fade_prob from L57 > X% and price retraced N% from peak, and reversal_valid from L17 triggered, then early_exit_flag = true. Or a small ML (maybe logistic regression) taking inputs like current %profit vs expected, momentum shift, volatility jump, anomaly to output probability of giving back profits if staying in. If that probability > threshold, it triggers early exit. It essentially tries to catch the case "we had a winner, but now signs show it might reverse, so exit while still above entry". For losing trades, early exit might not apply because SL logic covers those (though it might recommend cutting before SL if clear failure, but that’s similar rationale).
- File & Location: core/l81_early_exit.py.
- Config/Wiring: Config in config/trade_management.yml (conditions for early exit triggers, minimum profit to consider, etc.). Runs continuously on open positions (like every new bar check). If triggered, communicates to execution to close position ahead of plan.
- Health & Logging: Logs “Early exit triggered for BTC trade: reversal signals high, exiting at +1.2% profit (vs +2% target)”. If too sensitive, might exit good trades prematurely (L6 would track performance hit). If off, trades just run to SL/TP as normal, which is safe but maybe less optimized.
- TCN Impact: Enhances risk-adjusted returns by saving profits that could otherwise evaporate. This improves Return (keeps some winners that would turn losers) and lowers variance (fewer round trips from win to loss). It demonstrates an advanced level of trade management which benefits TCN metrics like consistency and drawdown. However, it must be well-tuned (exiting too often can reduce total profit). At TCN-10000 level, an effective early exit AI signals extraordinary sophistication in risk control.
L82 – Trade Reinforcement Learning Engine
- Domain: Reinforcement Learning Execution
- Primary Role: A self-learning agent that continuously learns from trade outcomes to improve policy over time[412][413]. L82 experiments with adjusting certain decisions (entry timing, sizing tweaks, hold duration) and receives reward signals (from realized trade P&L and risk outcomes) to evolve the strategy. It sits in parallel to the rule-based logic, gradually influencing strategy parameters or choices as it learns.
- Key Inputs: State features summarizing the environment at decision times (could compress all layers outputs L0–L80 into a fixed-size state vector – likely a subset like [pattern_state, trend_state, micro_risk, regime, etc.] at entry time and during trade)[414]. Actions that the RL can take, which might be discrete like (Bias Long, Bias Short, or Wait) or continuous adjustments (like tweak position size or modify SL). Reward R as defined by L6 (e.g. trade outcome normalized by risk, plus penalties for large drawdowns etc.)[415][416]. Possibly uses the reward shaping from L48 (pattern-based reward adjustments) to accelerate learning.
- Key Outputs: RL_action_bias (a subtle bias or suggestion to the HL decision – e.g. an extra vote to go long or short beyond model outputs)[417], and RL_weight_updates (small adjustments to internal weights that might correspond to meta-parameters in other layers, or its own neural net weights)[417]. The bias might be used by L66 or L68 as one additional input, effectively fine-tuning decisions beyond static logic. Over time, RL might discover slight improvements (e.g. maybe hold winners a bit longer than rule suggests in certain regimes, etc.).
- Core Logic/Model: Likely employs an RL algorithm like Proximal Policy Optimization (PPO) or Soft Actor-Critic (SAC) since mentioned[414]. The state includes condensed outputs of all key layers and maybe recent trade performance. The action could be an adjustment to strategy (like a vector that nudges the outputs of HLDE or risk engine). The reward is shaped to positive if trade fulfilled target or exceeded expectancy, negative if SL hit or large adverse excursion, etc.[418][419]. It might train in the background (off-policy using stored episodes recorded by L6 or via simulated environment). Once sufficiently trained, it can operate online by providing slight adjustments. E.g., RL might learn to reduce position size on Fridays due to weekend risks, or push Pine mirror to more aggressively exit during certain patterns not formally encoded.
- File & Location: core/l82_trade_RL_agent.py.
- Config/Wiring: Config in config/rl.yml (learning rate, exploration policy, etc.). L82 runs asynchronously (maybe using historical data in simulation or micro-batches between trades). Its biases are fed into fusion (L66) or HLDE (L68) as an additional "opinion". Possibly low weight initially and allowed to increase as confidence in RL grows (tested by performance logs).
- Health & Logging: Logs RL policy changes (“RL suggests slight bias to SHORT in current regime”). RL can be risky if it learns wrong – oversight required: maybe gating by L45 (meta-controller ensures RL doesn’t override core logic except in small ways). If off or misbehaving, the core system still runs on rule-based logic, which ensures baseline performance (RL is an enhancement).
- TCN Impact: The presence of a learning agent that adapts continuously is a big plus for Adaptation (the engine isn’t static – it can improve in new market conditions)[420]. If effective, RL can push performance above what static rules achieve, improving Return and possibly adjusting risk adaptively (Trust). Achieving full TCN-10000 likely expects some form of RL/meta-learning to get that last mile of intelligent adaptation, so L82 is a key component for that milestone.
L83 – Trade Outcome Expectation Engine
- Domain: Risk & Tail
- Primary Role: After a trade is entered, L83 continuously updates the expected outcome probabilities given evolving market conditions (essentially an in-trade live win probability model)[421][422]. It estimates on-the-fly the probability the trade will hit TP vs hit SL vs stagnate, and time-to-event. This helps decide mid-trade adjustments (like move stops or exit early via L81) and informs risk monitors (like if probability of success drops too low, consider exit).
- Key Inputs: Real-time price relative to entry, trailing performance (how far in profit or loss), current volatility vs at entry (if volatility higher, outcomes might change), L2’s updated quantile forecasts (which can be conditioned on current price position), L57 trend fade signals (if trade was trend-following but now fade signals appear, win probability falls), microstructure changes from L8 (if large opposing orders appear, chance of hitting TP lowers), time in trade, etc.
- Key Outputs: post_entry_success_prob (probability trade hits take-profit before stop)[423], post_entry_failure_prob (probability hit stop-loss first)[424], expected_duration (estimated time until resolution, TP or SL)[424]. These may be consumed by L81 (if failure_prob becomes high, trigger early exit) and by L84 (health monitoring – if expected_duration far beyond normal, maybe something’s off). Also used by L7 maybe to schedule other trades around it.
- Core Logic/Model: Possibly uses a survival analysis or hazard model: given trade open, at each moment compute hazard rates for TP or SL event. Could leverage L2’s predictive distribution updated with current conditions – e.g. simulate forward using quantile curves to see chance of hitting either bound. Or a simpler logistic regression: take current % to TP and % to SL, plus momentum and volatility metrics, output probabilities of reaching one before the other. Also could incorporate known patterns: e.g. if trade hasn’t moved much in half the expected time, success probability might drop.
- File & Location: core/l83_outcome_predictor.py.
- Config/Wiring: Config in config/trade_management.yml (for calibration of this probability model). Runs continuously on open positions and updates likely each bar. Sends output to some central trade tracking object that L81 and others read.
- Health & Logging: Logs if probabilities shift significantly (“Trade ABC: P(win) down from 60% to 40% after volatility spike”). If inaccurate, might cause premature exits or holding too long; L6 would catch systematic errors (like if early exit triggers often but trade would have won, means model underestimates success). That feedback can refine L83. If disabled, system just relies on static initial expectancy and gut (less optimal but functional).
- TCN Impact: Improves Risk control by dynamically assessing ongoing trades. This reduces surprises – if a trade’s context deteriorates, the engine can act (improving Trust by avoiding turning winners to losers). It also aids in Timing exits (closing before full stop or letting winners run if success probability remains high). Such dynamic monitoring is expected in top-tier systems, contributing positively to TCN’s evaluation of sophisticated risk management.
L84 – Trade Health Monitoring Engine
- Domain: Risk & Tail
- Primary Role: Monitors each open trade’s pattern and trend integrity and flags if the rationale for entry is no longer valid (even if SL not hit)[425][426]. For example, if a trade was based on a pattern which has since invalidated, or a trend that reversed, L84 scores the trade’s “health”. It provides a continuous check-up beyond just price movement.
- Key Inputs: The pattern state that justified entry (which pattern or setup triggered it, likely note from L32), current pattern signals from L32 for that asset (if the pattern that was present is now gone or an opposite pattern formed), trend alignment from L59 (if trade was long but microstructure trend alignment turns negative, not healthy), volatility regime shifts from L64, and L83’s success probability.
- Key Outputs: trade_health_score (0–1 rating of how well the original trade thesis holds)[427], health_deterioration_rate (how fast it’s worsening, e.g. pattern gradually failing vs sudden)[427], and immediate_attention_flag (if health drops below a critical threshold, signalling L81 or manual oversight to consider an exit)[427]. These outputs feed L81 (which might treat a near-zero health as trigger for early exit) and any dashboard for human risk managers.
- Core Logic/Model: Compares current pattern/trend context to entry context: if trade was based on a bull flag but now an engulfing bearish pattern emerged (health ~ 0 => immediate attention). If nothing changed, health remains high. Uses pattern validity from L36 focusing on the trade’s logic specifically. Could be a weighted sum: started with pattern X and trend Y, now weight if pattern X still valid (1 or 0), trend Y still intact (1 or 0), micro risk introduced (-some). Possibly decays health as time passes with no progress (drift). High deterioration rate if, say, pattern flipped opposite quickly.
- File & Location: core/l84_trade_health.py.
- Config/Wiring: Config in config/trade_management.yml for thresholds to flag immediate exit. Runs on open trades periodically (like every new significant signal).
- Health & Logging: Logs health for each trade (“Trade #12 health 0.3: original bull flag broken by new low – attention required”). If mis-specified, might exit trades too early or hold too long; synergy with L81 ensures that multiple layers (health and outcome probabilities) are considered for exit decisions. If off, system relies on direct signals like L81 triggers and stops.
- TCN Impact: Provides robust Quality Assurance on each trade, akin to a risk manager reviewing each position. This leads to fewer “surprises” where a trade was left riding when its premise died, improving outcomes (Trust). It’s an advanced layer of risk control that likely contributes to consistency and lower tail losses – factors improving TCN score under risk management.
L85 – Critical Failure Detection Engine
- Domain: Risk & Tail
- Primary Role: Monitors for catastrophic market events or system anomalies that require immediate action – e.g. exchange outages, flash crashes, liquidity collapse, etc. L85 is like an emergency brake: it detects signals that normal trading logic might not handle quickly enough, and triggers failsafe measures (like closing positions or halting trading)[428][429].
- Key Inputs: Market data anomalies (e.g. price gap beyond a threshold in one tick), L61 anomaly flags (especially “liquidity collapse” or “iceberg vanish” etc.), L9’s latency detection (if exchange data stops, that’s a serious issue), volatility explosion (vol up many std devs beyond expected – possible flash crash), also internal system health (if L0 feed degraded flags or Pine disconnect alerts).
- Key Outputs: critical_failure_flag (true if such an event is detected)[429] and emergency_exit_signal (instruct all positions to close ASAP)[429]. Possibly also triggers switching to Pine failsafe mode or backup strategies. These outputs are acted upon by L5 (closing all trades, maybe via market orders regardless of normal signals) and by governance layers (could send notifications to ops team).
- Core Logic/Model: Has a list of conditions: - Market halt: e.g., no price ticks for X seconds or exchange returns errors continuously (imply exchange downtime) – triggers critical_failure_flag. - Flash crash: price drops a certain % within a minute, likely beyond any normal vol, or spread skyrockets and order book empties – triggers. - Liquidity collapse: L8 shows essentially no depth, L61 flagged iceberg gone and huge imbalance – triggers. - Slippage explosion: L10 predicted certain slip but actual slip in a trade was an order of magnitude more – could mean market disorder. - Also monitors system metrics: e.g., if CPU or memory usage skyrockets or strategy modules not responding (like no signal from L3 in some time) – could trigger a protective halt (though this crosses into system monitoring not described, but possible). When triggered, sets emergency_exit and possibly instructs L4 to cut risk by 90% or hold off new entries until manual reset.
- File & Location: core/l85_emergency_monitor.py.
- Config/Wiring: Config in config/emergency.yml for thresholds (drop %, timeouts). Running continuously in background. Integrated with Pine via an override: Pine might have a code path that if emergency_exit_signal is true, it cancels all orders and closes positions immediately.
- Health & Logging: Only logs when triggered because it’s rare (“Critical Failure: Exchange latency >10s, all trading halted”). If triggered incorrectly (false alarm), it could unnecessarily exit trades and stop trading, which is harmful. So config must be tuned to almost never false alarm. If L85 fails to detect something real, worst-case is large losses or system meltdown; thus redundancy likely exists (like human monitoring or exchange circuit breakers).
- TCN Impact: This is more about tail-risk protection – a safety net that can prevent extremely large losses in rare events. If it successfully avoids a catastrophic loss even once, it justifies itself by preserving capital (which strongly affects long-term Sharpe and drawdown metrics that TCN cares about). It also shows institutional rigor in risk management beyond normal conditions, likely a factor in achieving TCN-10000 (since that implies robust handling of extreme scenarios).
L86 – Portfolio Risk Engine (Total Account Risk)
- Domain: Risk & Tail
- Primary Role: Aggregates risk exposures across all positions to monitor and manage total portfolio drawdown and exposure levels[430][431]. L86 ensures that as a whole, the account stays within defined risk parameters (like maximum VAR, or concurrent exposure limits). If total risk is too high, it may trigger scaling down or not allowing new trades.
- Key Inputs: Current positions’ sizes and stop levels from L4 (to estimate worst-case loss per trade), correlation matrix from L72 (to compute combined risk), Monte Carlo results from L74 (for portfolio VAR), current account equity, and maybe open orders (to include near-future exposures).
- Key Outputs: portfolio_risk (a composite measure such as current VAR or % of equity at risk if all stops hit)[432], portfolio_stress_index (some measure of how stressed the portfolio is by current conditions – possibly comparing current drawdown to historical worst), and max_concurrent_trades (L86 might adjust allowed trades count if risk is near limit)[433]. L86 could signal L7 or L69 to not initiate further trades or to reduce some positions if portfolio_risk beyond threshold.
- Core Logic/Model: Calculates total risk as sum of individual position risk (position size * distance to SL) but accounts for diversification: effective risk = sqrt(sum_i sum_j (risk_i * risk_j * corr(i,j))). It compares this to risk budget (e.g. 2% of equity max loss on worst-case scenario). If over budget, it may instruct to cut the largest or least promising positions (some logic for which to cut?). More simply, it monitors a running sum of potential loss if SLs triggered – if beyond X% equity, raise alerts or triggers (like do not add new trades or tighten stops on all positions).
- File & Location: core/l86_portfolio_risk.py.
- Config/Wiring: Config in config/portfolio.yml (max portfolio risk% allowed, etc.). L86 likely runs continuously and informs L7 (maybe by reducing risk_budget for new trades to 0 if limit hit) and HLDE (which could freeze new entries or even call for partial exits on existing ones if extreme). Also provides input to any UI or risk monitor system.
- Health & Logging: Logs current portfolio VAR (“Portfolio risk ~ 3.5% of equity, limit 5%”) and flags if near or over limit (“Risk limit exceeded – no new trades, consider reducing exposure”). If L86 fails to catch an overload, portfolio might become too leveraged – but L4 and L7 still have per-trade and scheduling checks, so only if many trades succeed in aligning risk could it happen (rare with all these controls). If it false alarms too early, it may throttle performance (fewer trades than possible).
- TCN Impact: Ensures aggregate risk is controlled – directly affecting Tail Risk metrics. TCN scorers would consider how the system handles multi-position risk, and L86 provides that assurance. It’s crucial for maintaining low drawdowns relative to returns (Sharpe, Sortino improvements). The presence of an explicit portfolio risk oversight is definitely expected at institutional readiness and thus feeds into achieving the TCN-10000 risk management standard.
L87 – Account Health Engine
- Domain: Risk & Tail
- Primary Role: Gauges overall account health by analyzing factors like recent drawdowns, equity curve shape, win/loss streaks, etc., to potentially adjust strategy parameters or signal if the engine’s performance is degrading[434][435]. L87 is like a doctor for the trading system, telling if the system is within normal performance or if something’s off (maybe due to market change or model drift).
- Key Inputs: Performance logs from L6 (recent returns, drawdown %, number of consecutive losses), risk metrics from L86 (current risk relative to equity), external factors like maybe macro environment (if entire market changed regime?), and reliability trends from L44/L53 (if pattern or trend reliability is dropping, that affects health).
- Key Outputs: account_health_score (maybe 0–100 measuring system performance health, incorporating both equity curve stats and model metrics)[436], account_drawdown_risk (an estimate of the probability of further drawdown given current state), and recovery_probability (chance the system will recover to peak without intervention)[436]. These outputs could prompt actions: e.g., if health_score falls below threshold (meaning system may be breaking down), it could trigger L85-like behavior to pause trading (or switch to Pine-only minimal strategy) until retrained or adjusted.
- Core Logic/Model: Likely monitors if current drawdown > some multiple of historical avg drawdown – if yes, health drops. If win rate has significantly dropped beyond expected variance – health down. If key model reliabilities (L44/L53) are decaying consistently – health down. Possibly uses a scoring system summing these factors. It might incorporate a small ML that learned from past periods labeled healthy vs unhealthy, to output a probability that current drawdown is normal or signals a regime/model breakdown (like a Bayesian or logistic model using features: drawdown%, losing streak length, volatility of returns, etc.).
- File & Location: core/l87_account_health.py.
- Config/Wiring: Config in config/health.yml (thresholds for alarm, e.g. health_score < 50% pause trading). Runs maybe daily or weekly to avoid reacting to minor fluctuations. If health poor, could communicate to an orchestrator to reduce position sizes globally or pause until models retrained (semi-automatic measure).
- Health & Logging: Logs health status periodically (“Account Health: 75 (good), drawdown 4%, within norms”). If it detects serious issues (“Health 30 – abnormal drawdown, potential model drift”), it might log recommended action or automatically engage safety (like risk-off mode). If malfunction, system might trade through a problematic period not realizing performance issues (where a prudent manager would stop), risking larger drawdown. But there's manual oversight usually, so L87 is a tool to assist or automate that oversight.
- TCN Impact: Reflects the system’s Self-awareness and Integrity – a top-tier system monitors its own performance and can take steps to self-correct or at least alert. This strongly supports the Trust aspect, as it reduces risk of ruin from prolonged poor performance. In TCN evaluation, a system that knows when to stand down or adapt would score higher in stability and risk management. L87’s presence and effective use can be one of those final elements that push from 99th to 100th percentile in institutional trustworthiness.
## Pine Mirror & Execution Domain
L5 – Execution Bridge / Pine Mirror Engine
- Domain: Pine Mirror & Execution
- Primary Role: Bridges the Python core (L0–L4 decisions) to the TradingView Pine script that executes orders. It handles sending signals (via JSON or webhook) to Pine, translating Python’s commands into Pine alerts, synchronizing the two systems, and ensuring a failsafe operation if Python goes down[437][438]. Essentially, L5 is the communication and coordination layer between Python “brain” and Pine “limbs”.
- Key Inputs: Trade commands from Python (direction, entry price, SL, TP, position size) packaged by L69/L70, status of Pine (acknowledgements, any error alerts like order rejections), and possibly multi-asset alerts (coordinating signals across up to 50 charts as mentioned).
- Key Outputs: JSON or message structures containing trade signals to Pine’s script (includes data like regime, sigma, momentum, RR, SL, TP, direction, etc.)[438], and synchronization signals like heartbeat or “positions open/closed” notifications to Pine. It also outputs fallback instructions to Pine if Python is offline (since Pine mirror logic exists).
- Core Logic/Model: On each decision event from Python, L5 formats a JSON alert with all required fields (matching Pine’s expected format)[438], then uses a communication channel (webhook to TradingView or broker API) to send it. It ensures timing precision – e.g. if signals come on 1m and 5m bars, align them properly so Pine executes exactly on bar close signals[439]. It also manages “alert generation across 50 coins” as needed in architecture[439] (so possibly cycling through all trading symbols to send updates). If Python disconnects or fails, L5/Pine will detect no signal and Pine’s failsafe strategy (like basic MA crossover or static logic) will take over – L5 should raise an alert that it’s in fallback mode. Conversely, when Python returns, L5 resyncs Pine’s state (like sending any missed updates, resetting Pine variables accordingly).
- File & Location: core/l5_execution_bridge.py.
- Config/Wiring: Config in config/execution.yml (webhook URLs, API keys for alerts if needed, message schema). Works closely with Pine’s code – TradingView Pine script is coded to interpret L5’s messages. L5 also listens to Pine via perhaps an API or logs if Pine signals error (like an order failed) and then instructs Python to react (like try again or adjust).
- Health & Logging: L5 logs all communications (“Sent LONG signal to BTCUSD at 12:00:00 with size X, SL Y, TP Z”). It will highlight if Pine doesn’t confirm (like no response – indicating Pine might be down or network issues). If L5 fails (communication breakdown), the Pine mirror is designed to continue trading albeit with a simpler logic, ensuring positions aren’t unmanaged. But performance then relies on that fallback (less sophisticated). Quick detection of such issues is crucial (maybe L0’s error alert or L85 triggers if no ack).
- TCN Impact: This layer is critical to Execution Integrity – even the best strategy fails if execution fails. L5 ensures seamless, low-latency command execution and failover, which influences the Trust metric heavily (the system reliably executes as intended). In TCN scoring, robust execution and fault tolerance (Python <-> Pine redundancy) is an institutional requirement. L5, by guaranteeing that the “core intelligence” translates into real orders properly (and providing an emergency mirror), supports hitting the TCN-10000 mark on reliability and continuity.
L69 – Pine Final Packager (64-field Limiter)
- Domain: Pine Mirror & Execution
- Primary Role: This layer runs on Pine side or just before Pine to compress the plethora of input fields into at most 64 fields limit for TradingView’s strategy inputs[440][441]. It takes the final payload from L5/L69 Python side and ensures it’s structured within Pine’s variable count constraints. Essentially, it’s responsible for mapping the high-dimensional Python output to Pine’s limited input interface.
- Key Inputs: The execution bundle from L69 (with potentially dozens of fields: family, pattern scores, reliability, etc. – easily >64 variables).
- Key Outputs: final_pine_payload – a trimmed or encoded set of fields that Pine will actually read (ex: might combine related metrics, or skip less critical ones, or use bit-packing)[442][443]. Pine’s UI will display these as inputs on the chart.
- Core Logic/Model: Possibly groups fields: e.g., rather than separate pattern scores, it might send a single code (like an integer where bits represent which main pattern is active, or compress multiple floats into one by scaling). It might also simply not send everything – focusing on critical values like expectancy, RR, confidence, and leaving out dozens of internal debug fields (which might not be needed by Pine to execute). The key is to not exceed 64. L69 probably had this in mind already, so maybe it’s not a separate process but a step in packaging. Possibly enumerated fields could be, say: we allocate 10 fields for key signals (direction, size, SL, TP, expectancy, confidence, patternFamily, riskFlags, etc.) well under 64. If any needed more, could pack multiple boolean flags into one int bitfield.
- File & Location: Could be integrated in L5 or as part of Pine script logic itself. If separate, core/l69_field_limiter.py.
- Config/Wiring: Pine’s code needs to know how to decode whatever packing is done. So this is configured in the Pine script and corresponding bridging code. It’s likely predetermined to exactly fit Pine’s input slots.
- Health & Logging: This is more of a static formatting thing – if mis-specified, Pine might not get a parameter (like if we tried to send >64, Pine would drop extras). That could cause Pine to act with defaults (risky). So careful design and testing ensure all needed data fits. Logging mostly would be in development; at runtime, hopefully straightforward.
- TCN Impact: Not directly affecting strategy quality, but absolutely crucial for Operational readiness – it shows the system overcame a practical platform limitation elegantly. Without it, the strategy might not run in Pine at all. So from a scoring perspective, it’s baseline to have solved it (TCN might implicitly assume execution viability). It’s part of the “Integration & governance” pillar (ensuring the strategy can run within technological constraints reliably). Achieving TCN-10000 implies all such practical issues are handled – L69 demonstrates that.
L98 – Global Meta-State Engine
- Domain: Pine Mirror & Execution
- Primary Role: Combines all layer outputs into a single global state snapshot for monitoring, consistency checks, and high-level governance. L98 produces a global state vector (perhaps for display on a dashboard or for feeding into audit systems) summarizing the entire engine’s status[444][445]. It ensures internal variables are consistent (no contradictory states) and provides a single point of reference to verify the engine’s condition.
- Key Inputs: Key outputs from every major domain – positions from L4, risk from L86, signals from L66/L68, regime from L64, pattern state from L32, micro risk from L62, health from L87, etc. Possibly internal flags (like if any layer is in fallback or failing).
- Key Outputs: global_state_vector (a vector or structured object capturing overall system state: positions, biases, risk levels, regime, etc.)[445], and global_confidence_score (maybe an overall confidence in the system’s decisions – possibly lowest of sub-confidences or some aggregate)[446]. This likely isn’t used by other layers for decisions but is logged/stored for oversight. Could be fed into a security/governance layer (like L100) or for an admin UI.
- Core Logic/Model: Aggregation – collects and normalizes states (e.g., ensures values are on comparable scale or encoded properly). Might check for contradictions (like if global_confidence is extremely low but trades open – could flag that to L87 or L85). The global_confidence_score might be computed from various confidence metrics (from L3, L24, L67, L87 health, etc.) to give a high-level “system confidence” number. If it’s low, triggers might be set in L85 or L87 to intervene.
- File & Location: core/l98_global_state.py.
- Config/Wiring: Likely outputs to a particular file or monitoring service, or Pine might simply display some aggregated info from it. Not heavily configurable beyond selection of fields to include.
- Health & Logging: Logs state every period (like a heartbeat with everything). If disabled, it doesn’t affect trading, but you lose integrated oversight. It’s crucial for debugging and ensuring “full internal consistency” as roadmap said[342].
- TCN Impact: Indirect – it shows that the engine has a concept of its unified state, aiding in Governance and Security. This can help detect if something’s off (for example, if a layer is giving weird outputs, global state could catch mismatch). It’s an infrastructure piece that fortifies reliability – a factor in TCN scoring under integrity and maintainability of the system.
L99 – Pine Final Packager (64-field Limiter)
(Note: L99 seems to overlap with earlier field limiting – it’s possible L99 is effectively implemented as the final packaging on Pine side.)
- Domain: Pine Mirror & Execution
- Primary Role: On the Pine side, this final step likely compresses any last bits of logic needed to adhere to TradingView’s environment, packaging outputs into Pine’s data structures or arrays. Perhaps it’s ensuring the final state variables used by Pine’s strategy (like for plotting or computing position sizes) are set from the received payload. Essentially, L99 is a stub in code that ensures everything from Python is ingested properly in Pine within limitations.
- Key Inputs: The final payload from L69 (which is presumably within 64 fields).
- Key Outputs: The actual assignment of these to Pine variables that the Pine strategy uses for decisions. Possibly L99 just acknowledges receiving the payload.
- Core Logic/Model: Likely just variable assignment or minimal logic (since heavy logic is in Python). Could combine some values if still needed in Pine (but presumably not).
- File & Location: In the TradingView Pine script, this would be implemented (no separate file, it’s part of Pine code).
- TCN Impact: By this stage, negligible direct impact – just ensures execution environment compliance. It’s an indicator of thorough engineering which is implicit for TCN-10000 but not a separate metric.
L100 – Final Executor (Python → Pine → Human)
- Domain: Pine Mirror & Execution
- Primary Role: The ultimate execution guardian that integrates trade execution logic between Python, Pine, and possibly manual human oversight for security/integrity[447][448]. L100 ensures that trades are executed as intended, monitors if Pine and Python are in sync, triggers any manual notifications (to human operators) if needed, and closes the loop on state management. It’s like the final sentinel ensuring all components (autonomous and human) are aware of actions.
- Key Inputs: Confirmations from Pine that an entry or exit occurred (via broker API feedback or Pine’s strategy logs), updates from Python on state (positions taken, etc.), and any governance rules (like daily trading cutoff times, security checks requiring human sign-off if risk too high). Possibly also monitors the entire system runtime state (like if any process is not responding, it might notify).
- Key Outputs: pre_entry_alert (notify human or log before an entry if necessary)[449], entry_signal (actual order execution trigger)[449], early_exit_alert (if L81 triggers, maybe notify or log), dynamic_TP_SL_update (if trailing stops or updates happen, ensure Pine applied them), exit_alert (when position closed, notify/log outcome), and full executor package (for audit – a detailed record of everything for that trade)[448].
- Core Logic/Model: Orchestrates final execution and notifications. For example, if a trade is about to execute, L100 might log and email “Entering LONG BTCUSD, 1% equity, SL at..., TP at..., per system.” It ensures all needed state resets happen after exit (like clearing variables, ready for new cycle). It also might implement any final security checks – e.g. maybe require human confirmation if trade size > certain threshold or if multiple system components down (just speculation). Essentially, it’s the final integration of auto and manual control.
- File & Location: Possibly partly in Pine, partly as a separate monitoring script/integration. Could be in a control script running on a server listening to events from Pine and Python.
- Health & Logging: Logs absolutely every step and outcome (“Signal executed, order ID..., outcome recorded”). If L100 fails, trades may execute but without proper logging or oversight – which is dangerous for institutional ops as you lose audit trail or might violate compliance. So redundancy likely – logs saved in multiple places, etc.
- TCN Impact: L100 is about Institutional Governance, Security, Integrity Sentinel as per summary[450]. It’s crucial for meeting the non-functional requirements (like compliance logging, human oversight). TCN-10000 would demand evidence of such governance. L100 helps ensure the system can be trusted by an institution – providing audit trails and manual override points. This doesn’t improve returns but is vital for trust, which is indirectly captured in TCN scoring under qualitative robustness and governance.
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [343] StratoQuant_L0–L100_FULL_SPEC_Part_01.txt
file://file-42H7WfJjGuLpf8CWNmZnnv
[11] [12] [57] [58] [342] [395] [396] [399] [400] [401] [402] [403] [420] [450] TCN-10000 ROADMAP.txt
file://file-A9TfP3s7raWzQwqA7NcTKH
[13] [14] [15] [16] [17] [18] [44] [45] [46] [47] [48] [49] [50] [51] [52] [53] [54] [55] [56] [59] [60] [61] [62] [185] [336] [337] [338] [339] [340] [341] [344] [345] [346] [347] [348] [349] [350] [351] [352] [353] [354] [355] [356] [357] [358] [359] [360] [361] [364] [365] [366] StratoQuant_L0–L100_FULL_SPEC_Part_07E.txt
file://file-D5f1vAWj3y4prbhFE7eQW3
[19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [328] [329] [330] [331] [332] [333] [334] [335] [415] [416] [418] [419] StratoQuant_L0–L100_FULL_SPEC_Part_04.txt
file://file-WWa7tBsTzS54KPB2CJcHPf
[29] [30] [31] [32] [33] [34] [35] [36] [37] [38] [39] [80] [81] [82] [83] [84] [85] [86] [88] [89] [90] [91] [92] [93] [94] [95] [96] [97] [98] [99] [100] [101] StratoQuant_L0–L100_FULL_SPEC_Part_05.txt
file://file-QeTLvkPRDWD2QwWFwfBmuG
[40] [41] [42] [43] [127] [128] [146] [147] [148] [149] [150] [151] [152] [154] [155] [156] [157] [158] [159] [160] [161] [162] [163] [164] [165] [166] [169] [170] [171] [172] [173] [174] [175] [176] [177] [178] [179] [180] [181] [182] [183] [184] [186] [187] [188] [189] [190] [191] [192] [193] [194] [195] [196] [197] [198] [266] StratoQuant_L0–L100_FULL_SPEC_Part_07D.txt
file://file-3DTVq7qQUtUuUvy2VwXajP
[63] [64] [65] [66] [67] [68] [69] [70] [71] [72] [73] [74] [75] [76] [77] [78] [79] [87] [306] [307] [308] [309] [310] [311] [312] [313] [314] [316] [317] [318] [319] [320] [321] [322] [323] [324] [325] [326] [327] StratoQuant_L0–L100_FULL_SPEC_Part_02.txt
file://file-7ofofdeVXexbLBGEgtXF95
[102] [103] [104] [105] [106] [107] [108] [109] [110] [111] [112] [113] [114] [115] [116] [117] [118] [119] [120] [123] [124] [125] [126] [130] [131] [132] [133] [136] [137] [138] [139] [140] [141] [142] [143] [144] [145] [236] StratoQuant_L0–L100_FULL_SPEC_Part_06.txt
file://file-XvSQKPqRaitBw3x1UEFuBf
[121] [129] [134] [135] [199] [200] [201] [202] [203] [204] [205] [206] [207] [208] [209] [210] [211] [212] [213] [214] [215] [216] [217] [218] [219] [220] [221] [222] [223] [224] [225] [226] [227] [228] [229] [230] [231] [232] [233] [234] [235] [237] [238] [239] [240] [241] [242] [243] [244] [245] StratoQuant_L0–L100_FULL_SPEC_Part_07A.txt
file://file-L5BD5et4FESmGhC72Qsk2h
[122] [246] [247] [248] [249] [250] [251] [252] [253] [254] [255] [256] [257] [258] [259] [260] [261] [262] [263] [264] [265] [267] [268] [269] [270] [271] [272] [273] [274] [275] [276] [277] [278] [279] [280] [281] [282] [283] [284] [285] [286] [287] [288] [289] [290] [291] [292] [293] [294] [295] [296] [297] [298] [299] [300] [301] [302] [303] [304] [305] StratoQuant_L0–L100_FULL_SPEC_Part_07B.txt
file://file-W8nrRXKVKELM6LiwNdwkBn
[153] [315] [362] [367] [368] [369] [370] [371] [372] [373] [374] [375] [376] [377] [378] [379] [380] [381] [382] [383] [384] [385] [386] [387] [388] [389] [390] [391] [392] [393] [394] [397] [437] [438] [439] StratoQuant_L0–L100_FULL_SPEC_Part_03.txt
file://file-RcKCfzUZsDbJLr4ihPPL7h
[167] [168] [363] StratoQuant_L0–L100_FULL_SPEC_Part_07C.txt
file://file-SwqEgoMPwm1bZTJRQjfYJ7
[398] [404] [405] [406] [407] [408] [409] [410] [411] [412] [413] [414] [417] [421] [422] [423] [424] [425] [426] [427] [428] [429] [430] [431] [432] [433] [434] [435] [436] [440] [441] [442] [443] [444] [445] [446] [447] [448] [449] StratoQuant_L0–L100_FULL_SPEC_Part_07F.txt
file://file-45ZDySnUFTWkApqr9uxvqL